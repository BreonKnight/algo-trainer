{
  "zigzag-traversal": {
    "name": "Zigzag Traversal",
    "type": "array",
    "description": "Zigzag Traversal is an algorithm with time complexity O(n). It is primarily used for level-order traversal with alternating       directions",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Level-order traversal with alternating\n      directions\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Level-order traversal with alternating\n      directions\n    ",
    "useCase": "Level-order traversal with alternating\n      directions\n    ",
    "pseudocode": "// Zigzag level order traversal\nZIGZAG-TRAVERSAL(root):\n  if root == null:\n    return []\n  \n  result = []\n  queue = [root]\n  level = 0\n  \n  while queue is not empty:\n    level_size = len(queue)\n    current_level = []\n    \n    for i = 0 to level_size-1:\n      node = queue.dequeue()\n      if level % 2 == 0:\n        current_level.append(node.val)\n      else:\n        current_level.insert(0, node.val)\n      \n      if node.left:\n        queue.enqueue(node.left)\n      if node.right:\n        queue.enqueue(node.right)\n    \n    result.append(current_level)\n    level += 1\n  \n  return result\n\n// Example usage\ntree = [3,9,20,null,null,15,7]\nresult = ZIGZAG-TRAVERSAL(tree)\n// Returns: [[3],[20,9],[15,7]]",
    "keySteps": [
      "Modified level-order traversal",
      "Uses queue for efficient level processing",
      "Can be implemented with two stacks"
    ]
  },
  "z-algorithm": {
    "name": "Z Algorithm",
    "type": "string",
    "description": "Z-Algorithm is an algorithm with time complexity O(n). It is primarily used for pattern matching in string",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Pattern matching in string\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Pattern matching in string\n    ",
    "useCase": "Pattern matching in string\n    ",
    "pseudocode": "# Z Algorithm: Pattern matching in string\n# Input: String S[1..n]\n# Output: Array Z[1..n] where Z[i] is length of longest substring starting at i that is also a prefix\n\nAlgorithm Z-ALGORITHM(S)\n    n ← length[S]\n    Z[1..n] ← [0, 0, ..., 0]\n    Z[1] ← n\n    L ← 1\n    R ← 1\n\n    for i ← 2 to n do\n        if i > R then\n            # Case 1: i outside current Z-box\n            L ← i\n            R ← i\n            while R ≤ n and S[R-L+1] = S[R] do\n                R ← R + 1\n            Z[i] ← R - L\n            R ← R - 1\n        else\n            # Case 2: i inside current Z-box\n            k ← i - L + 1\n            if Z[k] < R - i + 1 then\n                # Case 2a: Z[k] < remaining\n                Z[i] ← Z[k]\n            else\n                # Case 2b: Z[k] ≥ remaining\n                L ← i\n                while R ≤ n and S[R-L+1] = S[R] do\n                    R ← R + 1\n                Z[i] ← R - L\n                R ← R - 1\n    return Z\n\n# Example:\n# Input: S = \"aabxaabxcaabxaabxay\"\n#\n# Step 1: Initialize Z[1] = 19 (length of S)\n# Step 2: i=2, outside Z-box, find Z[2] = 1\n# Step 3: i=3, outside Z-box, find Z[3] = 0\n# Step 4: i=4, outside Z-box, find Z[4] = 0\n# Step 5: i=5, outside Z-box, find Z[5] = 4\n# ... continue until i=19\n#\n# Output: Z = [19, 1, 0, 0, 4, 1, 0, 0, 0, 8, 1, 0, 0, 5, 1, 0, 0, 1, 0]",
    "keySteps": [
      "Initialize Z array and first element",
      "Maintain Z-box boundaries (L, R)",
      "Handle two cases: outside and inside Z-box",
      "Compute Z[i] based on position and previous values"
    ]
  },
  "union-find": {
    "name": "Union Find",
    "type": "algorithm",
    "description": "Union Find is an algorithm with time complexity O(α(n). It is primarily used for managing disjoint sets",
    "timeComplexity": "O(α(n)) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Managing disjoint sets\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Managing disjoint sets\n    ",
    "useCase": "Managing disjoint sets\n    ",
    "pseudocode": "// Create new set\nMAKE-SET(x):\n    x.parent = x\n    x.rank = 0\n\n// Find set representative\nFIND-SET(x):\n    if x ≠ x.parent:\n        x.parent = FIND-SET(x.parent)  // Path compression\n    return x.parent\n\n// Union two sets\nUNION(x, y):\n    x_root = FIND-SET(x)\n    y_root = FIND-SET(y)\n    if x_root = y_root:\n        return\n    if x_root.rank < y_root.rank:\n        x_root.parent = y_root\n    else if x_root.rank > y_root.rank:\n        y_root.parent = x_root\n    else:\n        y_root.parent = x_root\n        x_root.rank = x_root.rank + 1\n\n// Check if elements are in same set\nCONNECTED(x, y):\n    return FIND-SET(x) = FIND-SET(y)",
    "keySteps": []
  },
  "two-sum": {
    "name": "Two Sum",
    "type": "array",
    "description": "Two Sum is an algorithm with time complexity O(n²). It is primarily used for find indices of two numbers that sum       to target",
    "timeComplexity": "O(n²) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find indices of two numbers that sum\n      to target\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find indices of two numbers that sum\n      to target\n    ",
    "useCase": "Find indices of two numbers that sum\n      to target\n    ",
    "pseudocode": "TWO-SUM(A, target)\n    let n be the length of A\n    for i ← 1 to n - 1\n        do for j ← i + 1 to n\n            do if A[i] + A[j] = target\n                then return [i, j]\n    return NIL\n\n// Example:\n// Input: A = [2, 7, 11, 15], target = 9\n//\n// i = 1, j = 2: A[1] + A[2] = 2 + 7 = 9\n//\n// Output: [1, 2]",
    "keySteps": [
      "Initialize: Set up nested loops for array traversal",
      "Compare: Check if current pair sums to target",
      "Return: Indices of elements that sum to target"
    ]
  },
  "two-sum-two-pointers": {
    "name": "Two Sum Two Pointers",
    "type": "array",
    "description": "Two Sum (Two Pointers) is an algorithm with time complexity O(n log n). It is primarily used for find pairs that sum to target",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find pairs that sum to target\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find pairs that sum to target\n    ",
    "useCase": "Find pairs that sum to target\n    ",
    "pseudocode": "# Two Sum (Two Pointers): Find pairs that sum to target\n# Input: Array A[1..n], target value t\n# Output: Indices (i, j) where A[i] + A[j] = t, or (-1, -1) if not found\n\nAlgorithm TWO-SUM-TWO-POINTERS(A, t)\n    # Sort array for two pointers approach\n    A ← SORT(A)\n    left ← 1\n    right ← length[A]\n\n    while left < right do\n        sum ← A[left] + A[right]\n        if sum = t then\n            return (left, right)\n        else if sum < t then\n            left ← left + 1\n        else\n            right ← right - 1\n        end if\n    end while\n\n    return (-1, -1)\n\n# Example:\n# Input: A = [2, 7, 11, 15], t = 9\n#\n# Step 1: A = [2, 7, 11, 15], left = 1, right = 4\n# Step 2: sum = 2 + 15 = 17 > 9, right = 3\n# Step 3: sum = 2 + 11 = 13 > 9, right = 2\n# Step 4: sum = 2 + 7 = 9 = t, return (1, 2)\n#\n# Output: (1, 2)",
    "keySteps": [
      "Sort the input array",
      "Initialize left and right pointers",
      "Move pointers based on sum comparison with target",
      "Return indices when sum equals target"
    ]
  },
  "two-sum-dict": {
    "name": "Two Sum Dictionary",
    "type": "array",
    "description": "Two Sum (Dictionary) is an algorithm with time complexity O(n). It is primarily used for find pairs that sum to target",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Find pairs that sum to target\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Find pairs that sum to target\n    ",
    "useCase": "Find pairs that sum to target\n    ",
    "pseudocode": "# Two Sum (Dictionary): Find pairs that sum to target\n# Input: Array A[1..n], target value t\n# Output: Indices (i, j) where A[i] + A[j] = t, or (-1, -1) if not found\n\nAlgorithm TWO-SUM-DICTIONARY(A, t)\n    # Initialize dictionary to store value-index pairs\n    D ← empty dictionary\n\n    for i ← 1 to length[A] do\n        complement ← t - A[i]\n        if complement ∈ D then\n            return (D[complement], i)\n        end if\n        D[A[i]] ← i\n    end for\n\n    return (-1, -1)\n\n# Example:\n# Input: A = [2, 7, 11, 15], t = 9\n#\n# Step 1: i = 1, A[1] = 2, complement = 7, D = {2: 1}\n# Step 2: i = 2, A[2] = 7, complement = 2 ∈ D, return (1, 2)\n#\n# Output: (1, 2)",
    "keySteps": [
      "Initialize empty dictionary",
      "For each element, calculate complement",
      "Check if complement exists in dictionary",
      "Store current element and index in dictionary"
    ]
  },
  "two-pointers": {
    "name": "Two Pointers",
    "type": "array",
    "description": "Two Pointers is an algorithm with time complexity O(n). It is primarily used for finding pairs or subarrays that       satisfy certain conditions",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Finding pairs or subarrays that\n      satisfy certain conditions\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Finding pairs or subarrays that\n      satisfy certain conditions\n    ",
    "useCase": "Finding pairs or subarrays that\n      satisfy certain conditions\n    ",
    "pseudocode": "// Two sum\nTWO-SUM(A, target):\n  left = 0\n  right = A.length - 1\n  while left < right:\n    sum = A[left] + A[right]\n    if sum == target:\n      return [left, right]\n    else if sum < target:\n      left += 1\n    else:\n      right -= 1\n  return NIL\n\n// Remove duplicates\nREMOVE-DUPLICATES(A):\n  if A.length == 0:\n    return 0\n  slow = 0\n  for fast = 1 to A.length-1:\n    if A[fast] != A[slow]:\n      slow += 1\n      A[slow] = A[fast]\n  return slow + 1\n\n// Container with most water\nMAX-AREA(height):\n  left = 0\n  right = height.length - 1\n  max_area = 0\n  while left < right:\n    area = min(height[left], height[right]) * (right - left)\n    max_area = max(max_area, area)\n    if height[left] < height[right]:\n      left += 1\n    else:\n      right -= 1\n  return max_area\n\n// Three sum\nTHREE-SUM(A, target):\n  sort(A)\n  result = []\n  for i = 0 to A.length-2:\n    if i > 0 and A[i] == A[i-1]:\n      continue\n    left = i + 1\n    right = A.length - 1\n    while left < right:\n      sum = A[i] + A[left] + A[right]\n      if sum == target:\n        result.append([A[i], A[left], A[right]])\n        while left < right and A[left] == A[left+1]:\n          left += 1\n        while left < right and A[right] == A[right-1]:\n          right -= 1\n        left += 1\n        right -= 1\n      else if sum < target:\n        left += 1\n      else:\n        right -= 1\n  return result",
    "keySteps": []
  },
  "two-pointer": {
    "name": "Two Pointer",
    "type": "string",
    "description": "Two Pointer is an algorithm with time complexity O(n). It is primarily used for array/string manipulation with two       indices",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Array/string manipulation with two\n      indices\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Array/string manipulation with two\n      indices\n    ",
    "useCase": "Array/string manipulation with two\n      indices\n    ",
    "pseudocode": "// Two pointer technique\nTWO-POINTER-SUM(A, target):\n  left = 0\n  right = len(A) - 1\n  \n  while left < right:\n    sum = A[left] + A[right]\n    if sum == target:\n      return [left, right]\n    elif sum < target:\n      left += 1\n    else:\n      right -= 1\n  return [-1, -1]\n\n// Example usage\nA = [1, 2, 3, 4, 5, 6]\ntarget = 9\nresult = TWO-POINTER-SUM(A, target)\n// Returns: [3, 4] (indices of 4 and 5)",
    "keySteps": [
      "Finding pairs that sum to a target value",
      "Reversing arrays or strings",
      "Finding palindromes",
      "Merging sorted arrays"
    ]
  },
  "trie": {
    "name": "Trie",
    "type": "tree",
    "description": "Trie is an algorithm with time complexity O(L). It is primarily used for efficient string storage and search",
    "timeComplexity": "O(L) &nbsp;|&nbsp; Space: O(AL) &nbsp;|&nbsp; Use: Efficient string storage and search\n    ",
    "spaceComplexity": "O(AL) &nbsp;|&nbsp; Use: Efficient string storage and search\n    ",
    "useCase": "Efficient string storage and search\n    ",
    "pseudocode": "// Trie node structure\nTRIE-NODE:\n    children[1..26]  // Array of child nodes\n    is_end          // Marks end of word\n    count           // Number of words with this prefix\n\n// Initialize trie\nTRIE-INIT():\n    root ← new TRIE-NODE\n    root.is_end ← false\n    root.count ← 0\n    return root\n\n// Insert word into trie\nTRIE-INSERT(root, word):\n    current ← root\n    for i ← 1 to length[word]:\n        index ← word[i] - 'a'\n        if current.children[index] = NIL:\n            current.children[index] ← new TRIE-NODE\n        current ← current.children[index]\n        current.count ← current.count + 1\n    current.is_end ← true\n\n// Search word in trie\nTRIE-SEARCH(root, word):\n    current ← root\n    for i ← 1 to length[word]:\n        index ← word[i] - 'a'\n        if current.children[index] = NIL:\n            return false\n        current ← current.children[index]\n    return current.is_end\n\n// Count words with prefix\nTRIE-COUNT-PREFIX(root, prefix):\n    current ← root\n    for i ← 1 to length[prefix]:\n        index ← prefix[i] - 'a'\n        if current.children[index] = NIL:\n            return 0\n        current ← current.children[index]\n    return current.count\n\n// Example:\n// Input: words = [\"apple\", \"app\", \"banana\", \"ball\"]\n//\n// Trie Structure:\n//         (root)\n//        /      \\\\\n//       a        b\n//      /         \\\\\n//     p           a\n//    / \\\\         \\\\\n//   p   p         l\n//  /     \\\\        \\\\\n// l       l        l\n// |       |        |\n// e       e        e\n//\n// Operations:\n// 1. Search \"app\" → true\n// 2. Search \"ban\" → false\n// 3. Count prefix \"ap\" → 2\n// 4. Count prefix \"ba\" → 2",
    "keySteps": [
      "Initialize: Create root node",
      "Insert: Add words character by character",
      "Search: Traverse trie for word existence"
    ]
  },
  "trie-operations": {
    "name": "Trie Operations",
    "type": "tree",
    "description": "Trie Operations is an algorithm with time complexity O(m). It is primarily used for string prefix       operations",
    "timeComplexity": "O(m) &nbsp;|&nbsp; Space: O(ALPHABET_SIZE * m * n) &nbsp;|&nbsp; Use: String prefix\n      operations\n    ",
    "spaceComplexity": "O(ALPHABET_SIZE * m * n) &nbsp;|&nbsp; Use: String prefix\n      operations\n    ",
    "useCase": "String prefix\n      operations\n    ",
    "pseudocode": "// Node structure\nNODE:\n    children[ALPHABET_SIZE]\n    isEndOfWord\n\n// Initialize trie\nTRIE-INIT():\n    root ← new NODE\n    root.isEndOfWord ← false\n    for i ← 1 to ALPHABET_SIZE:\n        root.children[i] ← null\n    return root\n\n// Insert word\nTRIE-INSERT(root, word):\n    node ← root\n    for i ← 1 to length[word]:\n        index ← word[i] - 'a'\n        if node.children[index] = null:\n            node.children[index] ← new NODE\n        node ← node.children[index]\n    node.isEndOfWord ← true\n\n// Search word\nTRIE-SEARCH(root, word):\n    node ← root\n    for i ← 1 to length[word]:\n        index ← word[i] - 'a'\n        if node.children[index] = null:\n            return false\n        node ← node.children[index]\n    return node.isEndOfWord\n\n// Check prefix\nTRIE-STARTS-WITH(root, prefix):\n    node ← root\n    for i ← 1 to length[prefix]:\n        index ← prefix[i] - 'a'\n        if node.children[index] = null:\n            return false\n        node ← node.children[index]\n    return true\n\n// Delete word\nTRIE-DELETE(root, word):\n    return TRIE-DELETE-HELPER(root, word, 0)\n\nTRIE-DELETE-HELPER(node, word, depth):\n    if node = null:\n        return false\n    if depth = length[word]:\n        if node.isEndOfWord:\n            node.isEndOfWord ← false\n            return is-empty(node)\n        return false\n    index ← word[depth] - 'a'\n    if TRIE-DELETE-HELPER(node.children[index], word, depth + 1):\n        node.children[index] ← null\n        return is-empty(node) and not node.isEndOfWord\n    return false\n\n// Example:\n// Input: Operations [INSERT(\"apple\"), INSERT(\"app\"), SEARCH(\"apple\"), DELETE(\"app\")]\n//\n// After INSERT(\"apple\"):\n//    root\n//     |\n//     a\n//     |\n//     p\n//     |\n//     p\n//     |\n//     l\n//     |\n//     e (end)\n//\n// After INSERT(\"app\"):\n//    root\n//     |\n//     a\n//     |\n//     p\n//     |\n//     p (end)\n//     |\n//     l\n//     |\n//     e (end)\n//\n// SEARCH(\"apple\") → true\n// SEARCH(\"app\") → true\n//\n// After DELETE(\"app\"):\n//    root\n//     |\n//     a\n//     |\n//     p\n//     |\n//     p\n//     |\n//     l\n//     |\n//     e (end)",
    "keySteps": [
      "Insert: Add word character by character, marking end",
      "Search: Traverse trie following word characters",
      "Delete: Remove word and clean up unused nodes"
    ]
  },
  "tree-implementation": {
    "name": "Tree Implementation",
    "type": "tree",
    "description": "Tree Implementation is an algorithm with time complexity O(n). It is primarily used for tree representation and traversal",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Tree representation and traversal\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Tree representation and traversal\n    ",
    "useCase": "Tree representation and traversal\n    ",
    "pseudocode": "// Binary tree node structure\nTREE-NODE(key):\n    node ← new object\n    node.key ← key\n    node.left ← NIL\n    node.right ← NIL\n    node.parent ← NIL\n    return node\n\n// Tree traversal algorithms\nINORDER-TREE-WALK(x):\n    if x ≠ NIL:\n        INORDER-TREE-WALK(x.left)\n        print x.key\n        INORDER-TREE-WALK(x.right)\n\nPREORDER-TREE-WALK(x):\n    if x ≠ NIL:\n        print x.key\n        PREORDER-TREE-WALK(x.left)\n        PREORDER-TREE-WALK(x.right)\n\nPOSTORDER-TREE-WALK(x):\n    if x ≠ NIL:\n        POSTORDER-TREE-WALK(x.left)\n        POSTORDER-TREE-WALK(x.right)\n        print x.key\n\n// Tree search operations\nTREE-SEARCH(x, k):\n    if x = NIL or k = x.key:\n        return x\n    if k < x.key:\n        return TREE-SEARCH(x.left, k)\n    else:\n        return TREE-SEARCH(x.right, k)\n\nITERATIVE-TREE-SEARCH(x, k):\n    while x ≠ NIL and k ≠ x.key:\n        if k < x.key:\n            x ← x.left\n        else:\n            x ← x.right\n    return x\n\nTREE-MINIMUM(x):\n    while x.left ≠ NIL:\n        x ← x.left\n    return x\n\nTREE-MAXIMUM(x):\n    while x.right ≠ NIL:\n        x ← x.right\n    return x\n\nTREE-SUCCESSOR(x):\n    if x.right ≠ NIL:\n        return TREE-MINIMUM(x.right)\n    y ← x.parent\n    while y ≠ NIL and x = y.right:\n        x ← y\n        y ← y.parent\n    return y\n\n// Example:\n// Input: Binary tree with keys [4, 2, 6, 1, 3, 5, 7]\n//\n// Tree structure:\n//       4\n//     /   \\\\\n//    2     6\n//   / \\\\   / \\\\\n//  1   3 5   7\n//\n// Inorder traversal: 1 2 3 4 5 6 7\n// Preorder traversal: 4 2 1 3 6 5 7\n// Postorder traversal: 1 3 2 5 7 6 4",
    "keySteps": [
      "Structure: Define node with key, left, right, and parent pointers",
      "Traversal: Implement inorder, preorder, and postorder walks",
      "Operations: Search, minimum, maximum, and successor functions"
    ]
  },
  "tree-dp": {
    "name": "Tree (Dynamic Programming)",
    "type": "tree",
    "description": "Tree Dynamic Programming is an algorithm with time complexity O(n). It is primarily used for solve tree problems with overlapping       subproblems",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Solve tree problems with overlapping\n      subproblems\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Solve tree problems with overlapping\n      subproblems\n    ",
    "useCase": "Solve tree problems with overlapping\n      subproblems\n    ",
    "pseudocode": "# Tree Dynamic Programming: Solve tree problems with overlapping subproblems\n# Input: Root node r of a tree\n# Output: Optimal solution value for the tree\n\nAlgorithm TREE-DP(r)\n    # Base case: empty tree\n    if r = NIL then\n        return 0\n    end if\n\n    # Initialize memoization table\n    memo ← empty dictionary\n\n    # Helper function for post-order traversal\n    function DFS(u)\n        if u = NIL then\n            return 0\n        end if\n\n        # Check if already computed\n        if u ∈ memo then\n            return memo[u]\n        end if\n\n        # Case 1: Include current node\n        include ← u.value\n        for each child v of u do\n            for each grandchild w of v do\n                include ← include + DFS(w)\n            end for\n        end for\n\n        # Case 2: Exclude current node\n        exclude ← 0\n        for each child v of u do\n            exclude ← exclude + DFS(v)\n        end for\n\n        # Store and return optimal solution\n        memo[u] ← max(include, exclude)\n        return memo[u]\n    end function\n\n    return DFS(r)\n\n# Example:\n# Input: Tree with nodes [3, 4, 5, 1, 3, 1]\n#\n# Step 1: DFS(3)\n#   include = 3 + DFS(1) + DFS(3) = 3 + 1 + 3 = 7\n#   exclude = DFS(4) + DFS(5) = 4 + 5 = 9\n#   memo[3] = max(7, 9) = 9\n#\n# Output: 9",
    "keySteps": []
  },
  "topological-sort": {
    "name": "Topological Sort",
    "type": "algorithm",
    "description": "Topological Sort is an algorithm with time complexity O(V + E). It is primarily used for linear ordering of vertices in a       dag",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Linear ordering of vertices in a\n      DAG\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Linear ordering of vertices in a\n      DAG\n    ",
    "useCase": "Linear ordering of vertices in a\n      DAG\n    ",
    "pseudocode": "# Topological Sort: Linear ordering of vertices in a DAG\n# Input: Directed Acyclic Graph G = (V, E)\n# Output: Topological ordering of vertices\n\nAlgorithm TOPOLOGICAL-SORT(G)\n    # Initialize visited and result arrays\n    visited ← empty array of size |V|\n    result ← empty array\n    time ← 0\n\n    # Helper function for DFS\n    function DFS(u)\n        visited[u] ← true\n        time ← time + 1\n        u.discovery ← time\n\n        for each vertex v in G.Adj[u] do\n            if not visited[v] then\n                DFS(v)\n            end if\n        end for\n\n        time ← time + 1\n        u.finish ← time\n        result.append(u)\n    end function\n\n    # Perform DFS on all vertices\n    for each vertex u in G.V do\n        if not visited[u] then\n            DFS(u)\n        end if\n    end for\n\n    # Reverse to get topological order\n    return reverse(result)\n\n# Example:\n# Input: G = (V, E) where V = {1, 2, 3, 4, 5}\n#        E = {(1,2), (1,3), (2,4), (3,4), (4,5)}\n#\n# Step 1: DFS(1)\n#   discovery[1] = 1, finish[1] = 10\n#   discovery[2] = 2, finish[2] = 7\n#   discovery[4] = 3, finish[4] = 6\n#   discovery[5] = 4, finish[5] = 5\n#   discovery[3] = 8, finish[3] = 9\n#\n# Output: [1, 3, 2, 4, 5]",
    "keySteps": [
      "Initialize visited and result arrays",
      "Perform DFS on all unvisited vertices",
      "Track discovery and finish times",
      "Reverse result to get topological order"
    ]
  },
  "test-data": {
    "name": "Test Data",
    "type": "other",
    "description": "Test Data is an algorithm with time complexity O(n). It is primarily used for verify algorithm correctness",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Verify algorithm correctness\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Verify algorithm correctness\n    ",
    "useCase": "Verify algorithm correctness\n    ",
    "pseudocode": "// Test Data Structure\nTEST-CASE:\n    input: any\n    expected: any\n    description: string\n\n// Test Suite\nTEST-SUITE:\n    test_cases: array of TEST-CASE\n    edge_cases: array of TEST-CASE\n    boundary_cases: array of TEST-CASE\n\n// Example Test Suite\ntest_suite = {\n    test_cases: [\n        {\n            input: [1, 2, 3, 4, 5],\n            expected: 15,\n            description: \"Sum of array elements\"\n        },\n        {\n            input: [-1, -2, -3],\n            expected: -6,\n            description: \"Sum of negative numbers\"\n        }\n    ],\n    edge_cases: [\n        {\n            input: [],\n            expected: 0,\n            description: \"Empty array\"\n        },\n        {\n            input: [1],\n            expected: 1,\n            description: \"Single element\"\n        }\n    ],\n    boundary_cases: [\n        {\n            input: [Number.MAX_SAFE_INTEGER, 1],\n            expected: Number.MAX_SAFE_INTEGER + 1,\n            description: \"Integer overflow\"\n        }\n    ]\n}",
    "keySteps": [
      "Define: Input and expected output",
      "Include: Edge cases and boundary conditions",
      "Verify: Algorithm correctness"
    ]
  },
  "ternary-search-algorithm": {
    "name": "Ternary Search",
    "type": "searching",
    "description": "Ternary Search is an algorithm with time complexity O(log₃ n). It is primarily used for find maximum/minimum in unimodal       function",
    "timeComplexity": "O(log₃ n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find maximum/minimum in unimodal\n      function\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find maximum/minimum in unimodal\n      function\n    ",
    "useCase": "Find maximum/minimum in unimodal\n      function\n    ",
    "pseudocode": "# Ternary Search: Find maximum/minimum in unimodal function\n# Input: Array A[1..n], target value t\n# Output: Index of target value, or -1 if not found\n\nAlgorithm TERNARY-SEARCH(A, t)\n    left ← 1\n    right ← length[A]\n\n    while left ≤ right do\n        # Divide range into three parts\n        mid1 ← left + (right - left) / 3\n        mid2 ← right - (right - left) / 3\n\n        if A[mid1] = t then\n            return mid1\n        else if A[mid2] = t then\n            return mid2\n        else if t < A[mid1] then\n            right ← mid1 - 1\n        else if t > A[mid2] then\n            left ← mid2 + 1\n        else\n            left ← mid1 + 1\n            right ← mid2 - 1\n        end if\n    end while\n\n    return -1\n\n# Example:\n# Input: A = [1, 2, 3, 4, 5, 6, 7, 8, 9], t = 5\n#\n# Step 1: left = 1, right = 9, mid1 = 4, mid2 = 6\n#         A[4] = 4 < 5, A[6] = 6 > 5\n# Step 2: left = 5, right = 5, mid1 = 5, mid2 = 5\n#         A[5] = 5 = t\n#\n# Output: 5",
    "keySteps": []
  },
  "suffix-tree": {
    "name": "Suffix Tree",
    "type": "algorithm",
    "description": "Suffix Tree is an algorithm with time complexity O(n). It is primarily used for efficient string operations",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Efficient string operations\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Efficient string operations\n    ",
    "useCase": "Efficient string operations\n    ",
    "pseudocode": "// Suffix tree node structure\nSUFFIX-NODE:\n    start\n    end\n    children\n    suffix_link\n    parent\n\n// Build suffix tree using Ukkonen's algorithm\nBUILD-SUFFIX-TREE(S):\n    n ← length[S]\n    root ← new SUFFIX-NODE\n    active_node ← root\n    active_edge ← 0\n    active_length ← 0\n    remaining ← 0\n\n    for i ← 1 to n:\n        remaining ← remaining + 1\n        last_new_node ← NIL\n\n        while remaining > 0:\n            if active_length = 0:\n                active_edge ← i\n\n            if active_node.children[S[active_edge]] = NIL:\n                active_node.children[S[active_edge]] ← new SUFFIX-NODE\n                if last_new_node ≠ NIL:\n                    last_new_node.suffix_link ← active_node\n                    last_new_node ← NIL\n            else:\n                next_node ← active_node.children[S[active_edge]]\n                if active_length ≥ next_node.end - next_node.start + 1:\n                    active_length ← active_length - (next_node.end - next_node.start + 1)\n                    active_edge ← active_edge + (next_node.end - next_node.start + 1)\n                    active_node ← next_node\n                    continue\n\n            if S[i] = S[next_node.start + active_length]:\n                active_length ← active_length + 1\n                if last_new_node ≠ NIL and active_node ≠ root:\n                    last_new_node.suffix_link ← active_node\n                    last_new_node ← NIL\n                break\n\n            split_node ← new SUFFIX-NODE\n            active_node.children[S[active_edge]] ← split_node\n            split_node.children[S[next_node.start + active_length]] ← next_node\n            next_node.start ← next_node.start + active_length\n            split_node.children[S[i]] ← new SUFFIX-NODE\n\n            if last_new_node ≠ NIL:\n                last_new_node.suffix_link ← split_node\n\n            last_new_node ← split_node\n            remaining ← remaining - 1\n\n            if active_node = root and active_length > 0:\n                active_length ← active_length - 1\n                active_edge ← i - remaining + 1\n            else if active_node ≠ root:\n                active_node ← active_node.suffix_link\n\n    return root\n\n// Example:\n// Input: S = \"banana\"\n//\n// Suffix Tree:\n//         (root)\n//        /   |   \\\\\n//       b    a    n\n//      /     |     \\\\\n//     a      n      a\n//    /       |       \\\\\n//   n        a        n\n//  /         |         \\\\\n// a          n          a\n// |          |          |\n// $          a          $\n//            |\n//            n\n//            |\n//            a\n//            |\n//            $",
    "keySteps": [
      "Initialize: Create root node and active point",
      "Process: Add characters one by one",
      "Update: Maintain suffix links and active point"
    ]
  },
  "suffix-array": {
    "name": "Suffix Array",
    "type": "algorithm",
    "description": "Suffix Array is an algorithm with time complexity O(n log n). It is primarily used for efficient string operations",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Efficient string operations\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Efficient string operations\n    ",
    "useCase": "Efficient string operations\n    ",
    "pseudocode": "# Suffix Array: Efficient string operations\n# Input: String S[1..n]\n# Output: Suffix array SA[1..n] where SA[i] is starting index of i-th smallest suffix\n\nAlgorithm SUFFIX-ARRAY(S)\n    n ← length[S]\n    # Initialize suffix array with indices\n    SA ← array of size n\n    for i ← 1 to n do\n        SA[i] ← i\n    end for\n\n    # Sort suffixes based on first character\n    sort SA using S[SA[i]] as key\n\n    # Sort suffixes based on increasing length\n    for k ← 1 to n do\n        # Create equivalence classes\n        rank ← array of size n\n        rank[SA[1]] ← 0\n        for i ← 2 to n do\n            if S[SA[i]] = S[SA[i-1]] then\n                rank[SA[i]] ← rank[SA[i-1]]\n            else\n                rank[SA[i]] ← rank[SA[i-1]] + 1\n            end if\n        end for\n\n        # Sort suffixes based on first 2^k characters\n        temp ← array of size n\n        for i ← 1 to n do\n            temp[i] ← SA[i]\n        end for\n\n        for i ← 1 to n do\n            SA[i] ← temp[i]\n            if SA[i] > k then\n                SA[i] ← SA[i] - k\n            else\n                SA[i] ← SA[i] + n - k\n            end if\n        end for\n\n        # Update equivalence classes\n        new_rank ← array of size n\n        new_rank[SA[1]] ← 0\n        for i ← 2 to n do\n            if rank[SA[i]] = rank[SA[i-1]] and\n               rank[SA[i]+k] = rank[SA[i-1]+k] then\n                new_rank[SA[i]] ← new_rank[SA[i-1]]\n            else\n                new_rank[SA[i]] ← new_rank[SA[i-1]] + 1\n            end if\n        end for\n        rank ← new_rank\n    end for\n\n    return SA\n\n# Example:\n# Input: S = \"banana\"\n#\n# Step 1: SA = [1, 2, 3, 4, 5, 6]\n# Step 2: Sort by first character\n#         SA = [2, 1, 3, 5, 4, 6]\n# Step 3: Sort by first 2 characters\n#         SA = [2, 1, 3, 5, 4, 6]\n# Step 4: Sort by first 4 characters\n#         SA = [6, 4, 2, 1, 3, 5]\n#\n# Output: [6, 4, 2, 1, 3, 5]",
    "keySteps": [
      "Initialize suffix array with indices",
      "Sort suffixes based on first character",
      "Create and update equivalence classes",
      "Sort suffixes based on increasing length"
    ]
  },
  "strongly-connected-components": {
    "name": "Monster Territory Clusters",
    "type": "graph",
    "description": "Monster Territory Clusters is an algorithm with time complexity O(V + E). It is primarily used for find groups of territories where       monsters can freely move between any two areas",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find groups of territories where\n      monsters can freely move between any two areas\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find groups of territories where\n      monsters can freely move between any two areas\n    ",
    "useCase": "Find groups of territories where\n      monsters can freely move between any two areas\n    ",
    "pseudocode": "# Monster Territory Clusters: Find groups of interconnected monster territories\n# Input: G = (V, E) - directed graph of monster territories and migration paths\n# Output: List of territory clusters where monsters can freely move between any two areas\n\nAlgorithm FIND-TERRITORY-CLUSTERS(territory_graph)\n    # First DFS pass to get exploration times\n    for each territory t ∈ territory_graph\n        t.explored ← false\n        t.parent ← NIL\n    time ← 0\n    exploration_stack ← []\n    for each territory t ∈ territory_graph\n        if not t.explored\n            EXPLORE-TERRITORY(territory_graph, t, exploration_stack)\n\n    # Compute reverse migration paths\n    reverse_graph ← REVERSE-MIGRATION-PATHS(territory_graph)\n\n    # Second DFS pass in reverse order of exploration\n    for each territory t ∈ territory_graph\n        t.explored ← false\n        t.parent ← NIL\n    territory_clusters ← []\n    while exploration_stack is not empty\n        t ← exploration_stack.pop()\n        if not t.explored\n            cluster ← []\n            EXPLORE-TERRITORY(reverse_graph, t, cluster)\n            territory_clusters.append(cluster)\n\n    return territory_clusters\n\nAlgorithm EXPLORE-TERRITORY(graph, territory, result)\n    territory.explored ← true\n    for each connected_territory ∈ graph[territory]\n        if not connected_territory.explored\n            connected_territory.parent ← territory\n            EXPLORE-TERRITORY(graph, connected_territory, result)\n    result.append(territory)\n\nAlgorithm REVERSE-MIGRATION-PATHS(graph)\n    reverse_graph ← new Graph\n    for each territory t ∈ graph\n        reverse_graph[t] ← []\n    for each territory t ∈ graph\n        for each connected_territory ∈ graph[t]\n            reverse_graph[connected_territory].append(t)\n    return reverse_graph\n\n# Example:\n# Input: Territory Graph where\n# V = {Ancient Forest, Wildspire Waste, Coral Highlands, Elder's Recess, Rotten Vale}\n# E = {\n#   Ancient Forest → Wildspire Waste,\n#   Wildspire Waste → Coral Highlands,\n#   Coral Highlands → Ancient Forest,\n#   Coral Highlands → Elder's Recess,\n#   Elder's Recess → Rotten Vale,\n#   Rotten Vale → Wildspire Waste\n# }\n#\n# First DFS pass:\n# Ancient Forest: explored first\n# Wildspire Waste: explored second\n# Coral Highlands: explored third\n# Elder's Recess: explored fourth\n# Rotten Vale: explored last\n#\n# Second DFS pass on reverse graph:\n# Cluster 1: {Ancient Forest, Wildspire Waste, Coral Highlands}\n# Cluster 2: {Elder's Recess}\n# Cluster 3: {Rotten Vale}\n#\n# Output: [\n#   [\"Ancient Forest\", \"Wildspire Waste\", \"Coral Highlands\"],\n#   [\"Elder's Recess\"],\n#   [\"Rotten Vale\"]\n# ]",
    "keySteps": [
      "Explore territories to understand migration patterns",
      "Map reverse migration paths between territories",
      "Identify clusters where monsters can freely move between territories",
      "Use clusters to plan efficient hunting routes and predict monster movements"
    ]
  },
  "string-operations": {
    "name": "String Operations",
    "type": "string",
    "description": "String Operations is an algorithm with time complexity O(n). It is primarily used for string manipulation",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: String manipulation\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: String manipulation\n    ",
    "useCase": "String manipulation\n    ",
    "pseudocode": "// Common String Operations\nCONCATENATE(s1, s2):\n  return s1 + s2\n\nSUBSTRING(s, start, end):\n  return s[start..end]\n\nCHAR_AT(s, index):\n  return s[index]\n\nLENGTH(s):\n  return s.length\n\nCOMPARE(s1, s2):\n  return s1 == s2\n\nFIND(s, pattern):\n  return s.indexOf(pattern)\n\nREPLACE(s, old, new):\n  return s.replace(old, new)\n\nSPLIT(s, delimiter):\n  return s.split(delimiter)\n\nJOIN(arr, delimiter):\n  return arr.join(delimiter)\n\nTRIM(s):\n  return s.trim()\n\nTO_UPPER(s):\n  return s.toUpperCase()\n\nTO_LOWER(s):\n  return s.toLowerCase()",
    "keySteps": []
  },
  "string-hashing": {
    "name": "String Hashing",
    "type": "string",
    "description": "String Hashing is an algorithm with time complexity O(n). It is primarily used for fast string comparison and pattern       matching",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Fast string comparison and pattern\n      matching\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Fast string comparison and pattern\n      matching\n    ",
    "useCase": "Fast string comparison and pattern\n      matching\n    ",
    "pseudocode": "# String Hashing: Efficient string comparison using rolling hash\n# Input: String s[1..n], base b, modulus m\n# Output: Hash value of string\n\nAlgorithm ROLLING-HASH(s, b, m)\n    hash ← 0\n    power ← 1\n    for i ← 1 to length[s] do\n        hash ← (hash + (s[i] - 'a' + 1) · power) mod m\n        power ← (power · b) mod m\n    end for\n    return hash\n\nAlgorithm SUBSTRING-HASH(s, start, len, b, m)\n    hash ← 0\n    power ← 1\n    for i ← start to start + len - 1 do\n        hash ← (hash + (s[i] - 'a' + 1) · power) mod m\n        power ← (power · b) mod m\n    end for\n    return hash\n\n# Example:\n# Input: s = \"hello\", b = 31, m = 10^9 + 7\n#\n# ROLLING-HASH(\"hello\", 31, 10^9 + 7) = 99162322\n# SUBSTRING-HASH(\"hello\", 2, 3, 31, 10^9 + 7) = 297486966  # Hash of \"ell\"",
    "keySteps": [
      "O(1) comparison of strings",
      "Low collision probability with good parameters",
      "Useful for Rabin-Karp and other string algorithms"
    ]
  },
  "state-compression-dp": {
    "name": "State Compression DP",
    "type": "dynamic-programming",
    "description": "State Compression DP is an algorithm with time complexity O(n * 2^m). It is primarily used for solve problems with state       represented as bits",
    "timeComplexity": "O(n * 2^m) &nbsp;|&nbsp; Space: O(2^m) &nbsp;|&nbsp; Use: Solve problems with state\n      represented as bits\n    ",
    "spaceComplexity": "O(2^m) &nbsp;|&nbsp; Use: Solve problems with state\n      represented as bits\n    ",
    "useCase": "Solve problems with state\n      represented as bits\n    ",
    "pseudocode": "# State Compression DP: Solve problems with state represented as bits\n# Input: Grid G[1..n][1..m]\n# Output: Maximum value achievable\n\nAlgorithm STATE-COMPRESSION-DP(G)\n    n ← rows[G]\n    m ← cols[G]\n    # Initialize DP table\n    dp ← array of size 2^m\n    for i ← 0 to 2^m - 1 do\n        dp[i] ← -∞\n    end for\n    dp[0] ← 0\n\n    # Process each row\n    for i ← 1 to n do\n        # Initialize current row's DP\n        curr ← array of size 2^m\n        for j ← 0 to 2^m - 1 do\n            curr[j] ← -∞\n        end for\n\n        # Try all possible states\n        for prev ← 0 to 2^m - 1 do\n            if dp[prev] = -∞ then\n                continue\n            end if\n\n            # Try all possible current states\n            for curr_state ← 0 to 2^m - 1 do\n                # Check if current state is valid\n                valid ← true\n                for j ← 0 to m - 1 do\n                    if (curr_state & (1 << j)) ≠ 0 then\n                        if G[i][j+1] = 0 then\n                            valid ← false\n                            break\n                        end if\n                        if j > 0 and (curr_state & (1 << (j-1))) ≠ 0 then\n                            valid ← false\n                            break\n                        end if\n                    end if\n                end for\n\n                if valid then\n                    # Calculate value for current state\n                    value ← 0\n                    for j ← 0 to m - 1 do\n                        if (curr_state & (1 << j)) ≠ 0 then\n                            value ← value + G[i][j+1]\n                        end if\n                    end for\n\n                    # Update DP\n                    curr[curr_state] ← max(curr[curr_state], dp[prev] + value)\n                end if\n            end for\n        end for\n\n        dp ← curr\n    end for\n\n    return max(dp)\n\n# Example:\n# Input: G = [[1, 2, 3],\n#             [4, 5, 6],\n#             [7, 8, 9]]\n#\n# Step 1: dp = [0, -∞, -∞, -∞, -∞, -∞, -∞, -∞]\n# Step 2: Process first row\n#         curr = [0, 1, 2, 3, -∞, -∞, -∞, -∞]\n# Step 3: Process second row\n#         curr = [0, 4, 5, 9, -∞, -∞, -∞, -∞]\n# Step 4: Process third row\n#         curr = [0, 7, 8, 15, -∞, -∞, -∞, -∞]\n#\n# Output: 15",
    "keySteps": [
      "Initialize DP table with bit states",
      "Process each row of the grid",
      "Check validity of current state",
      "Update DP with maximum value"
    ]
  },
  "stack": {
    "name": "Stack",
    "type": "data-structures",
    "description": "A linear data structure that follows Last-In-First-Out (LIFO) principle",
    "timeComplexity": "O(1) for push, pop, and peek operations",
    "spaceComplexity": "O(n) for storing n elements",
    "useCase": "Function call stack, expression evaluation, backtracking algorithms",
    "pseudocode": "# Stack: LIFO (Last-In-First-Out) data structure\n# Input: Elements to be pushed onto stack\n# Output: Elements popped from stack in reverse order\n\nAlgorithm STACK-OPERATIONS\n    # Initialize empty stack\n    S ← empty array\n    top ← 0\n\n    # Push element x onto stack\n    Algorithm PUSH(S, x)\n        top ← top + 1\n        S[top] ← x\n\n    # Pop element from stack\n    Algorithm POP(S)\n        if top = 0 then\n            return \"underflow\"\n        end if\n        x ← S[top]\n        top ← top - 1\n        return x\n\n    # Check if stack is empty\n    Algorithm STACK-EMPTY(S)\n        if top = 0 then\n            return true\n        else\n            return false\n        end if\n\n    # Peek at top element\n    Algorithm PEEK(S)\n        if top = 0 then\n            return \"empty\"\n        end if\n        return S[top]\n\n# Example:\n# Input: Push sequence [1, 2, 3]\n#\n# Step 1: PUSH(S, 1)\n#         S = [1], top = 1\n# Step 2: PUSH(S, 2)\n#         S = [1, 2], top = 2\n# Step 3: PUSH(S, 3)\n#         S = [1, 2, 3], top = 3\n# Step 4: POP(S)\n#         Returns 3, S = [1, 2], top = 2\n# Step 5: PEEK(S)\n#         Returns 2\n#\n# Output: Elements popped in order [3, 2, 1]",
    "keySteps": [
      "PUSH: Add element to top of stack in O(1) time",
      "POP: Remove and return top element in O(1) time",
      "STACK-EMPTY: Check if stack is empty in O(1) time",
      "PEEK: View top element without removal in O(1) time"
    ]
  },
  "stack-sort": {
    "name": "Stack Sort",
    "type": "data-structures",
    "description": "Stack Sort is an algorithm with time complexity O(n²). It is primarily used for sort using stack operations",
    "timeComplexity": "O(n²) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Sort using stack operations\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Sort using stack operations\n    ",
    "useCase": "Sort using stack operations\n    ",
    "pseudocode": "// Sort array using stack operations\nSTACK-SORT(A):\n    n ← length[A]\n    S ← empty stack\n    T ← empty stack\n    // Push all elements to first stack\n    for i ← 1 to n:\n        PUSH(S, A[i])\n    // Sort elements using two stacks\n    while S not empty:\n        temp ← POP(S)\n        while T not empty and TOP(T) > temp:\n            PUSH(S, POP(T))\n        PUSH(T, temp)\n    // Transfer sorted elements back to array\n    for i ← n downto 1:\n        A[i] ← POP(T)\n    return A\n\n// Example:\n// Input: A = [5, 2, 4, 6, 1, 3]\n//\n// Execution:\n// 1. Initial push: S = [5, 2, 4, 6, 1, 3], T = []\n// 2. After first iteration: S = [5, 2, 4, 6], T = [1, 3]\n// 3. After second iteration: S = [5, 2, 4], T = [1, 3, 6]\n// 4. After third iteration: S = [5, 2], T = [1, 3, 4, 6]\n// 5. After fourth iteration: S = [5], T = [1, 2, 3, 4, 6]\n// 6. After fifth iteration: S = [], T = [1, 2, 3, 4, 5, 6]\n//\n// Output: [1, 2, 3, 4, 5, 6]",
    "keySteps": [
      "Initialize: Create two empty stacks",
      "Sort: Use second stack to maintain sorted order",
      "Transfer: Move sorted elements back to array"
    ]
  },
  "stack-implementation": {
    "name": "Stack Implementation",
    "type": "data-structures",
    "description": "Stack Implementation is an algorithm with time complexity O(1). It is primarily used for lifo data structure",
    "timeComplexity": "O(1) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: LIFO data structure\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: LIFO data structure\n    ",
    "useCase": "LIFO data structure\n    ",
    "pseudocode": "STACK-EMPTY(S)\n    if S.top = 0\n        then return true\n        else return false\n\nPUSH(S, x)\n    if S.top = S.size\n        then error \"stack overflow\"\n    S.top ← S.top + 1\n    S[S.top] ← x\n\nPOP(S)\n    if STACK-EMPTY(S)\n        then error \"stack underflow\"\n    S.top ← S.top - 1\n    return S[S.top + 1]\n\n// Example:\n// Input: Operations [PUSH(10), PUSH(20), POP(), PUSH(30), PUSH(40)]\n//\n// Initial state:\n//   S = []\n//   S.top = 0\n//\n// After PUSH(10):\n//   S = [10]\n//   S.top = 1\n//\n// After PUSH(20):\n//   S = [10, 20]\n//   S.top = 2\n//\n// After POP():\n//   S = [10]\n//   S.top = 1\n//   Returns: 20\n//\n// After PUSH(30):\n//   S = [10, 30]\n//   S.top = 2\n//\n// After PUSH(40):\n//   S = [10, 30, 40]\n//   S.top = 3\n//\n// Final state:\n//   S = [10, 30, 40]\n//   S.top = 3",
    "keySteps": [
      "Initialize: Create array and top pointer",
      "Push: Add element and increment top pointer",
      "Pop: Remove element and decrement top pointer"
    ]
  },
  "sparse-table": {
    "name": "Sparse Table",
    "type": "tree",
    "description": "Sparse Table is an algorithm with time complexity O(1). It is primarily used for range       minimum/maximum queries",
    "timeComplexity": "O(1) query, O(n log n) build &nbsp;|&nbsp; Space: O(n log n) &nbsp;|&nbsp; Use: Range\n      minimum/maximum queries\n    ",
    "spaceComplexity": "O(n log n) &nbsp;|&nbsp; Use: Range\n      minimum/maximum queries\n    ",
    "useCase": "Range\n      minimum/maximum queries\n    ",
    "pseudocode": "// Build sparse table\nBUILD-SPARSE-TABLE(A, n):\n  k = floor(log₂(n))\n  st = new array[n][k+1]\n  \n  // Initialize first column\n  for i = 0 to n-1:\n    st[i][0] = A[i]\n  \n  // Fill remaining columns\n  for j = 1 to k:\n    for i = 0 to n-2^j:\n      st[i][j] = min(st[i][j-1], st[i+2^(j-1)][j-1])\n  return st\n\n// Query minimum in range [L, R]\nQUERY-MIN(st, L, R):\n  j = floor(log₂(R-L+1))\n  return min(st[L][j], st[R-2^j+1][j])\n\n// Example usage\nA = [4, 2, 3, 7, 1, 5, 3, 3, 9, 6, 7, 1, 2, 4, 5]\nst = BUILD-SPARSE-TABLE(A, 15)\nmin_val = QUERY-MIN(st, 2, 7)  // Returns minimum in range [2,7]",
    "keySteps": [
      "O(1) query time for range minimum/maximum",
      "Static data structure (no updates)",
      "Can be extended for other range queries"
    ]
  },
  "sorting-quicksort": {
    "name": "Quick Sort",
    "type": "sorting",
    "description": "Quick Sort is an algorithm with time complexity O(n log n). It is primarily used for efficient       general-purpose sorting",
    "timeComplexity": "O(n log n) avg, O(n²) worst &nbsp;|&nbsp; Space: O(log n) &nbsp;|&nbsp; Use: Efficient\n      general-purpose sorting\n    ",
    "spaceComplexity": "O(log n) &nbsp;|&nbsp; Use: Efficient\n      general-purpose sorting\n    ",
    "useCase": "Efficient\n      general-purpose sorting\n    ",
    "pseudocode": "QUICKSORT(A, p, r):\n    if p < r:\n        q ← PARTITION(A, p, r)\n        QUICKSORT(A, p, q-1)\n        QUICKSORT(A, q+1, r)\n\nPARTITION(A, p, r):\n    x ← A[r]    // pivot\n    i ← p - 1\n    for j ← p to r-1:\n        if A[j] ≤ x:\n            i ← i + 1\n            exchange A[i] with A[j]\n    exchange A[i+1] with A[r]\n    return i + 1\n\n// Example:\n// Input: A = [3, 7, 8, 5, 2, 1, 9, 5, 4]\n//\n// First partition (pivot = 4):\n// [3, 2, 1, 4, 7, 8, 9, 5, 5]\n//\n// Recursive calls:\n// Left: [3, 2, 1]\n// Right: [7, 8, 9, 5, 5]\n//\n// Final result: [1, 2, 3, 4, 5, 5, 7, 8, 9]",
    "keySteps": [
      "Choose pivot element (usually last element)",
      "Partition array around pivot",
      "Recursively sort subarrays",
      "Use median-of-three for pivot selection"
    ]
  },
  "sorting-mergesort": {
    "name": "Merge Sort",
    "type": "sorting",
    "description": "Merge Sort is an algorithm with time complexity O(n log n). It is primarily used for stable sorting with guaranteed       performance",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Stable sorting with guaranteed\n      performance\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Stable sorting with guaranteed\n      performance\n    ",
    "useCase": "Stable sorting with guaranteed\n      performance\n    ",
    "pseudocode": "MERGESORT(A, p, r):\n    if p < r:\n        q ← ⌊(p + r) / 2⌋\n        MERGESORT(A, p, q)\n        MERGESORT(A, q + 1, r)\n        MERGE(A, p, q, r)\n\nMERGE(A, p, q, r):\n    n₁ ← q - p + 1\n    n₂ ← r - q\n    let L[1..n₁ + 1] and R[1..n₂ + 1] be new arrays\n    for i ← 1 to n₁:\n        L[i] ← A[p + i - 1]\n    for j ← 1 to n₂:\n        R[j] ← A[q + j]\n    L[n₁ + 1] ← ∞\n    R[n₂ + 1] ← ∞\n    i ← 1\n    j ← 1\n    for k ← p to r:\n        if L[i] ≤ R[j]:\n            A[k] ← L[i]\n            i ← i + 1\n        else:\n            A[k] ← R[j]\n            j ← j + 1\n\n// Example:\n// Input: A = [3, 7, 8, 5, 2, 1, 9, 5, 4]\n//\n// First split:\n// Left: [3, 7, 8, 5]\n// Right: [2, 1, 9, 5, 4]\n//\n// Recursive splits:\n// [3, 7] [8, 5] [2, 1] [9, 5, 4]\n//\n// Merge steps:\n// [3, 7] [5, 8] [1, 2] [4, 5, 9]\n// [3, 5, 7, 8] [1, 2, 4, 5, 9]\n// [1, 2, 3, 4, 5, 5, 7, 8, 9]",
    "keySteps": [
      "Divide array into two halves",
      "Recursively sort each half",
      "Merge sorted halves",
      "Stable sorting algorithm"
    ]
  },
  "sorting-heapsort": {
    "name": "Heap Sort",
    "type": "sorting",
    "description": "Heap Sort is an algorithm with time complexity O(n log n). It is primarily used for in-place sorting with guaranteed       performance",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: In-place sorting with guaranteed\n      performance\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: In-place sorting with guaranteed\n      performance\n    ",
    "useCase": "In-place sorting with guaranteed\n      performance\n    ",
    "pseudocode": "HEAPSORT(A):\n    BUILD-MAX-HEAP(A)\n    for i ← length[A] downto 2:\n        exchange A[1] with A[i]\n        heap-size[A] ← heap-size[A] - 1\n        MAX-HEAPIFY(A, 1)\n\nBUILD-MAX-HEAP(A):\n    heap-size[A] ← length[A]\n    for i ← ⌊length[A]/2⌋ downto 1:\n        MAX-HEAPIFY(A, i)\n\nMAX-HEAPIFY(A, i):\n    l ← LEFT(i)\n    r ← RIGHT(i)\n    if l ≤ heap-size[A] and A[l] > A[i]:\n        largest ← l\n    else:\n        largest ← i\n    if r ≤ heap-size[A] and A[r] > A[largest]:\n        largest ← r\n    if largest ≠ i:\n        exchange A[i] with A[largest]\n        MAX-HEAPIFY(A, largest)\n\nLEFT(i):\n    return 2i\n\nRIGHT(i):\n    return 2i + 1\n\n// Example:\n// Input: A = [3, 7, 8, 5, 2, 1, 9, 5, 4]\n//\n// Build max heap:\n//        9\n//      /   \\\\\n//     7     8\n//    / \\\\   / \\\\\n//   5   2 1   5\n//  / \\\\\n// 3   4\n//\n// Extract max and heapify:\n// [9, 8, 7, 5, 5, 4, 3, 2, 1]",
    "keySteps": [
      "Build max heap from array",
      "Extract maximum element",
      "Maintain heap property",
      "In-place sorting algorithm"
    ]
  },
  "sorting-comparisons": {
    "name": "Sorting Comparisons",
    "type": "Sorting",
    "description": "Sorting Comparisons is an algorithm with time complexity O(n log n). It is primarily used for comparing and analyzing sorting       algorithms",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Comparing and analyzing sorting\n      algorithms\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Comparing and analyzing sorting\n      algorithms\n    ",
    "useCase": "Comparing and analyzing sorting\n      algorithms\n    ",
    "pseudocode": "// Comparison-based sorting algorithms\nQUICK-SORT(A, p, r):\n  if p < r:\n    q = PARTITION(A, p, r)\n    QUICK-SORT(A, p, q-1)\n    QUICK-SORT(A, q+1, r)\n\nMERGE-SORT(A, p, r):\n  if p < r:\n    q = floor((p + r) / 2)\n    MERGE-SORT(A, p, q)\n    MERGE-SORT(A, q+1, r)\n    MERGE(A, p, q, r)\n\nHEAP-SORT(A):\n  BUILD-MAX-HEAP(A)\n  for i = length[A] downto 2:\n    exchange A[1] with A[i]\n    heap-size[A] = heap-size[A] - 1\n    MAX-HEAPIFY(A, 1)",
    "keySteps": [
      "All comparison-based sorts have Ω(n log n) lower bound",
      "Choose based on data characteristics and requirements",
      "Hybrid approaches (e.g., Timsort) combine strengths"
    ]
  },
  "sliding-window": {
    "name": "Sliding Window",
    "type": "algorithm",
    "description": "A technique for efficiently processing arrays by maintaining a window of elements",
    "timeComplexity": "O(n) where n is the array length",
    "spaceComplexity": "O(1) for fixed-size window problems",
    "useCase": "Finding subarrays with specific properties, string pattern matching, array optimization\n      ",
    "pseudocode": "# Sliding Window: Find subarrays with specific properties\n# Input: Array A[1..n], window size k\n# Output: Maximum sum of any subarray of size k\n\nAlgorithm SLIDING-WINDOW(A, k)\n    n ← length[A]\n    if n < k then\n        return -1\n    end if\n\n    # Compute sum of first window\n    window_sum ← 0\n    for i ← 1 to k do\n        window_sum ← window_sum + A[i]\n    end for\n    max_sum ← window_sum\n\n    # Slide window and update sum\n    for i ← k + 1 to n do\n        window_sum ← window_sum + A[i] - A[i - k]\n        max_sum ← max(max_sum, window_sum)\n    end for\n\n    return max_sum\n\n# Example:\n# Input: A = [1, 4, 2, 10, 2, 3, 1, 0, 20], k = 4\n#\n# Step 1: window_sum = 1 + 4 + 2 + 10 = 17\n#         max_sum = 17\n# Step 2: window_sum = 17 + 2 - 1 = 18\n#         max_sum = 18\n# Step 3: window_sum = 18 + 3 - 4 = 17\n#         max_sum = 18\n# Step 4: window_sum = 17 + 1 - 2 = 16\n#         max_sum = 18\n# Step 5: window_sum = 16 + 0 - 10 = 6\n#         max_sum = 18\n# Step 6: window_sum = 6 + 20 - 2 = 24\n#         max_sum = 24\n#\n# Output: 24",
    "keySteps": [
      "Initialize window sum and maximum sum variables",
      "Compute sum of the first window of size k",
      "Slide window by adding new element and removing oldest",
      "Update maximum sum when a larger sum is found"
    ]
  },
  "sieve-of-sundaram": {
    "name": "Sieve of Sundaram",
    "type": "number-theory",
    "description": "An alternative to the Sieve of Eratosthenes that generates odd composite numbers",
    "timeComplexity": "O(n log n) where n is the upper limit",
    "spaceComplexity": "O(n/2) for storing odd numbers up to n",
    "useCase": "Finding prime numbers, especially when memory is limited",
    "pseudocode": "# Sieve of Sundaram\n# Input: Integer n > 1\n# Output: Array of primes ≤ n\n\nAlgorithm SIEVE-OF-SUNDARAM(n)\n    # Initialize array\n    k ← (n - 1) // 2\n    is_prime ← array of size k + 1\n    for i ← 1 to k do\n        is_prime[i] ← true\n    end for\n\n    # Mark numbers of form i + j + 2ij\n    for i ← 1 to k do\n        j ← i\n        while i + j + 2*i*j ≤ k do\n            is_prime[i + j + 2*i*j] ← false\n            j ← j + 1\n        end while\n    end for\n\n    # Collect primes\n    primes ← [2]  # 2 is the only even prime\n    for i ← 1 to k do\n        if is_prime[i] then\n            primes.append(2*i + 1)\n        end if\n    end for\n\n    return primes\n\n# Example:\n# Input: n = 30\n#\n# Step 1: k = (30 - 1) // 2 = 14\n#         is_prime = [T, T, T, T, T, T, T, T, T, T, T, T, T, T, T]\n#\n# Step 2: Mark numbers\n#         i = 1: mark 4, 7, 10, 13\n#         i = 2: mark 7, 12\n#         i = 3: mark 10\n#         i = 4: mark 13\n#\n# Step 3: Collect primes\n#         primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\n#\n# Output: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]",
    "keySteps": [
      "Initialize array for odd numbers up to n/2",
      "Mark numbers of form i + j + 2ij as composite",
      "Collect remaining unmarked numbers as potential primes",
      "Transform indices to get actual prime numbers"
    ]
  },
  "sieve-of-eratosthenes": {
    "name": "Sieve of Eratosthenes",
    "type": "algorithm",
    "description": "An efficient algorithm to find all prime numbers up to a given limit",
    "timeComplexity": "O(n log log n) where n is the upper limit",
    "spaceComplexity": "O(n) for storing the boolean array",
    "useCase": "Finding prime numbers, prime factorization, number theory problems",
    "pseudocode": "# Sieve of Eratosthenes: Find all primes up to n\n# Input: Integer n > 1\n# Output: Array of primes ≤ n\n\nAlgorithm SIEVE-OF-ERATOSTHENES(n)\n    # Initialize array of booleans\n    is_prime ← array of size n + 1\n    for i ← 2 to n do\n        is_prime[i] ← true\n    end for\n\n    # Mark multiples of primes\n    for i ← 2 to √n do\n        if is_prime[i] then\n            for j ← i² to n step i do\n                is_prime[j] ← false\n            end for\n        end if\n    end for\n\n    # Collect primes\n    primes ← empty array\n    for i ← 2 to n do\n        if is_prime[i] then\n            primes.append(i)\n        end if\n    end for\n\n    return primes\n\n# Example:\n# Input: n = 30\n#\n# Step 1: is_prime = [F, F, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T]\n# Step 2: i = 2, mark multiples of 2\n#         is_prime = [F, F, T, T, F, T, F, T, F, T, F, T, F, T, F, T, F, T, F, T, F, T, F, T, F, T, F, T, F, T, F]\n# Step 3: i = 3, mark multiples of 3\n#         is_prime = [F, F, T, T, F, T, F, T, F, F, F, T, F, T, F, F, F, T, F, T, F, F, F, T, F, T, F, F, F, T, F]\n# Step 4: i = 5, mark multiples of 5\n#         is_prime = [F, F, T, T, F, T, F, T, F, F, F, T, F, T, F, F, F, T, F, T, F, F, F, T, F, T, F, F, F, T, F]\n#\n# Output: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]",
    "keySteps": [
      "Initialize array of booleans for all numbers up to n",
      "Mark multiples of each prime number as non-prime",
      "Collect remaining unmarked numbers as primes",
      "Return the array of prime numbers"
    ]
  },
  "sieve-of-atkin": {
    "name": "Sieve of Atkin",
    "type": "number-theory",
    "description": "Sieve of Atkin is an algorithm with time complexity O(n/log log n). It is primarily used for find all primes up to n",
    "timeComplexity": "O(n/log log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Find all primes up to n\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Find all primes up to n\n    ",
    "useCase": "Find all primes up to n\n    ",
    "pseudocode": "# Sieve of Atkin\n# Input: Integer n > 1\n# Output: Array of primes ≤ n\n\nAlgorithm SIEVE-OF-ATKIN(n)\n    # Initialize array\n    is_prime ← array of size n + 1\n    for i ← 0 to n do\n        is_prime[i] ← false\n    end for\n\n    # Mark potential primes\n    for x ← 1 to √n do\n        for y ← 1 to √n do\n            # Case 1: 4x² + y²\n            k ← 4*x*x + y*y\n            if k ≤ n and (k mod 12 = 1 or k mod 12 = 5) then\n                is_prime[k] ← not is_prime[k]\n            end if\n\n            # Case 2: 3x² + y²\n            k ← 3*x*x + y*y\n            if k ≤ n and k mod 12 = 7 then\n                is_prime[k] ← not is_prime[k]\n            end if\n\n            # Case 3: 3x² - y²\n            k ← 3*x*x - y*y\n            if x > y and k ≤ n and k mod 12 = 11 then\n                is_prime[k] ← not is_prime[k]\n            end if\n        end for\n    end for\n\n    # Mark squares of primes as non-prime\n    for i ← 5 to √n do\n        if is_prime[i] then\n            for j ← i*i to n step i*i do\n                is_prime[j] ← false\n            end for\n        end if\n    end for\n\n    # Collect primes\n    primes ← [2, 3]\n    for i ← 5 to n do\n        if is_prime[i] then\n            primes.append(i)\n        end if\n    end for\n\n    return primes\n\n# Example:\n# Input: n = 30\n#\n# Step 1: Initialize array\n#         is_prime = [F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F]\n#\n# Step 2: Mark potential primes\n#         x = 1, y = 1: k = 5, 4, 2\n#         x = 2, y = 1: k = 17, 13, 11\n#         x = 2, y = 2: k = 20, 16, 8\n#         ...\n#\n# Step 3: Mark squares\n#         i = 5: mark 25\n#\n# Step 4: Collect primes\n#         primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\n#\n# Output: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]",
    "keySteps": [
      "Initialize array for potential primes",
      "Mark numbers using quadratic forms",
      "Mark squares of primes as non-prime",
      "Collect remaining primes"
    ]
  },
  "shell-sort": {
    "name": "Shell Sort",
    "type": "algorithm",
    "description": "An optimization of insertion sort that allows the exchange of items that are far apart",
    "timeComplexity": "O(n log² n) average case, depends on gap sequence",
    "spaceComplexity": "O(1) in-place sorting algorithm",
    "useCase": "Optimized insertion sort with gap sequence, good for medium-sized arrays",
    "pseudocode": "# Shell Sort: An optimization of insertion sort using gap sequence\n# Input: Array A[1..n]\n# Output: Sorted array A\n\nAlgorithm SHELL-SORT(A)\n    n ← length[A]\n    \n    # Start with a large gap, then reduce it\n    gap ← ⌊n/2⌋\n    \n    while gap > 0 do\n        # Do insertion sort for elements at positions i, i+gap, i+2*gap, ...\n        for i ← gap + 1 to n do\n            temp ← A[i]\n            j ← i\n            \n            # Shift earlier gap-sorted elements up until correct location\n            while j ≥ gap and A[j - gap] > temp do\n                A[j] ← A[j - gap]\n                j ← j - gap\n            end while\n            \n            # Put temp in its correct location\n            A[j] ← temp\n        end for\n        \n        # Reduce the gap\n        gap ← ⌊gap/2⌋\n    end while\n\n# Example:\n# Input: A = [12, 34, 54, 2, 3]\n#\n# Step 1: gap = 2\n# [12, 34, 54, 2, 3] → [12, 2, 54, 34, 3]\n#\n# Step 2: gap = 1\n# [12, 2, 54, 34, 3] → [2, 3, 12, 34, 54]",
    "keySteps": [
      "Initialize gap sequence starting with n/2",
      "Perform insertion sort on elements separated by gap",
      "Reduce gap size and repeat until gap is 1",
      "Final pass with gap=1 is a standard insertion sort"
    ]
  },
  "selection-sort": {
    "name": "Selection Sort",
    "type": "sorting",
    "description": "Selection Sort is an algorithm with time complexity O(n²). It is primarily used for sorting array in-place",
    "timeComplexity": "O(n²) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Sorting array in-place\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Sorting array in-place\n    ",
    "useCase": "Sorting array in-place\n    ",
    "pseudocode": "SELECTION-SORT(A)\n    n ← length[A]\n\n    for i ← 1 to n-1\n        # Find minimum in unsorted part\n        min_idx ← i\n        for j ← i+1 to n\n            if A[j] < A[min_idx]\n                min_idx ← j\n\n        # Swap with first unsorted element\n        swap A[i] and A[min_idx]\n\n# Example:\n# Input: A = [5, 2, 4, 6, 1, 3]\n# After each iteration:\n# [1, 2, 4, 6, 5, 3]  # 1 is selected\n# [1, 2, 4, 6, 5, 3]  # 2 is selected\n# [1, 2, 3, 6, 5, 4]  # 3 is selected\n# [1, 2, 3, 4, 5, 6]  # 4 is selected\n# [1, 2, 3, 4, 5, 6]  # 5 is selected\n# Output: [1, 2, 3, 4, 5, 6]",
    "keySteps": [
      "Find: Minimum element in unsorted part",
      "Swap: With first unsorted element",
      "Repeat: Until array is sorted"
    ]
  },
  "segment-tree": {
    "name": "Segment Tree",
    "type": "tree",
    "description": "Segment Tree is an algorithm with time complexity O(log n). It is primarily used for range queries and updates",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Range queries and updates\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Range queries and updates",
    "pseudocode": "// Build segment tree\n\nSEGMENT-TREE-BUILD(A, v, tl, tr)\n    if tl = tr then\n        T[v] ← A[tl]\n    else\n        tm ← ⌊(tl + tr)/2⌋\n        SEGMENT-TREE-BUILD(A, 2*v, tl, tm)\n        SEGMENT-TREE-BUILD(A, 2*v+1, tm+1, tr)\n        T[v] ← T[2*v] + T[2*v+1]\n    end if\n\n//Query range sum\nSEGMENT-TREE-QUERY(v, tl, tr, l, r)\n    if l > r then\n        return 0\n    end if\n    if l = tl and r = tr then\n        return T[v]\n    end if\n    tm ← ⌊(tl + tr)/2⌋\n    return SEGMENT-TREE-QUERY(2*v, tl, tm, l, min(r, tm)) +\n           SEGMENT-TREE-QUERY(2*v+1, tm+1, tr, max(l, tm+1), r)\n\n// Update value at index\nSEGMENT-TREE-UPDATE(v, tl, tr, pos, new_val)\n    if tl = tr then\n        T[v] ← new_val\n    else\n        tm ← ⌊(tl + tr)/2⌋\n        if pos ≤ tm then\n            SEGMENT-TREE-UPDATE(2*v, tl, tm, pos, new_val)\n        else\n            SEGMENT-TREE-UPDATE(2*v+1, tm+1, tr, pos, new_val)\n        end if\n        T[v] ← T[2*v] + T[2*v+1]\n    end if\n\n// Lazy update\nSEGMENT-TREE-LAZY-UPDATE(v, tl, tr, l, r, addend)\n    PUSH(v, tl, tr)\n    if l > r then\n        return\n    end if\n    if l = tl and r = tr then\n        lazy[v] ← lazy[v] + addend\n        PUSH(v, tl, tr)\n    else\n        tm ← ⌊(tl + tr)/2⌋\n        SEGMENT-TREE-LAZY-UPDATE(2*v, tl, tm, l, min(r, tm), addend)\n        SEGMENT-TREE-LAZY-UPDATE(2*v+1, tm+1, tr, max(l, tm+1), r, addend)\n        T[v] ← T[2*v] + T[2*v+1]\n    end if\n\n// Push operation for lazy propagation\nPUSH(v, tl, tr)\n    if lazy[v] ≠ 0 then\n        T[v] ← T[v] + lazy[v] * (tr - tl + 1)\n        if tl ≠ tr then\n            lazy[2*v] ← lazy[2*v] + lazy[v]\n            lazy[2*v+1] ← lazy[2*v+1] + lazy[v]\n        end if\n        lazy[v] ← 0\n    end if\n\n// Example:\n// Input: A = [1, 3, -2, 8, -7]\n//\n// Build tree:\n//       3\n//     /   \\\n//   2      1\n//  / \\    / \\\n// 1   3  -2  1\n//1 3 -2 8 -7 0 0 0\n//\n// Query [1,3]: 3 + (-2) + 8 = 9\n// Update pos 2 to 5: [1, 3, 5, 8, -7]\n// Range update [1,3] add 2: [1, 5, 7, 10, -7]",
    "useCase": "Efficient range queries and updates on arrays, such as range sum, minimum/maximum, and dynamic statistics",
    "keySteps": [
      "Recursively build the segment tree from the input array",
      "Query the tree for a range by combining relevant segments",
      "Update a value or range and propagate changes up the tree",
      "Use lazy propagation for efficient range updates (if needed)"
    ]
  },
  "rotate-matrix": {
    "name": "Matrix Operations",
    "type": "array",
    "description": "Matrix Operations is an algorithm with time complexity O(n²). It is primarily used for matrix transformations and operations",
    "timeComplexity": "O(n²) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Matrix transformations and operations\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Matrix transformations and operations\n    ",
    "useCase": "Matrix transformations and operations\n    ",
    "pseudocode": "ROTATE-CLOCKWISE(A)\n1  n = A.rows\n2  // Transpose the matrix\n3  for i = 1 to n\n4      for j = i to n\n5          exchange A[i][j] with A[j][i]\n6  // Reverse each row\n7  for i = 1 to n\n8      for j = 1 to n/2\n9          exchange A[i][j] with A[i][n-j+1]\n10 return A\n\nROTATE-COUNTERCLOCKWISE(A)\n1  n = A.rows\n2  // Transpose the matrix\n3  for i = 1 to n\n4      for j = i to n\n5          exchange A[i][j] with A[j][i]\n6  // Reverse each column\n7  for j = 1 to n\n8      for i = 1 to n/2\n9          exchange A[i][j] with A[n-i+1][j]\n10 return A\n\n// Example:\n// Input: A = [[1, 2, 3],\n//             [4, 5, 6],\n//             [7, 8, 9]]\n//\n// Clockwise rotation:\n// Step 1: Transpose\n//         [[1, 4, 7],\n//          [2, 5, 8],\n//          [3, 6, 9]]\n// Step 2: Reverse rows\n//         [[7, 4, 1],\n//          [8, 5, 2],\n//          [9, 6, 3]]\n//\n// Counterclockwise rotation:\n// Step 1: Transpose\n//         [[1, 4, 7],\n//          [2, 5, 8],\n//          [3, 6, 9]]\n// Step 2: Reverse columns\n//         [[3, 6, 9],\n//          [2, 5, 8],\n//          [1, 4, 7]]",
    "keySteps": []
  },
  "red-black-tree": {
    "name": "Red-Black Tree",
    "type": "tree",
    "description": "Red-Black Tree is an algorithm with time complexity O(log n). It is primarily used for self-balancing binary search tree",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Self-balancing binary search tree\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Self-balancing binary search tree\n    ",
    "useCase": "Self-balancing binary search tree\n    ",
    "pseudocode": "RB-INSERT(T, z)\n    let y ← null\n    let x ← T.root\n\n    while x ≠ null\n        do y ← x\n           if z.key < x.key\n               then x ← x.left\n               else x ← x.right\n\n    z.p ← y\n    if y = null\n        then T.root ← z\n        else if z.key < y.key\n            then y.left ← z\n            else y.right ← z\n\n    z.left ← null\n    z.right ← null\n    z.color ← RED\n    RB-INSERT-FIXUP(T, z)\n\nRB-INSERT-FIXUP(T, z)\n    while z.p.color = RED\n        do if z.p = z.p.p.left\n               then y ← z.p.p.right\n                    if y.color = RED\n                        then z.p.color ← BLACK\n                             y.color ← BLACK\n                             z.p.p.color ← RED\n                             z ← z.p.p\n                        else if z = z.p.right\n                            then z ← z.p\n                                 LEFT-ROTATE(T, z)\n                            z.p.color ← BLACK\n                            z.p.p.color ← RED\n                            RIGHT-ROTATE(T, z.p.p)\n               else (same as then clause with \"right\" and \"left\" exchanged)\n    T.root.color ← BLACK\n\nLEFT-ROTATE(T, x)\n    let y ← x.right\n    x.right ← y.left\n    if y.left ≠ null\n        then y.left.p ← x\n    y.p ← x.p\n    if x.p = null\n        then T.root ← y\n        else if x = x.p.left\n            then x.p.left ← y\n            else x.p.right ← y\n    y.left ← x\n    x.p ← y\n\n// Example:\n// Input: Insert keys [10, 20, 30, 40, 50, 25]\n//\n// Insert 10:\n//   Tree: 10(B)\n//\n// Insert 20:\n//   Tree: 10(B)\n//         \\\n//         20(R)\n//\n// Insert 30:\n//   Tree: 20(B)\n//        /  \\\n//     10(R) 30(R)\n//\n// Insert 40:\n//   Tree: 20(B)\n//        /  \\\n//     10(B) 30(B)\n//             \\\n//            40(R)\n//\n// Insert 50:\n//   Tree: 20(B)\n//        /  \\\n//     10(B) 40(B)\n//           /  \\\n//        30(R) 50(R)\n//\n// Insert 25:\n//   Tree: 20(B)\n//        /  \\\n//     10(B) 40(R)\n//           /  \\\n//        30(B) 50(B)\n//       /\n//    25(R)",
    "keySteps": ["Step 1: [Description]", "Step 2: [Description]", "Step 3: [Description]"]
  },
  "recursion": {
    "name": "Recursion",
    "type": "algorithm",
    "description": "Recursion is an algorithm with time complexity O(n). It is primarily used for break problems into smaller       subproblems",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Break problems into smaller\n      subproblems\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Break problems into smaller\n      subproblems\n    ",
    "useCase": "Break problems into smaller\n      subproblems\n    ",
    "pseudocode": "// Factorial\nFACTORIAL(n):\n  if n ≤ 1:\n    return 1\n  return n * FACTORIAL(n-1)\n\n// Fibonacci\nFIBONACCI(n):\n  if n ≤ 1:\n    return n\n  return FIBONACCI(n-1) + FIBONACCI(n-2)\n\n// Tower of Hanoi\nHANOI(n, source, target, auxiliary):\n  if n == 1:\n    move disk from source to target\n    return\n  HANOI(n-1, source, auxiliary, target)\n  move disk from source to target\n  HANOI(n-1, auxiliary, target, source)\n\n// Binary Search\nBINARY-SEARCH(A, l, r, x):\n  if l > r:\n    return -1\n  mid = floor((l + r) / 2)\n  if A[mid] == x:\n    return mid\n  if A[mid] > x:\n    return BINARY-SEARCH(A, l, mid-1, x)\n  return BINARY-SEARCH(A, mid+1, r, x)\n\n// Merge Sort\nMERGE-SORT(A, l, r):\n  if l ≥ r:\n    return\n  mid = floor((l + r) / 2)\n  MERGE-SORT(A, l, mid)\n  MERGE-SORT(A, mid+1, r)\n  MERGE(A, l, mid, r)\n\n// Quick Sort\nQUICK-SORT(A, l, r):\n  if l ≥ r:\n    return\n  p = PARTITION(A, l, r)\n  QUICK-SORT(A, l, p-1)\n  QUICK-SORT(A, p+1, r)",
    "keySteps": []
  },
  "radix-sort": {
    "name": "Radix Sort",
    "type": "sorting",
    "description": "Radix Sort is an algorithm with time complexity O(d(n+k). It is primarily used for sort numbers by processing       individual digits",
    "timeComplexity": "O(d(n+k)) &nbsp;|&nbsp; Space: O(n+k) &nbsp;|&nbsp; Use: Sort numbers by processing\n      individual digits\n    ",
    "spaceComplexity": "O(n+k) &nbsp;|&nbsp; Use: Sort numbers by processing\n      individual digits\n    ",
    "useCase": "Sort numbers by processing\n      individual digits\n    ",
    "pseudocode": "RADIX-SORT(A)\n1  // Find maximum number to know number of digits\n2  max_num = max(A)\n3  exp = 1\n4  while max_num/exp > 0\n5      COUNTING-SORT(A, exp)\n6      exp *= 10\n\nCOUNTING-SORT(A, exp)\n1  n = A.length\n2  output = [0] * n\n3  count = [0] * 10\n4\n5  // Store count of occurrences\n6  for i = 0 to n-1\n7      index = (A[i]/exp) % 10\n8      count[index] += 1\n9\n10 // Change count[i] to position of digit i in output\n11 for i = 1 to 9\n12     count[i] += count[i-1]\n13\n14 // Build output array\n15 for i = n-1 downto 0\n16     index = (A[i]/exp) % 10\n17     output[count[index]-1] = A[i]\n18     count[index] -= 1\n19\n20 // Copy output to A\n21 for i = 0 to n-1\n22     A[i] = output[i]\n\n// Example:\n// Input: A = [170, 45, 75, 90, 802, 24, 2, 66]\n//\n// Step 1 (exp=1):\n// Count: [2, 0, 2, 0, 1, 2, 2, 0, 0, 1]\n// Output: [170, 90, 802, 2, 24, 45, 75, 66]\n//\n// Step 2 (exp=10):\n// Count: [2, 2, 2, 0, 1, 1, 0, 0, 0, 0]\n// Output: [802, 2, 24, 45, 66, 170, 75, 90]\n//\n// Step 3 (exp=100):\n// Count: [6, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n// Output: [2, 24, 45, 66, 75, 90, 170, 802]",
    "keySteps": [
      "Find: Maximum number to determine digit count",
      "Process: Each digit position from least to most significant",
      "Sort: Using counting sort for each digit position"
    ]
  },
  "rabin-karp": {
    "name": "Rabin-Karp",
    "type": "data-structures",
    "description": "Rabin-Karp is an algorithm with time complexity O(n + m). It is primarily used for pattern matching with rolling hash",
    "timeComplexity": "O(n + m) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Pattern matching with rolling hash\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Pattern matching with rolling hash\n    ",
    "useCase": "Pattern matching with rolling hash\n    ",
    "pseudocode": "# Rabin-Karp: Pattern matching with rolling hash\n# Input: Text T[1..n], pattern P[1..m]\n# Output: Starting indices where P occurs in T\n\nAlgorithm RABIN-KARP(T, P)\n    n ← length[T]\n    m ← length[P]\n    d ← 256  # Number of characters in alphabet\n    q ← 101  # Prime number for hash\n    h ← d^(m-1) mod q\n\n    # Compute hash of pattern and first window\n    p ← 0\n    t ← 0\n    for i ← 1 to m do\n        p ← (d * p + P[i]) mod q\n        t ← (d * t + T[i]) mod q\n    end for\n\n    # Slide pattern over text\n    for s ← 0 to n - m do\n        if p = t then\n            # Check for exact match\n            match ← true\n            for i ← 1 to m do\n                if P[i] ≠ T[s + i] then\n                    match ← false\n                    break\n                end if\n            end for\n            if match then\n                print \"Pattern found at index\" s\n            end if\n        end if\n\n        # Compute hash for next window\n        if s < n - m then\n            t ← (d * (t - T[s + 1] * h) + T[s + m + 1]) mod q\n            if t < 0 then\n                t ← t + q\n            end if\n        end if\n    end for\n\n# Example:\n# Input: T = \"GEEKS FOR GEEKS\", P = \"GEEK\"\n#\n# Step 1: p = hash(\"GEEK\") = 71\n#         t = hash(\"GEEK\") = 71\n#         Match found at index 0\n# Step 2: t = hash(\"EEKS\") = 69\n# Step 3: t = hash(\"EKS \") = 75\n# Step 4: t = hash(\"KS F\") = 83\n# Step 5: t = hash(\"S FO\") = 95\n# Step 6: t = hash(\" FOR\") = 70\n# Step 7: t = hash(\"FOR \") = 82\n# Step 8: t = hash(\"OR G\") = 79\n# Step 9: t = hash(\"R GE\") = 71\n#         Match found at index 10\n#\n# Output: Pattern found at indices 0 and 10",
    "keySteps": [
      "Compute hash of pattern and first window",
      "Slide pattern over text",
      "Check for exact match when hashes match",
      "Update rolling hash for next window"
    ]
  },
  "quickselect": {
    "name": "Quickselect",
    "type": "Divide And Conquer",
    "description": "Quickselect is an algorithm with time complexity O(n). It is primarily used for find k-th       smallest element",
    "timeComplexity": "O(n) average, O(n²) worst &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find k-th\n      smallest element\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find k-th\n      smallest element\n    ",
    "useCase": "Find k-th\n      smallest element\n    ",
    "pseudocode": "QUICKSELECT(A, k)\n    return SELECT(A, 1, A.length, k)\n\nSELECT(A, p, r, k)\n    if p = r\n        then return A[p]\n    let q ← PARTITION(A, p, r)\n    let i ← q - p + 1\n    if k = i\n        then return A[q]\n    else if k < i\n        then return SELECT(A, p, q-1, k)\n    else return SELECT(A, q+1, r, k-i)\n\nPARTITION(A, p, r)\n    let x ← A[r]\n    let i ← p - 1\n    for j ← p to r - 1\n        do if A[j] ≤ x\n            then i ← i + 1\n                exchange A[i] with A[j]\n    exchange A[i+1] with A[r]\n    return i + 1\n\n// Example:\n// Input: A = [3, 2, 1, 5, 4], k = 3\n//\n// First call: p = 1, r = 5, k = 3\n//   q = 3 (after PARTITION)\n//   i = 3 - 1 + 1 = 3\n//   k = i, return A[3] = 3\n//\n// Output: 3",
    "keySteps": [
      "Partition: Divide array using pivot element",
      "Compare: Check if k-th element is found",
      "Recurse: Search in appropriate subarray"
    ]
  },
  "quick-sort": {
    "name": "Quick Sort",
    "type": "n²",
    "description": "Quick Sort is an algorithm with time complexity O(n²). It is primarily used for efficient in-place sorting",
    "timeComplexity": "O(n²) &nbsp;|&nbsp; Space: O(log n) &nbsp;|&nbsp; Use: Efficient in-place sorting\n    ",
    "spaceComplexity": "O(log n) &nbsp;|&nbsp; Use: Efficient in-place sorting\n    ",
    "useCase": "Efficient in-place sorting\n    ",
    "pseudocode": "// Main quick sort function\nQUICK-SORT(array, start, end):\n    # If array has more than one element\n    if start < end:\n        # Partition the array and get pivot position\n        pivot_position = PARTITION(array, start, end)\n        # Sort left side of pivot\n        QUICK-SORT(array, start, pivot_position - 1)\n        # Sort right side of pivot\n        QUICK-SORT(array, pivot_position + 1, end)\n\n// Partition the array around a pivot\nPARTITION(array, start, end):\n    # Choose last element as pivot\n    pivot = array[end]\n    # Initialize pointer for elements less than pivot\n    smaller_element_pointer = start - 1\n\n    # Move through the array\n    for current_element from start to end - 1:\n        # If current element is less than pivot\n        if array[current_element] ≤ pivot:\n            # Move smaller element pointer\n            smaller_element_pointer = smaller_element_pointer + 1\n            # Swap current element with element at pointer\n            swap array[smaller_element_pointer] with array[current_element]\n\n    # Place pivot in correct position\n    swap array[smaller_element_pointer + 1] with array[end]\n    # Return pivot position\n    return smaller_element_pointer + 1",
    "keySteps": []
  },
  "queue": {
    "name": "Queue",
    "type": "Data Structure",
    "description": "Queue is an algorithm with time complexity O(1). It is primarily used for fifo (first-in-first-out) operations",
    "timeComplexity": "O(1) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: FIFO (First-In-First-Out) operations\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: FIFO (First-In-First-Out) operations\n    ",
    "useCase": "FIFO (First-In-First-Out) operations\n    ",
    "pseudocode": "// Standard Queue\nclass Queue:\n    def __init__(self):\n        self.items = []\n\n    # Enqueue (add to rear)\n    def enqueue(self, item):\n        self.items.append(item)\n\n    # Dequeue (remove from front)\n    def dequeue(self):\n        if self.is_empty():\n            return None\n        return self.items.pop(0)\n\n    # Check if empty\n    def is_empty(self):\n        return len(self.items) == 0\n\n    # Get size\n    def size(self):\n        return len(self.items)\n\n    # Peek front\n    def peek(self):\n        if self.is_empty():\n            return None\n        return self.items[0]\n\n// Circular Queue\nclass CircularQueue:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.items = [None] * capacity\n        self.front = 0\n        self.rear = -1\n        self.size = 0\n\n    # Enqueue\n    def enqueue(self, item):\n        if self.is_full():\n            return False\n        self.rear = (self.rear + 1) % self.capacity\n        self.items[self.rear] = item\n        self.size += 1\n        return True\n\n    # Dequeue\n    def dequeue(self):\n        if self.is_empty():\n            return None\n        item = self.items[self.front]\n        self.front = (self.front + 1) % self.capacity\n        self.size -= 1\n        return item\n\n    # Check if empty\n    def is_empty(self):\n        return self.size == 0\n\n    # Check if full\n    def is_full(self):\n        return self.size == self.capacity\n\n    # Peek front\n    def peek(self):\n        if self.is_empty():\n            return None\n        return self.items[self.front]\n\n// Priority Queue\nclass PriorityQueue:\n    def __init__(self):\n        self.items = []\n\n    # Enqueue with priority\n    def enqueue(self, item, priority):\n        self.items.append((item, priority))\n        self.items.sort(key=lambda x: x[1])\n\n    # Dequeue highest priority\n    def dequeue(self):\n        if self.is_empty():\n            return None\n        return self.items.pop(0)[0]\n\n    # Check if empty\n    def is_empty(self):\n        return len(self.items) == 0\n\n    # Get size\n    def size(self):\n        return len(self.items)\n\n    # Peek highest priority\n    def peek(self):\n        if self.is_empty():\n            return None\n        return self.items[0][0]\n\n// Double-Ended Queue (Deque)\nclass Deque:\n    def __init__(self):\n        self.items = []\n\n    # Add to front\n    def add_front(self, item):\n        self.items.insert(0, item)\n\n    # Add to rear\n    def add_rear(self, item):\n        self.items.append(item)\n\n    # Remove from front\n    def remove_front(self):\n        if self.is_empty():\n            return None\n        return self.items.pop(0)\n\n    # Remove from rear\n    def remove_rear(self):\n        if self.is_empty():\n            return None\n        return self.items.pop()\n\n    # Check if empty\n    def is_empty(self):\n        return len(self.items) == 0\n\n    # Get size\n    def size(self):\n        return len(self.items)\n\n    # Peek front\n    def peek_front(self):\n        if self.is_empty():\n            return None\n        return self.items[0]\n\n    # Peek rear\n    def peek_rear(self):\n        if self.is_empty():\n            return None\n        return self.items[-1]",
    "keySteps": []
  },
  "queue-implementation": {
    "name": "Queue Implementation",
    "type": "data-structures",
    "description": "Queue Implementation is an algorithm with time complexity O(1). It is primarily used for fifo data structure",
    "timeComplexity": "O(1) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: FIFO data structure\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: FIFO data structure\n    ",
    "useCase": "FIFO data structure\n    ",
    "pseudocode": "QUEUE-EMPTY(Q)\n    if Q.head = Q.tail\n        then return true\n        else return false\n\nQUEUE-FULL(Q)\n    if Q.head = Q.tail + 1 or (Q.head = 1 and Q.tail = Q.size)\n        then return true\n        else return false\n\nENQUEUE(Q, x)\n    if QUEUE-FULL(Q)\n        then error \"queue overflow\"\n    Q[Q.tail] ← x\n    if Q.tail = Q.size\n        then Q.tail ← 1\n        else Q.tail ← Q.tail + 1\n\nDEQUEUE(Q)\n    if QUEUE-EMPTY(Q)\n        then error \"queue underflow\"\n    x ← Q[Q.head]\n    if Q.head = Q.size\n        then Q.head ← 1\n        else Q.head ← Q.head + 1\n    return x\n\n// Example:\n// Input: Operations [ENQUEUE(10), ENQUEUE(20), DEQUEUE(), ENQUEUE(30), ENQUEUE(40)]\n//\n// Initial state:\n//   Q = []\n//   Q.head = 1\n//   Q.tail = 1\n//\n// After ENQUEUE(10):\n//   Q = [10]\n//   Q.head = 1\n//   Q.tail = 2\n//\n// After ENQUEUE(20):\n//   Q = [10, 20]\n//   Q.head = 1\n//   Q.tail = 3\n//\n// After DEQUEUE():\n//   Q = [20]\n//   Q.head = 2\n//   Q.tail = 3\n//   Returns: 10\n//\n// After ENQUEUE(30):\n//   Q = [20, 30]\n//   Q.head = 2\n//   Q.tail = 4\n//\n// After ENQUEUE(40):\n//   Q = [20, 30, 40]\n//   Q.head = 2\n//   Q.tail = 5\n//\n// Final state:\n//   Q = [20, 30, 40]\n//   Q.head = 2\n//   Q.tail = 5",
    "keySteps": [
      "Initialize: Create array and head/tail pointers",
      "Enqueue: Add element at tail and update pointer",
      "Dequeue: Remove element from head and update pointer"
    ]
  },
  "probability-dp": {
    "name": "Probability DP",
    "type": "dynamic-programming",
    "description": "Probability DP is an algorithm with time complexity O(n·k). It is primarily used for calculate probability of events",
    "timeComplexity": "O(n·k) &nbsp;|&nbsp; Space: O(n·k) &nbsp;|&nbsp; Use: Calculate probability of events\n    ",
    "spaceComplexity": "O(n·k) &nbsp;|&nbsp; Use: Calculate probability of events\n    ",
    "useCase": "Calculate probability of events\n    ",
    "pseudocode": "PROBABILITY-DP(n, k, p)\n    let dp[0‥n][0‥k] be a new array\n    for i ← 0 to n\n        do for j ← 0 to k\n            do dp[i][j] ← -1\n    return CALC-PROB(n, k, p, dp)\n\nCALC-PROB(n, k, p, dp)\n    if n = 0\n        then if k = 0\n                then return 1\n                else return 0\n    if k < 0\n        then return 0\n    if dp[n][k] ≠ -1\n        then return dp[n][k]\n\n    let prob ← p · CALC-PROB(n-1, k-1, p, dp) + (1-p) · CALC-PROB(n-1, k, p, dp)\n    dp[n][k] ← prob\n    return prob\n\n// Example:\n// Input: n = 3, k = 2, p = 0.5\n//\n// Initial call: n = 3, k = 2\n//\n// For n = 3:\n//   prob = 0.5·CALC-PROB(2,1) + 0.5·CALC-PROB(2,2)\n//\n// For n = 2:\n//   prob = 0.5·CALC-PROB(1,0) + 0.5·CALC-PROB(1,1)\n//\n// For n = 1:\n//   prob = 0.5·CALC-PROB(0,-1) + 0.5·CALC-PROB(0,0)\n//\n// Base cases:\n//   CALC-PROB(0,0) = 1\n//   CALC-PROB(0,-1) = 0\n//\n// Output: Probability of exactly 2 successes in 3 trials",
    "keySteps": [
      "Initialize: Create DP table for memoization",
      "Base Cases: Handle terminal conditions",
      "Recurse: Calculate probability using previous states"
    ]
  },
  "prims-algorithm": {
    "name": "Prim's Algorithm",
    "type": "graph",
    "description": "Prim's Algorithm is an algorithm with time complexity O(E log V). It is primarily used for finding minimum spanning tree",
    "timeComplexity": "O(E log V) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree\n    ",
    "useCase": "Finding minimum spanning tree\n    ",
    "pseudocode": "// Standard Prim's Algorithm\ndef prim(graph):\n    # Initialize MST and priority queue\n    mst = []\n    visited = set()\n    heap = [(0, None, next(iter(graph)))]  # (weight, parent, vertex)\n\n    while heap:\n        weight, parent, u = heapq.heappop(heap)\n        if u in visited:\n            continue\n\n        visited.add(u)\n        if parent is not None:\n            mst.append((parent, u, weight))\n\n        # Add adjacent vertices to heap\n        for v, w in graph[u].items():\n            if v not in visited:\n                heapq.heappush(heap, (w, u, v))\n\n    return mst\n\n// Prim's with Priority Queue\ndef prim_pq(graph):\n    mst = []\n    visited = set()\n    heap = [(0, None, next(iter(graph)))]\n\n    while heap:\n        weight, parent, u = heapq.heappop(heap)\n        if u in visited:\n            continue\n\n        visited.add(u)\n        if parent is not None:\n            mst.append((parent, u, weight))\n\n        for v, w in graph[u].items():\n            if v not in visited:\n                heapq.heappush(heap, (w, u, v))\n\n    return mst\n\n// Prim's with Fibonacci Heap\ndef prim_fh(graph):\n    mst = []\n    visited = set()\n    heap = FibonacciHeap()\n    heap.insert(next(iter(graph)), 0)\n\n    while not heap.is_empty():\n        u = heap.extract_min()\n        visited.add(u)\n\n        for v, w in graph[u].items():\n            if v not in visited:\n                if v not in heap:\n                    heap.insert(v, w)\n                elif w < heap.get_key(v):\n                    heap.decrease_key(v, w)\n\n    return mst",
    "keySteps": []
  },
  "prime-factorization": {
    "name": "Prime Factorization",
    "type": "Algorithm",
    "description": "Prime Factorization is an algorithm with time complexity O(√n). It is primarily used for decompose number into prime       factors",
    "timeComplexity": "O(√n) &nbsp;|&nbsp; Space: O(log n) &nbsp;|&nbsp; Use: Decompose number into prime\n      factors\n    ",
    "spaceComplexity": "O(log n) &nbsp;|&nbsp; Use: Decompose number into prime\n      factors\n    ",
    "useCase": "Decompose number into prime\n      factors\n    ",
    "pseudocode": "PRIME-FACTORS(n)\n  factors = []\n  // Handle even numbers\n  while n mod 2 == 0\n    factors.append(2)\n    n = n / 2\n  // Check odd numbers up to sqrt(n)\n  i = 3\n  while i * i <= n\n    while n mod i == 0\n      factors.append(i)\n      n = n / i\n    i = i + 2\n  // If n is a prime number > 2\n  if n > 2\n    factors.append(n)\n  return factors\n\n// Example:\n// Input: n = 60\n// Step 1: 60 ÷ 2 = 30, factors = [2]\n// Step 2: 30 ÷ 2 = 15, factors = [2, 2]\n// Step 3: 15 ÷ 3 = 5, factors = [2, 2, 3]\n// Step 4: 5 ÷ 5 = 1, factors = [2, 2, 3, 5]\n// Output: [2, 2, 3, 5]",
    "keySteps": [
      "Handle: Even numbers (factor of 2)",
      "Check: Odd numbers up to √n",
      "Add: Remaining prime factor if &gt; 2"
    ]
  },
  "prefix-sums": {
    "name": "Prefix Sums",
    "type": "Algorithm",
    "description": "Prefix Sums is an algorithm with time complexity O(n). It is primarily used for range sum queries",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Range sum queries\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Range sum queries\n    ",
    "useCase": "Range sum queries\n    ",
    "pseudocode": "PREFIX-SUMS(A)\n    let n be the length of A\n    let prefix[0‥n] be a new array\n    prefix[0] ← 0\n\n    for i ← 1 to n\n        do prefix[i] ← prefix[i-1] + A[i]\n\n    return prefix\n\nRANGE-SUM(prefix, l, r)\n    return prefix[r] - prefix[l-1]\n\n// Example:\n// Input: A = [1, 2, 3, 4, 5]\n//\n// prefix[0] = 0\n// prefix[1] = 0 + 1 = 1\n// prefix[2] = 1 + 2 = 3\n// prefix[3] = 3 + 3 = 6\n// prefix[4] = 6 + 4 = 10\n// prefix[5] = 10 + 5 = 15\n//\n// Range sum from index 2 to 4:\n// RANGE-SUM(prefix, 2, 4) = prefix[4] - prefix[1] = 10 - 1 = 9\n//\n// Output: prefix = [0, 1, 3, 6, 10, 15]",
    "keySteps": [
      "Initialize: Create prefix array with size n+1",
      "Compute: Cumulative sums in prefix array",
      "Query: Calculate range sums using prefix differences"
    ]
  },
  "palindrome-partitioning": {
    "name": "Palindrome Partitioning",
    "type": "backtracking",
    "description": "Palindrome Partitioning is an algorithm with time complexity O(n * 2^n). It is primarily used for finding all possible palindrome       partitions",
    "timeComplexity": "O(n * 2^n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Finding all possible palindrome\n      partitions\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Finding all possible palindrome\n      partitions\n    ",
    "useCase": "Finding all possible palindrome\n      partitions\n    ",
    "pseudocode": "// Check if string is palindrome\nIS-PALINDROME(s, start, end):\n  while start < end:\n    if s[start] != s[end]:\n      return false\n    start += 1\n    end -= 1\n  return true\n\n// Main partitioning function\nPALINDROME-PARTITION(s):\n  result = []\n  current = []\n  \n  function BACKTRACK(start):\n    if start == len(s):\n      result.append(current.copy())\n      return\n    \n    for end in range(start, len(s)):\n      if IS-PALINDROME(s, start, end):\n        current.append(s[start:end+1])\n        BACKTRACK(end + 1)\n        current.pop()\n  \n  BACKTRACK(0)\n  return result",
    "keySteps": [
      "Uses backtracking to explore all possible partitions",
      "Can be optimized with dynamic programming for minimum cuts",
      "Useful for string manipulation and text analysis"
    ]
  },
  "null-pattern": {
    "name": "Null Pattern",
    "type": "other",
    "description": "A design pattern that provides a default behavior for null objects",
    "timeComplexity": "O(1) for null checks and property access",
    "spaceComplexity": "O(1) for storing null object reference",
    "useCase": "Handle null/undefined values gracefully, prevent null pointer exceptions",
    "pseudocode": "# Null Pattern: Handle null/undefined values gracefully\n# Input: Object that may be null\n# Output: Safe access to object properties\n\nAlgorithm NULL-PATTERN(object)\n    if object = null then\n        return null\n    end if\n    \n    # Safe access to properties\n    result ← object.property\n    \n    # Safe method calls\n    if object.method ≠ null then\n        result ← object.method()\n    end if\n    \n    return result\n\n# Example:\n# Input: object = null\n# Output: null\n#\n# Input: object = { property: \"value\", method: () => \"result\" }\n# Output: \"result\"",
    "keySteps": [
      "Check if the object is null before accessing properties",
      "Provide default behavior for null objects",
      "Implement safe method calls with null checks",
      "Return appropriate default values when object is null"
    ]
  },
  "network-flow": {
    "name": "Network Flow",
    "type": "graph",
    "description": "Network Flow is an algorithm with time complexity O(V²E). It is primarily used for find maximum flow in a network",
    "timeComplexity": "O(V²E) &nbsp;|&nbsp; Space: O(V²) &nbsp;|&nbsp; Use: Find maximum flow in a network\n    ",
    "spaceComplexity": "O(V²) &nbsp;|&nbsp; Use: Find maximum flow in a network\n    ",
    "useCase": "Find maximum flow in a network\n    ",
    "pseudocode": "FORD-FULKERSON(G, s, t)\n1  for each edge (u,v) ∈ G.E\n2      (u,v).f = 0\n3  while there exists a path p from s to t in residual network Gf\n4      cf(p) = min{cf(u,v) : (u,v) is in p}\n5      for each edge (u,v) in p\n6          if (u,v) ∈ E\n7              (u,v).f = (u,v).f + cf(p)\n8          else\n9              (v,u).f = (v,u).f - cf(p)\n\nEDMONDS-KARP(G, s, t)\n1  for each edge (u,v) ∈ G.E\n2      (u,v).f = 0\n3  while there exists a path p from s to t in residual network Gf\n4      cf(p) = min{cf(u,v) : (u,v) is in p}\n5      for each edge (u,v) in p\n6          if (u,v) ∈ E\n7              (u,v).f = (u,v).f + cf(p)\n8          else\n9              (v,u).f = (v,u).f - cf(p)\n\nDINIC(G, s, t)\n1  for each edge (u,v) ∈ G.E\n2      (u,v).f = 0\n3  while BFS(Gf, s, t) finds a path\n4      while DFS(Gf, s, t, ∞) finds a blocking flow\n5          for each edge (u,v) in blocking flow\n6              if (u,v) ∈ E\n7                  (u,v).f = (u,v).f + cf(p)\n8              else\n9                  (v,u).f = (v,u).f - cf(p)\n\n// Example:\n// Input: G = (V, E) where\n// V = {s, a, b, c, d, t}\n// E = {(s,a,10), (s,b,5), (a,b,2), (a,c,5), (b,c,8), (b,d,4), (c,t,7), (d,t,10)}\n//\n// Step 1: Initial flow = 0\n// Step 2: Find augmenting path s->a->c->t with flow 5\n// Step 3: Find augmenting path s->b->d->t with flow 4\n// Step 4: Find augmenting path s->a->b->c->t with flow 2\n//\n// Final flow: 11",
    "keySteps": [
      "Initialize: Set all flows to 0",
      "Find: Augmenting path in residual network",
      "Update: Flow along the path"
    ]
  },
  "monotonic-stack": {
    "name": "Monotonic Stack",
    "type": "Algorithm",
    "description": "Monotonic Stack is an algorithm with time complexity O(n). It is primarily used for next greater/smaller element",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Next greater/smaller element\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Next greater/smaller element\n    ",
    "useCase": "Next greater/smaller element\n    ",
    "pseudocode": "// Next greater element\nNEXT-GREATER-ELEMENT(A):\n    n ← length[A]\n    S ← empty stack\n    result[1..n] ← -1\n    for i ← 1 to n:\n        while S not empty and A[TOP(S)] < A[i]:\n            result[POP(S)] ← A[i]\n        PUSH(S, i)\n    return result\n\n// Next smaller element\nNEXT-SMALLER-ELEMENT(A):\n    n ← length[A]\n    S ← empty stack\n    result[1..n] ← -1\n    for i ← 1 to n:\n        while S not empty and A[TOP(S)] > A[i]:\n            result[POP(S)] ← A[i]\n        PUSH(S, i)\n    return result\n\n// Previous greater element\nPREVIOUS-GREATER-ELEMENT(A):\n    n ← length[A]\n    S ← empty stack\n    result[1..n] ← -1\n    for i ← n downto 1:\n        while S not empty and A[TOP(S)] < A[i]:\n            result[POP(S)] ← A[i]\n        PUSH(S, i)\n    return result\n\n// Previous smaller element\nPREVIOUS-SMALLER-ELEMENT(A):\n    n ← length[A]\n    S ← empty stack\n    result[1..n] ← -1\n    for i ← n downto 1:\n        while S not empty and A[TOP(S)] > A[i]:\n            result[POP(S)] ← A[i]\n        PUSH(S, i)\n    return result\n\n// Example:\n// Input: A = [4, 5, 2, 10, 8]\n//\n// NEXT-GREATER-ELEMENT(A):\n//   i = 1: S = [1], result = [-1, -1, -1, -1, -1]\n//   i = 2: S = [2], result = [5, -1, -1, -1, -1]\n//   i = 3: S = [2, 3], result = [5, -1, -1, -1, -1]\n//   i = 4: S = [4], result = [5, 10, 10, -1, -1]\n//   i = 5: S = [4, 5], result = [5, 10, 10, -1, -1]\n//   Final result: [5, 10, 10, -1, -1]",
    "keySteps": [
      "Initialize: Create empty stack and result array",
      "Process: Maintain monotonic property while processing elements",
      "Update: Store results for popped elements"
    ]
  },
  "monotonic-queue": {
    "name": "Monotonic Queue",
    "type": "Algorithm",
    "description": "Monotonic Queue is an algorithm with time complexity O(n). It is primarily used for sliding window maximum/minimum",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(k) &nbsp;|&nbsp; Use: Sliding window maximum/minimum\n    ",
    "spaceComplexity": "O(k) &nbsp;|&nbsp; Use: Sliding window maximum/minimum\n    ",
    "useCase": "Sliding window maximum/minimum\n    ",
    "pseudocode": "SLIDING-WINDOW-MAXIMUM(A, k)\n    let n be the length of A\n    let result[1‥n-k+1] be a new array\n    let Q be a new empty deque\n\n    for i ← 1 to n\n        do while Q is not empty and A[Q.back()] ≤ A[i]\n            do Q.pop_back()\n            Q.push_back(i)\n            if Q.front() = i - k\n                then Q.pop_front()\n            if i ≥ k\n                then result[i-k+1] ← A[Q.front()]\n\n    return result\n\n// Example:\n// Input: A = [1, 3, -1, -3, 5, 3, 6, 7], k = 3\n//\n// i = 1: A[1] = 1\n//   Q = [1]\n//\n// i = 2: A[2] = 3\n//   Q = [2]\n//\n// i = 3: A[3] = -1\n//   Q = [2,3]\n//   result[1] = 3\n//\n// i = 4: A[4] = -3\n//   Q = [2,3,4]\n//   result[2] = 3\n//\n// i = 5: A[5] = 5\n//   Q = [5]\n//   result[3] = 5\n//\n// i = 6: A[6] = 3\n//   Q = [5,6]\n//   result[4] = 5\n//\n// i = 7: A[7] = 6\n//   Q = [7]\n//   result[5] = 6\n//\n// i = 8: A[8] = 7\n//   Q = [8]\n//   result[6] = 7\n//\n// Output: [3, 3, 5, 5, 6, 7]",
    "keySteps": [
      "Initialize: Create result array and empty deque",
      "Process: Maintain monotonic deque while sliding window",
      "Update: Remove elements outside window and smaller values"
    ]
  },
  "miller-rabin-primality-test": {
    "name": "Miller-Rabin Primality Test",
    "type": "Number Theory",
    "description": "Miller-Rabin Primality Test is an algorithm with time complexity O(k log³ n). It is primarily used for probabilistic primality test",
    "timeComplexity": "O(k log³ n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Probabilistic primality test\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Probabilistic primality test\n    ",
    "useCase": "Probabilistic primality test\n    ",
    "pseudocode": "# Miller-Rabin Primality Test\n# Input: Integer n > 2, number of rounds k\n# Output: \"composite\" or \"probably prime\"\n\nAlgorithm MILLER-RABIN-PRIMALITY-TEST(n, k)\n    # Handle edge cases\n    if n ≤ 1 then\n        return \"composite\"\n    if n ≤ 3 then\n        return \"prime\"\n    if n mod 2 = 0 then\n        return \"composite\"\n\n    # Write n-1 as d·2^s\n    d ← n - 1\n    s ← 0\n    while d mod 2 = 0 do\n        d ← d / 2\n        s ← s + 1\n    end while\n\n    # Test k times\n    for i ← 1 to k do\n        a ← random integer in [2, n-2]\n        x ← a^d mod n\n        if x = 1 or x = n-1 then\n            continue\n        end if\n\n        for j ← 1 to s-1 do\n            x ← x² mod n\n            if x = n-1 then\n                break\n            end if\n            if x = 1 then\n                return \"composite\"\n            end if\n        end for\n\n        if x ≠ n-1 then\n            return \"composite\"\n        end if\n    end for\n\n    return \"probably prime\"\n\n# Example:\n# Input: n = 17, k = 5\n#\n# Step 1: n-1 = 16 = 1·2^4\n#         d = 1, s = 4\n#\n# Round 1: a = 2\n#          x = 2^1 mod 17 = 2\n#          x² mod 17 = 4\n#          x² mod 17 = 16 = n-1\n#          continue\n#\n# Round 2: a = 3\n#          x = 3^1 mod 17 = 3\n#          x² mod 17 = 9\n#          x² mod 17 = 13\n#          x² mod 17 = 16 = n-1\n#          continue\n#\n# ... (3 more rounds)\n#\n# Output: \"probably prime\"",
    "keySteps": [
      "Handle edge cases (n ≤ 1, n ≤ 3, even numbers)",
      "Factor n-1 into d·2^s",
      "Choose random base a",
      "Test for strong pseudoprimes"
    ]
  },
  "merge-sort": {
    "name": "Merge Sort",
    "type": "Sorting",
    "description": "Merge Sort is an algorithm with time complexity O(n log n). It is primarily used for stable sorting of arrays",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Stable sorting of arrays\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Stable sorting of arrays\n    ",
    "useCase": "Stable sorting of arrays\n    ",
    "pseudocode": "// Main merge sort function\nMERGE-SORT(array, start, end):\n    # If array has more than one element\n    if start < end:\n        # Find middle point\n        middle = floor of (start + end) / 2\n\n        # Sort left half\n        MERGE-SORT(array, start, middle)\n        # Sort right half\n        MERGE-SORT(array, middle + 1, end)\n        # Merge sorted halves\n        MERGE(array, start, middle, end)\n\n// Helper function to merge two sorted arrays\nMERGE(array, start, middle, end):\n    # Calculate sizes of left and right arrays\n    left_size = middle - start + 1\n    right_size = end - middle\n\n    # Create temporary arrays\n    left = new array of size left_size + 1\n    right = new array of size right_size + 1\n\n    # Copy data to temporary arrays\n    for i from 1 to left_size:\n        left[i] = array[start + i - 1]\n\n    for j from 1 to right_size:\n        right[j] = array[middle + j]\n\n    # Add sentinel values\n    left[left_size + 1] = infinity\n    right[right_size + 1] = infinity\n\n    # Merge the temporary arrays\n    i = 1\n    j = 1\n\n    for k from start to end:\n        if left[i] ≤ right[j]:\n            array[k] = left[i]\n            i = i + 1\n        else:\n            array[k] = right[j]\n            j = j + 1",
    "keySteps": []
  },
  "memoization": {
    "name": "Memoization",
    "type": "dynamic-programming",
    "description": "Memoization is an algorithm with time complexity O(n). It is primarily used for store computed results to avoid       redundant calculations",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Store computed results to avoid\n      redundant calculations\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Store computed results to avoid\n      redundant calculations\n    ",
    "useCase": "Store computed results to avoid\n      redundant calculations\n    ",
    "pseudocode": "# Memoization: Store computed results to avoid redundant calculations\n# Input: Function f with parameters, memoization table\n# Output: Result of function with parameters\n\nAlgorithm MEMOIZED-FIBONACCI(n)\n    # Initialize memoization table\n    memo ← array of size n + 1\n    for i ← 0 to n do\n        memo[i] ← -1\n    end for\n\n    # Helper function with memoization\n    function FIB(n)\n        if n ≤ 1 then\n            return n\n        end if\n\n        if memo[n] ≠ -1 then\n            return memo[n]\n        end if\n\n        memo[n] ← FIB(n - 1) + FIB(n - 2)\n        return memo[n]\n    end function\n\n    return FIB(n)\n\n# Example:\n# Input: n = 5\n#\n# Step 1: memo = [-1, -1, -1, -1, -1, -1]\n# Step 2: FIB(5)\n#         FIB(4) + FIB(3)\n#         (FIB(3) + FIB(2)) + (FIB(2) + FIB(1))\n#         ((FIB(2) + FIB(1)) + (FIB(1) + FIB(0))) + ((FIB(1) + FIB(0)) + 1)\n#         (((FIB(1) + FIB(0)) + 1) + (1 + 0)) + ((1 + 0) + 1)\n#         (((1 + 0) + 1) + (1 + 0)) + ((1 + 0) + 1)\n#         memo = [0, 1, 1, 2, 3, 5]\n#\n# Output: 5",
    "keySteps": [
      "Initialize memoization table",
      "Check if result exists in table",
      "Compute and store result if not found",
      "Return stored result"
    ]
  },
  "maximum-bipartite-matching": {
    "name": "Maximum Bipartite Matching",
    "type": "Algorithm",
    "description": "Maximum Bipartite Matching is an algorithm with time complexity O(VE). It is primarily used for find maximum matching in bipartite       graph",
    "timeComplexity": "O(VE) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find maximum matching in bipartite\n      graph\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find maximum matching in bipartite\n      graph\n    ",
    "useCase": "Find maximum matching in bipartite\n      graph\n    ",
    "pseudocode": "// Maximum bipartite matching using Ford-Fulkerson Algorithm\nMAX-BIPARTITE-MATCHING(G):\n    // G is a bipartite graph with partitions L and R\n    // Add source s and sink t\n    s ← new vertex\n    t ← new vertex\n    for each u ∈ L:\n        add edge (s, u)\n    for each v ∈ R:\n        add edge (v, t)\n    // Find maximum flow\n    return FORD-FULKERSON(G, s, t)\n\n// Ford-Fulkerson Algorithm algorithm\nFORD-FULKERSON(G, s, t):\n    for each edge (u, v) ∈ G.E:\n        f[u, v] ← 0\n        f[v, u] ← 0\n    while there exists a path p from s to t in residual network Gf:\n        cf(p) ← min{cf(u, v) : (u, v) is in p}\n        for each edge (u, v) in p:\n            f[u, v] ← f[u, v] + cf(p)\n            f[v, u] ← -f[u, v]\n    return f\n\n// Example:\n// Input: G = (L ∪ R, E), where\n// L = {1, 2, 3}, R = {4, 5, 6}\n// E = {(1,4), (1,5), (2,5), (3,4), (3,6)}\n//\n// Execution:\n// 1. Add source s and sink t\n// 2. Add edges: (s,1), (s,2), (s,3), (4,t), (5,t), (6,t)\n// 3. Find augmenting paths:\n//    - s→1→4→t\n//    - s→2→5→t\n//    - s→3→6→t\n//\n// Output: Matching = {(1,4), (2,5), (3,6)}",
    "keySteps": [
      "Transform: Convert to flow network",
      "Find: Maximum flow using Ford-Fulkerson Algorithm",
      "Extract: Matching from flow solution"
    ]
  },
  "matrix-traversal": {
    "name": "Matrix Traversal",
    "type": "Algorithm",
    "description": "Matrix Traversal is an algorithm with time complexity O(mn). It is primarily used for traverse 2d matrix in various       patterns",
    "timeComplexity": "O(mn) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Traverse 2D matrix in various\n      patterns\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Traverse 2D matrix in various\n      patterns\n    ",
    "useCase": "Traverse 2D matrix in various\n      patterns\n    ",
    "pseudocode": "// Matrix traversal patterns\nMATRIX-TRAVERSE(A):\n    m ← rows[A]\n    n ← columns[A]\n\n    // Row-wise traversal\n    for i ← 1 to m:\n        for j ← 1 to n:\n            process A[i, j]\n\n    // Column-wise traversal\n    for j ← 1 to n:\n        for i ← 1 to m:\n            process A[i, j]\n\n    // Diagonal traversal\n    for d ← 1 to m + n - 1:\n        for i ← max(1, d - n + 1) to min(d, m):\n            j ← d - i + 1\n            process A[i, j]\n\n// Example:\n// Input: A = [\n//   [1, 2, 3],\n//   [4, 5, 6],\n//   [7, 8, 9]\n// ]\n//\n// Row-wise: 1, 2, 3, 4, 5, 6, 7, 8, 9\n// Column-wise: 1, 4, 7, 2, 5, 8, 3, 6, 9\n// Diagonal: 1, 2, 4, 3, 5, 7, 6, 8, 9",
    "keySteps": [
      "Initialize: Get matrix dimensions",
      "Traverse: Process elements in desired pattern",
      "Process: Apply operation to each element"
    ]
  },
  "matrix-traversal-recursive": {
    "name": "Matrix Traversal Recursive",
    "type": "Algorithm",
    "description": "Recursive Matrix Traversal is an algorithm with time complexity O(mn). It is primarily used for recursive matrix traversal",
    "timeComplexity": "O(mn) &nbsp;|&nbsp; Space: O(m+n) &nbsp;|&nbsp; Use: Recursive matrix traversal\n    ",
    "spaceComplexity": "O(m+n) &nbsp;|&nbsp; Use: Recursive matrix traversal\n    ",
    "useCase": "Recursive matrix traversal\n    ",
    "pseudocode": "DFS-TRAVERSE(A, i, j, visited)\n    let m, n be the dimensions of A\n    if i < 1 or i > m or j < 1 or j > n or visited[i, j] = TRUE\n        then return\n\n    visited[i, j] ← TRUE\n    result ← A[i, j]\n\n    // Visit adjacent cells\n    DFS-TRAVERSE(A, i-1, j, visited)    // Up\n    DFS-TRAVERSE(A, i+1, j, visited)    // Down\n    DFS-TRAVERSE(A, i, j-1, visited)    // Left\n    DFS-TRAVERSE(A, i, j+1, visited)    // Right\n\n    return result\n\nRECURSIVE-TRAVERSE(A)\n    let m, n be the dimensions of A\n    let visited[1‥m, 1‥n] be a new array\n    let result[1‥m·n] be a new array\n    let idx ← 1\n\n    for i ← 1 to m\n        do for j ← 1 to n\n            do visited[i, j] ← FALSE\n\n    for i ← 1 to m\n        do for j ← 1 to n\n            do if visited[i, j] = FALSE\n                then result[idx] ← DFS-TRAVERSE(A, i, j, visited)\n                    idx ← idx + 1\n\n    return result\n\n// Example:\n// Input: A = [1 2 3]\n//            [4 5 6]\n//            [7 8 9]\n//\n// Starting from (1,1):\n// 1. Visit (1,1) = 1\n// 2. Visit (2,1) = 4\n// 3. Visit (3,1) = 7\n// 4. Visit (3,2) = 8\n// 5. Visit (3,3) = 9\n// 6. Visit (2,3) = 6\n// 7. Visit (2,2) = 5\n// 8. Visit (1,2) = 2\n// 9. Visit (1,3) = 3\n//\n// Output: [1, 4, 7, 8, 9, 6, 5, 2, 3]",
    "keySteps": [
      "Initialize: Create visited matrix and result array",
      "DFS: Recursively visit unvisited adjacent cells",
      "Collect: Store visited values in result array"
    ]
  },
  "matrix-spiral-traversal": {
    "name": "Matrix Spiral Traversal",
    "type": "array",
    "description": "Matrix Spiral Traversal is an algorithm with time complexity O(mn). It is primarily used for traverse matrix in spiral order",
    "timeComplexity": "O(mn) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Traverse matrix in spiral order\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Traverse matrix in spiral order\n    ",
    "useCase": "Traverse matrix in spiral order\n    ",
    "pseudocode": "SPIRAL-TRAVERSE(A)\n    let m, n be the dimensions of A\n    let result[1‥m·n] be a new array\n    let top ← 1, bottom ← m\n    let left ← 1, right ← n\n    let idx ← 1\n\n    while top ≤ bottom and left ≤ right\n        do for i ← left to right\n            do result[idx] ← A[top, i]\n                idx ← idx + 1\n            top ← top + 1\n\n            for i ← top to bottom\n                do result[idx] ← A[i, right]\n                    idx ← idx + 1\n                right ← right - 1\n\n                if top ≤ bottom\n                    then for i ← right downto left\n                        do result[idx] ← A[bottom, i]\n                            idx ← idx + 1\n                        bottom ← bottom - 1\n\n                        if left ≤ right\n                            then for i ← bottom downto top\n                                do result[idx] ← A[i, left]\n                                    idx ← idx + 1\n                                left ← left + 1\n    return result\n\n// Example:\n// Input: A = [1  2  3  4]\n//            [5  6  7  8]\n//            [9 10 11 12]\n//\n// Traversal order:\n// 1. Top row: 1, 2, 3, 4\n// 2. Right column: 8, 12\n// 3. Bottom row: 11, 10, 9\n// 4. Left column: 5\n// 5. Middle: 6, 7\n//\n// Output: [1, 2, 3, 4, 8, 12, 11, 10, 9, 5, 6, 7]",
    "keySteps": [
      "Initialize: Set boundaries for spiral traversal",
      "Traverse: Move right, down, left, up in spiral pattern",
      "Update: Adjust boundaries after each complete spiral"
    ]
  },
  "matrix-spiral-recursive": {
    "name": "Matrix Spiral Recursive",
    "type": "array",
    "description": "Matrix Spiral Traversal (Recursive) is an algorithm with time complexity O(mn). It is primarily used for matrix traversal in spiral order",
    "timeComplexity": "O(mn) &nbsp;|&nbsp; Space: O(mn) &nbsp;|&nbsp; Use: Matrix traversal in spiral order\n    ",
    "spaceComplexity": "O(mn) &nbsp;|&nbsp; Use: Matrix traversal in spiral order\n    ",
    "useCase": "Matrix traversal in spiral order\n    ",
    "pseudocode": "// Recursive spiral traversal of matrix\nSPIRAL-TRAVERSE(A, top, bottom, left, right):\n    if top > bottom or left > right:\n        return\n    // Traverse top row\n    for i ← left to right:\n        print A[top, i]\n    // Traverse right column\n    for i ← top + 1 to bottom:\n        print A[i, right]\n    if top < bottom and left < right:\n        // Traverse bottom row\n        for i ← right - 1 downto left:\n            print A[bottom, i]\n        // Traverse left column\n        for i ← bottom - 1 downto top + 1:\n            print A[i, left]\n    // Recursively traverse inner matrix\n    SPIRAL-TRAVERSE(A, top + 1, bottom - 1, left + 1, right - 1)\n\n// Example:\n// Input: A = [\n//   [1, 2, 3, 4],\n//   [5, 6, 7, 8],\n//   [9, 10, 11, 12]\n// ]\n//\n// Execution:\n// 1. Outer layer: 1, 2, 3, 4, 8, 12, 11, 10, 9, 5\n// 2. Inner layer: 6, 7\n//\n// Output: [1, 2, 3, 4, 8, 12, 11, 10, 9, 5, 6, 7]",
    "keySteps": [
      "Base case: Check if traversal is complete",
      "Traverse: Process outer layer in spiral order",
      "Recurse: Process inner matrix with updated boundaries"
    ]
  },
  "matrix-operations": {
    "name": "Matrix Operations",
    "type": "Algorithm",
    "description": "Matrix Operations is an algorithm with time complexity O(n³). It is primarily used for matrix multiplication and operations",
    "timeComplexity": "O(n³) &nbsp;|&nbsp; Space: O(n²) &nbsp;|&nbsp; Use: Matrix multiplication and operations\n    ",
    "spaceComplexity": "O(n²) &nbsp;|&nbsp; Use: Matrix multiplication and operations\n    ",
    "useCase": "Matrix multiplication and operations\n    ",
    "pseudocode": "MATRIX-MULTIPLY(A, B)\n    let m, n, p be the dimensions of A and B\n    let C[1‥m, 1‥p] be a new matrix\n    for i ← 1 to m\n        do for j ← 1 to p\n            do C[i, j] ← 0\n                for k ← 1 to n\n                    do C[i, j] ← C[i, j] + A[i, k] · B[k, j]\n    return C\n\nMATRIX-TRANSPOSE(A)\n    let m, n be the dimensions of A\n    let B[1‥n, 1‥m] be a new matrix\n    for i ← 1 to m\n        do for j ← 1 to n\n            do B[j, i] ← A[i, j]\n    return B\n\nMATRIX-ADD(A, B)\n    let m, n be the dimensions of A and B\n    let C[1‥m, 1‥n] be a new matrix\n    for i ← 1 to m\n        do for j ← 1 to n\n            do C[i, j] ← A[i, j] + B[i, j]\n    return C\n\n// Example:\n// Matrix Multiplication:\n// A = [1 2]    B = [5 6]\n//     [3 4]        [7 8]\n//\n// C[1,1] = 1·5 + 2·7 = 19\n// C[1,2] = 1·6 + 2·8 = 22\n// C[2,1] = 3·5 + 4·7 = 43\n// C[2,2] = 3·6 + 4·8 = 50\n//\n// Result: [19 22]\n//         [43 50]\n//\n// Matrix Transpose:\n// A = [1 2 3]\n//     [4 5 6]\n//\n// Result: [1 4]\n//         [2 5]\n//         [3 6]\n//\n// Matrix Addition:\n// A = [1 2]    B = [5 6]\n//     [3 4]        [7 8]\n//\n// Result: [6  8]\n//         [10 12]",
    "keySteps": [
      "Multiplication: Three nested loops for dot product calculation",
      "Transpose: Swap row and column indices",
      "Addition: Element-wise sum of corresponding entries"
    ]
  },
  "matrix-exponentiation": {
    "name": "Matrix Exponentiation",
    "type": "array",
    "description": "Matrix Exponentiation is an algorithm with time complexity O(log n). It is primarily used for fast computation of matrix powers",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Fast computation of matrix powers\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Fast computation of matrix powers\n    ",
    "useCase": "Fast computation of matrix powers\n    ",
    "pseudocode": "// Compute matrix power using binary exponentiation\nMATRIX-POWER(matrix, power):\n    # Initialize result as identity matrix\n    result = IDENTITY-MATRIX(size of matrix)\n    current = matrix\n\n    # Process each bit of power\n    while power > 0:\n        # If current bit is set\n        if power mod 2 == 1:\n            # Multiply result by current matrix\n            result = MATRIX-MULTIPLY(result, current)\n\n        # Square current matrix\n        current = MATRIX-MULTIPLY(current, current)\n        # Move to next bit\n        power = power / 2\n\n    return result\n\n// Multiply two matrices\nMATRIX-MULTIPLY(A, B):\n    n = number of rows in A\n    m = number of columns in B\n    result = new n × m matrix\n\n    # Compute each element\n    for i from 1 to n:\n        for j from 1 to m:\n            sum = 0\n            for k from 1 to number of columns in A:\n                sum = sum + A[i][k] * B[k][j]\n            result[i][j] = sum\n\n    return result",
    "keySteps": []
  },
  "matrix-chain-multiplication": {
    "name": "Matrix Chain Multiplication",
    "type": "array",
    "description": "Matrix Chain Multiplication is an algorithm with time complexity O(n³). It is primarily used for finding optimal matrix       multiplication order",
    "timeComplexity": "O(n³) &nbsp;|&nbsp; Space: O(n²) &nbsp;|&nbsp; Use: Finding optimal matrix\n      multiplication order\n    ",
    "spaceComplexity": "O(n²) &nbsp;|&nbsp; Use: Finding optimal matrix\n      multiplication order\n    ",
    "useCase": "Finding optimal matrix\n      multiplication order\n    ",
    "pseudocode": "// Find minimum number of scalar multiplications\nMATRIX-CHAIN-ORDER(p):\n    n = length of p - 1\n    # Initialize tables for costs and splits\n    m = new n × n table\n    s = new n × n table\n\n    # Cost is zero when multiplying one matrix\n    for i from 1 to n:\n        m[i][i] = 0\n\n    # Consider chains of increasing length\n    for l from 2 to n:\n        for i from 1 to n - l + 1:\n            j = i + l - 1\n            m[i][j] = ∞\n\n            # Try all possible split points\n            for k from i to j - 1:\n                # Compute cost of this split\n                cost = m[i][k] + m[k+1][j] + p[i-1] * p[k] * p[j]\n                if cost < m[i][j]:\n                    m[i][j] = cost\n                    s[i][j] = k\n\n    return m and s\n\n// Print optimal parenthesization\nPRINT-OPTIMAL-PARENS(s, i, j):\n    if i == j:\n        print \"A\" + i\n    else:\n        print \"(\"\n        PRINT-OPTIMAL-PARENS(s, i, s[i][j])\n        PRINT-OPTIMAL-PARENS(s, s[i][j] + 1, j)\n        print \")\"",
    "keySteps": []
  },
  "manachers-algorithm": {
    "name": "Manacher's Algorithm",
    "type": "string",
    "description": "Manacher's Algorithm is an algorithm with time complexity O(n). It is primarily used for find longest palindromic substring",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Find longest palindromic substring\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Find longest palindromic substring\n    ",
    "useCase": "Find longest palindromic substring\n    ",
    "pseudocode": "# Manacher's Algorithm: Find longest palindromic substring\n# Input: String S[1..n]\n# Output: Longest palindromic substring in S\n\nAlgorithm MANACHER(S)\n    # Transform string to handle even-length palindromes\n    T ← \"#\" + S[1] + \"#\" + S[2] + \"#\" + ... + S[n] + \"#\"\n    n' ← length[T]\n\n    # Initialize arrays\n    P ← array of size n' filled with 0\n    C ← 1\n    R ← 1\n\n    for i ← 2 to n' do\n        # Mirror position\n        i_mirror ← 2 * C - i\n\n        # If i is within current right boundary\n        if i < R then\n            P[i] ← min(R - i, P[i_mirror])\n        end if\n\n        # Expand around center\n        while T[i + P[i] + 1] = T[i - P[i] - 1] do\n            P[i] ← P[i] + 1\n        end while\n\n        # Update center and right boundary if needed\n        if i + P[i] > R then\n            C ← i\n            R ← i + P[i]\n        end if\n    end for\n\n    # Find maximum length and center\n    max_len ← 0\n    center ← 0\n    for i ← 1 to n' do\n        if P[i] > max_len then\n            max_len ← P[i]\n            center ← i\n        end if\n    end for\n\n    # Extract and return longest palindrome\n    start ← (center - max_len) / 2\n    return S[start..start + max_len - 1]\n\n# Example:\n# Input: S = \"babad\"\n#\n# Step 1: T = \"#b#a#b#a#d#\"\n# Step 2: P = [0, 1, 0, 3, 0, 1, 0, 1, 0, 1, 0]\n# Step 3: max_len = 3, center = 4\n#\n# Output: \"bab\"",
    "keySteps": [
      "Transform string to handle even-length palindromes",
      "Initialize arrays and boundaries",
      "Expand around each center and update boundaries",
      "Find and return longest palindrome"
    ]
  },
  "manacher": {
    "name": "Manacher's Algorithm",
    "type": "tree",
    "description": "Manacher's Algorithm is an algorithm with time complexity O(n). It is primarily used for finding longest palindromic substring",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Finding longest palindromic substring\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Finding longest palindromic substring\n    ",
    "useCase": "Finding longest palindromic substring\n    ",
    "pseudocode": "MANACHER(S):\n    // Transform string to handle even-length palindromes\n    T ← \"#\" + JOIN(S, \"#\") + \"#\"\n    n ← length(T)\n    P[1..n] ← 0\n    C ← 1    // center of current palindrome\n    R ← 1    // right boundary of current palindrome\n    \n    for i ← 2 to n-1:\n        // Mirror position\n        i_mirror ← 2C - i\n        \n        if i < R:\n            P[i] ← min(R - i, P[i_mirror])\n        \n        // Expand palindrome centered at i\n        while T[i + P[i] + 1] = T[i - P[i] - 1]:\n            P[i] ← P[i] + 1\n        \n        // Update center and right boundary if needed\n        if i + P[i] > R:\n            C ← i\n            R ← i + P[i]\n    \n    // Find maximum palindrome\n    max_len ← 0\n    center ← 0\n    for i ← 1 to n:\n        if P[i] > max_len:\n            max_len ← P[i]\n            center ← i\n    \n    // Extract palindrome from original string\n    start ← (center - max_len) div 2\n    return S[start..start + max_len - 1]\n\n// Example:\n// Input: S = \"babad\"\n//\n// Transformed string T:\n// #b#a#b#a#d#\n//\n// P array:\n// [0,1,0,3,0,1,0,1,0]\n//\n// Longest palindrome: \"bab\" or \"aba\"",
    "keySteps": [
      "Linear time algorithm for finding longest palindrome",
      "Uses palindrome mirroring property for optimization",
      "Handles both odd and even length palindromes",
      "More efficient than O(n²) dynamic programming approach"
    ]
  },
  "longest-increasing-subsequence": {
    "name": "Longest Increasing Subsequence",
    "type": "algorithm",
    "description": "Find the length of the longest strictly increasing subsequence in an array",
    "timeComplexity": "O(n log n) using binary search, O(n²) using dynamic programming",
    "spaceComplexity": "O(n) for storing the dp array or patience sorting array",
    "useCase": "Finding optimal sequences, pattern matching, data analysis",
    "pseudocode": "def lengthOfLIS(nums):\n    if not nums:\n        return 0\n    \n    # dp[i] represents the length of LIS ending at index i\n    dp = [1] * len(nums)\n    \n    for i in range(1, len(nums)):\n        for j in range(i):\n            if nums[i] > nums[j]:\n                dp[i] = max(dp[i], dp[j] + 1)\n    \n    return max(dp)\n\n# Binary search approach (O(n log n))\ndef lengthOfLIS_optimized(nums):\n    if not nums:\n        return 0\n    \n    # dp[i] represents the smallest tail of all increasing subsequences of length i+1\n    dp = []\n    \n    for num in nums:\n        # Find the first number in dp that is greater than or equal to num\n        i = bisect.bisect_left(dp, num)\n        if i == len(dp):\n            dp.append(num)\n        else:\n            dp[i] = num\n    \n    return len(dp)",
    "keySteps": [
      "Initialize dp array with 1s (each element is a subsequence of length 1)",
      "For each element, check all previous elements for increasing sequence",
      "Update dp[i] if a longer increasing subsequence is found",
      "Return the maximum value in dp array"
    ]
  },
  "linked-list": {
    "name": "Linked List",
    "type": "data-structures",
    "description": "Linked List is an algorithm with time complexity O(n). It is primarily used for dynamic data storage with efficient       insertions/deletions",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Dynamic data storage with efficient\n      insertions/deletions\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Dynamic data storage with efficient\n      insertions/deletions\n    ",
    "useCase": "Dynamic data storage with efficient\n      insertions/deletions\n    ",
    "pseudocode": "// Node structure\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next = None\n\n// Singly Linked List\nclass LinkedList:\n    def __init__(self):\n        self.head = None\n\n    # Insert at beginning\n    def insert_at_beginning(self, data):\n        new_node = Node(data)\n        new_node.next = self.head\n        self.head = new_node\n\n    # Insert at end\n    def insert_at_end(self, data):\n        new_node = Node(data)\n        if not self.head:\n            self.head = new_node\n            return\n        last = self.head\n        while last.next:\n            last = last.next\n        last.next = new_node\n\n    # Delete node\n    def delete_node(self, key):\n        temp = self.head\n        if temp and temp.data == key:\n            self.head = temp.next\n            return\n        while temp and temp.next:\n            if temp.next.data == key:\n                temp.next = temp.next.next\n                return\n            temp = temp.next\n\n    # Search node\n    def search(self, key):\n        current = self.head\n        while current:\n            if current.data == key:\n                return True\n            current = current.next\n        return False\n\n// Doubly Linked List\nclass DoublyLinkedList:\n    def __init__(self):\n        self.head = None\n        self.tail = None\n\n    # Insert at beginning\n    def insert_at_beginning(self, data):\n        new_node = Node(data)\n        if not self.head:\n            self.head = new_node\n            self.tail = new_node\n            return\n        new_node.next = self.head\n        self.head.prev = new_node\n        self.head = new_node\n\n    # Insert at end\n    def insert_at_end(self, data):\n        new_node = Node(data)\n        if not self.head:\n            self.head = new_node\n            self.tail = new_node\n            return\n        self.tail.next = new_node\n        new_node.prev = self.tail\n        self.tail = new_node\n\n    # Delete node\n    def delete_node(self, key):\n        current = self.head\n        while current:\n            if current.data == key:\n                if current.prev:\n                    current.prev.next = current.next\n                else:\n                    self.head = current.next\n                if current.next:\n                    current.next.prev = current.prev\n                else:\n                    self.tail = current.prev\n                return\n            current = current.next\n\n// Circular Linked List\nclass CircularLinkedList:\n    def __init__(self):\n        self.head = None\n\n    # Insert at beginning\n    def insert_at_beginning(self, data):\n        new_node = Node(data)\n        if not self.head:\n            new_node.next = new_node\n            self.head = new_node\n            return\n        last = self.head\n        while last.next != self.head:\n            last = last.next\n        new_node.next = self.head\n        last.next = new_node\n        self.head = new_node\n\n    # Insert at end\n    def insert_at_end(self, data):\n        new_node = Node(data)\n        if not self.head:\n            new_node.next = new_node\n            self.head = new_node\n            return\n        last = self.head\n        while last.next != self.head:\n            last = last.next\n        last.next = new_node\n        new_node.next = self.head",
    "keySteps": []
  },
  "linear-search": {
    "name": "Linear Search",
    "type": "searching",
    "description": "Linear Search is an algorithm with time complexity O(n). It is primarily used for find element in unsorted array",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find element in unsorted array\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find element in unsorted array\n    ",
    "useCase": "Find element in unsorted array\n    ",
    "pseudocode": "# Linear Search: Find element in unsorted array\n# Input: Array A[1..n], target value x\n# Output: Index of x in A if found, -1 otherwise\n\nAlgorithm LINEAR-SEARCH(A, x)\n    for i ← 1 to length[A] do\n        if A[i] = x then\n            return i\n        end if\n    end for\n    return -1\n\n# Example:\n# Input: A = [4, 2, 7, 1, 3], x = 7\n#\n# Step 1: i = 1, A[1] = 4 ≠ 7\n# Step 2: i = 2, A[2] = 2 ≠ 7\n# Step 3: i = 3, A[3] = 7 = 7\n#\n# Output: 3",
    "keySteps": [
      "Initialize loop through array",
      "Compare each element with target",
      "Return index if found",
      "Return -1 if not found"
    ]
  },
  "lca": {
    "name": "Lowest Common Ancestor",
    "type": "algorithm",
    "description": "Lowest Common Ancestor is an algorithm with time complexity O(log n). It is primarily used for find lca in tree",
    "timeComplexity": "O(log n) per query &nbsp;|&nbsp; Space: O(n log n) &nbsp;|&nbsp; Use: Find LCA in tree\n    ",
    "spaceComplexity": "O(n log n) &nbsp;|&nbsp; Use: Find LCA in tree\n    ",
    "useCase": "Find LCA in tree\n    ",
    "pseudocode": "LCA-PREPROCESS(T)\n    let n be the number of vertices in T\n    let depth[1‥n] be a new array\n    let up[1‥n][0‥log n] be a new array\n\n    DFS-LCA(T, T.root, NIL, depth, up)\n    return (depth, up)\n\nDFS-LCA(T, u, p, depth, up)\n    up[u][0] ← p\n    for i ← 1 to log n\n        do if up[u][i-1] ≠ NIL\n            then up[u][i] ← up[up[u][i-1]][i-1]\n            else up[u][i] ← NIL\n\n    for each v in T.Adj[u]\n        do if v ≠ p\n            then depth[v] ← depth[u] + 1\n                DFS-LCA(T, v, u, depth, up)\n\nLCA-QUERY(u, v, depth, up)\n    if depth[u] < depth[v]\n        then swap(u, v)\n\n    for i ← log n downto 0\n        do if depth[u] - (1 << i) ≥ depth[v]\n            then u ← up[u][i]\n\n    if u = v\n        then return u\n\n    for i ← log n downto 0\n        do if up[u][i] ≠ up[v][i]\n            then u ← up[u][i]\n                v ← up[v][i]\n\n    return up[u][0]\n\n// Example:\n// Input: Tree with edges (1,2), (1,3), (2,4), (2,5), (3,6)\n//\n// Preprocessing:\n//   depth = [0, 1, 1, 2, 2, 2]\n//   up[1] = [NIL, NIL, NIL]\n//   up[2] = [1, NIL, NIL]\n//   up[3] = [1, NIL, NIL]\n//   up[4] = [2, 1, NIL]\n//   up[5] = [2, 1, NIL]\n//   up[6] = [3, 1, NIL]\n//\n// Query: LCA(4,6)\n//   Step 1: Bring 4 to depth 2\n//   Step 2: Binary search for LCA\n//   Output: 1",
    "keySteps": [
      "Preprocess: Build binary lifting table",
      "Query: Bring nodes to same depth",
      "Binary Search: Find lowest common ancestor"
    ]
  },
  "lca-dfs": {
    "name": "LCA (DFS)",
    "type": "tree",
    "description": "LCA (DFS) is an algorithm with time complexity O(n). It is primarily used for finding lowest common ancestor in       binary trees",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(h) &nbsp;|&nbsp; Use: Finding lowest common ancestor in\n      binary trees\n    ",
    "spaceComplexity": "O(h) &nbsp;|&nbsp; Use: Finding lowest common ancestor in\n      binary trees\n    ",
    "useCase": "Finding lowest common ancestor in\n      binary trees\n    ",
    "pseudocode": "// LCA using DFS\nLCA-DFS(root, p, q):\n  if root == null or root == p or root == q:\n    return root\n  \n  left = LCA-DFS(root.left, p, q)\n  right = LCA-DFS(root.right, p, q)\n  \n  if left != null and right != null:\n    return root\n  return left if left != null else right\n\n// Alternative: Using Parent Pointers\nLCA-PARENT(root, p, q):\n  ancestors = new Set()\n  while p != null:\n    ancestors.add(p)\n    p = p.parent\n  \n  while q != null:\n    if q in ancestors:\n      return q\n    q = q.parent\n  return null",
    "keySteps": [
      "Works for both binary and n-ary trees",
      "Handles cases where one node is ancestor of the other",
      "Can be optimized for repeated queries using binary lifting"
    ]
  },
  "kruskals-algorithm": {
    "name": "Kruskal's Algorithm",
    "type": "graph",
    "description": "Kruskal's Algorithm's Algorithm is an algorithm with time complexity O(E log E). It is primarily used for find minimum spanning tree",
    "timeComplexity": "O(E log E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find minimum spanning tree\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find minimum spanning tree\n    ",
    "useCase": "Find minimum spanning tree\n    ",
    "pseudocode": "# Kruskal's Algorithm's Algorithm: Find minimum spanning tree\n# Input: Graph G = (V, E) with edge weights\n# Output: Set of edges forming minimum spanning tree\n\nAlgorithm KRUSKAL(G)\n    # Initialize disjoint set for vertices\n    for each vertex v in V do\n        MAKE-SET(v)\n    end for\n\n    # Sort edges by weight\n    sort E by weight in non-decreasing order\n\n    # Initialize result\n    A ← empty set\n\n    # Process edges in order\n    for each edge (u, v) in E do\n        if FIND-SET(u) ≠ FIND-SET(v) then\n            A ← A ∪ {(u, v)}\n            UNION(u, v)\n        end if\n    end for\n\n    return A\n\n# Example:\n# Input: G = (V, E) where\n# V = {a, b, c, d}\n# E = {(a,b,1), (a,c,4), (a,d,3), (b,c,2), (b,d,5), (c,d,6)}\n#\n# Step 1: Sort edges: (a,b,1), (b,c,2), (a,d,3), (a,c,4), (b,d,5), (c,d,6)\n# Step 2: Add (a,b), (b,c), (a,d)\n#\n# Output: {(a,b), (b,c), (a,d)}",
    "keySteps": [
      "Initialize disjoint sets for vertices",
      "Sort edges by weight",
      "Process edges in order and add to MST if no cycle",
      "Return set of edges forming MST"
    ]
  },
  "kruskal": {
    "name": "Kruskal's Algorithm",
    "type": "graph",
    "description": "Kruskal's Algorithm'sis an algorithm with time complexity O(E log E). It is primarily used for minimum spanning tree in       undirected graphs",
    "timeComplexity": "O(E log E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Minimum spanning tree in\n      undirected graphs\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Minimum spanning tree in\n      undirected graphs\n    ",
    "useCase": "Minimum spanning tree in\n      undirected graphs\n    ",
    "pseudocode": "KRUSKAL(G, w):\n    A ← ∅\n    for each vertex v ∈ G.V:\n        MAKE-SET(v)\n    sort G.E into nondecreasing order by weight w\n    for each edge (u, v) ∈ G.E, taken in nondecreasing order by weight:\n        if FIND-SET(u) ≠ FIND-SET(v):\n            A ← A ∪ {(u, v)}\n            UNION(u, v)\n    return A\n\nMAKE-SET(x):\n    x.p ← x\n    x.rank ← 0\n\nUNION(x, y):\n    LINK(FIND-SET(x), FIND-SET(y))\n\nLINK(x, y):\n    if x.rank > y.rank:\n        y.p ← x\n    else:\n        x.p ← y\n        if x.rank = y.rank:\n            y.rank ← y.rank + 1\n\nFIND-SET(x):\n    if x ≠ x.p:\n        x.p ← FIND-SET(x.p)\n    return x.p\n\n// Example:\n// Input: G = (V, E) where\n// V = {a, b, c, d, e, f}\n// E = {(a,b,4), (a,c,3), (b,c,1), (b,d,2), (c,d,4), (d,e,2), (d,f,2), (e,f,3)}\n//\n// Sorted edges by weight:\n// (b,c,1), (b,d,2), (d,e,2), (d,f,2), (a,c,3), (e,f,3), (a,b,4), (c,d,4)\n//\n// MST edges in order of selection:\n// (b,c,1), (b,d,2), (d,e,2), (d,f,2), (a,c,3)\n//\n// Total weight: 10",
    "keySteps": [
      "Greedy algorithm that always selects minimum weight edge",
      "Uses disjoint-set data structure for efficient operations",
      "Produces minimum spanning tree for connected graphs",
      "Sorting edges: O(E log E)"
    ]
  },
  "kmp-algorithm": {
    "name": "Knuth-Morris-Pratt",
    "type": "graph",
    "description": "\n          A linear time pattern matching algorithm that uses a preprocessed pattern to skip\n          unnecessary comparisons.\n        ",
    "timeComplexity": "O(n + m) where n is text length and m is pattern length",
    "spaceComplexity": "O(m) for storing the prefix function",
    "useCase": "Efficient string pattern matching, DNA sequence analysis, text search",
    "pseudocode": "# Knuth-Morris-Pratt: Pattern matching in strings\n# Input: Text T[1..n], Pattern P[1..m]\n# Output: All starting positions where P occurs in T\n\nAlgorithm KMP-MATCHER(T, P)\n    n ← length[T]\n    m ← length[P]\n\n    # Compute prefix function\n    π ← COMPUTE-PREFIX-FUNCTION(P)\n\n    q ← 0  # Number of characters matched\n    for i ← 1 to n do\n        while q > 0 and P[q + 1] ≠ T[i] do\n            q ← π[q]\n        end while\n        if P[q + 1] = T[i] then\n            q ← q + 1\n        end if\n        if q = m then\n            print \"Pattern occurs at position\" i - m\n            q ← π[q]\n        end if\n    end for\n\nAlgorithm COMPUTE-PREFIX-FUNCTION(P)\n    m ← length[P]\n    π[1] ← 0\n    k ← 0\n    for q ← 2 to m do\n        while k > 0 and P[k + 1] ≠ P[q] do\n            k ← π[k]\n        end while\n        if P[k + 1] = P[q] then\n            k ← k + 1\n        end if\n        π[q] ← k\n    end for\n    return π\n\n# Example:\n# Input: T = \"ABABDABACDABABCABAB\", P = \"ABABCABAB\"\n#\n# Step 1: π = [0, 0, 1, 2, 0, 1, 2, 3, 4]\n# Step 2: Match at position 10\n#\n# Output: Pattern occurs at position 10",
    "keySteps": [
      "Compute prefix function for pattern",
      "Match pattern against text using prefix function",
      "Skip unnecessary comparisons using prefix function",
      "Report all occurrences of pattern"
    ]
  },
  "karatsuba-multiplication": {
    "name": "Karatsuba Multiplication",
    "type": "number-theory",
    "description": "Karatsuba Multiplication is an algorithm with time complexity O(n^log₂3). It is primarily used for fast       multiplication of large integers",
    "timeComplexity": "O(n^log₂3) ≈ O(n^1.585) &nbsp;|&nbsp; Space: O(log n) &nbsp;|&nbsp; Use: Fast\n      multiplication of large integers\n    ",
    "spaceComplexity": "O(log n) &nbsp;|&nbsp; Use: Fast\n      multiplication of large integers\n    ",
    "useCase": "Fast\n      multiplication of large integers\n    ",
    "pseudocode": "KARATSUBA(x, y):\n    n ← max(length(x), length(y))\n    if n ≤ 1:\n        return x × y\n    \n    // Split numbers into high and low parts\n    m ← ⌈n/2⌉\n    x₁ ← x div 10^m\n    x₀ ← x mod 10^m\n    y₁ ← y div 10^m\n    y₀ ← y mod 10^m\n    \n    // Recursive calls\n    z₂ ← KARATSUBA(x₁, y₁)\n    z₀ ← KARATSUBA(x₀, y₀)\n    z₁ ← KARATSUBA(x₁ + x₀, y₁ + y₀) - z₂ - z₀\n    \n    // Combine results\n    return z₂ × 10^(2m) + z₁ × 10^m + z₀\n\n// Example:\n// Input: x = 1234, y = 5678\n//\n// Split:\n// x₁ = 12, x₀ = 34\n// y₁ = 56, y₀ = 78\n//\n// Recursive calls:\n// z₂ = KARATSUBA(12, 56) = 672\n// z₀ = KARATSUBA(34, 78) = 2652\n// z₁ = KARATSUBA(46, 134) - 672 - 2652 = 6164 - 672 - 2652 = 2840\n//\n// Combine:\n// 672 × 10⁴ + 2840 × 10² + 2652 = 7,006,652",
    "keySteps": [
      "Divide-and-conquer algorithm for integer multiplication",
      "Reduces number of multiplications from 4 to 3",
      "More efficient than traditional O(n²) multiplication",
      "Recurrence: T(n) = 3T(n/2) + O(n)"
    ]
  },
  "kahn-topological-sort": {
    "name": "Kahn's Topological Sort",
    "type": "graph",
    "description": "Kahn's Algorithm is an algorithm with time complexity O(V + E). It is primarily used for topological sorting of dags",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Topological sorting of DAGs\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Topological sorting of DAGs\n    ",
    "useCase": "Topological sorting of DAGs\n    ",
    "pseudocode": "KAHN-TOPOLOGICAL-SORT(G):\n    // G is a directed acyclic graph\n    // Returns topological order or detects cycle\n    in_degree[1..V] ← 0\n    for each vertex v in G:\n        for each neighbor u of v:\n            in_degree[u] ← in_degree[u] + 1\n    \n    Q ← empty queue\n    for each vertex v in G:\n        if in_degree[v] = 0:\n            Q.enqueue(v)\n    \n    topo_order ← empty list\n    while Q is not empty:\n        v ← Q.dequeue()\n        topo_order.append(v)\n        \n        for each neighbor u of v:\n            in_degree[u] ← in_degree[u] - 1\n            if in_degree[u] = 0:\n                Q.enqueue(u)\n    \n    if length(topo_order) ≠ V:\n        return \"Graph contains a cycle\"\n    return topo_order\n\n// Example:\n// Graph G:\n// 1 → 2 → 3\n// ↓   ↓   ↓\n// 4 → 5 → 6\n//\n// Initial in_degree:\n// [0,1,1,1,2,2]\n//\n// Topological order:\n// [1,2,4,3,5,6]",
    "keySteps": [
      "Finds topological order of vertices in a DAG",
      "Can detect cycles in directed graphs",
      "Uses in-degree counting and queue-based approach",
      "More efficient than DFS-based approach for large graphs"
    ]
  },
  "kadanes-algorithm": {
    "name": "Kadane's Algorithm",
    "type": "array",
    "description": "Kadane's Algorithm is an algorithm with time complexity O(n). It is primarily used for finding maximum subarray sum",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Finding maximum subarray sum\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Finding maximum subarray sum\n    ",
    "useCase": "Finding maximum subarray sum\n    ",
    "pseudocode": "// Find maximum subarray sum\nKADANE(A):\n  max_ending_here = A[1]\n  max_so_far = A[1]\n  for i = 2 to A.length:\n    max_ending_here = max(A[i], max_ending_here + A[i])\n    max_so_far = max(max_so_far, max_ending_here)\n  return max_so_far\n\n// Find maximum subarray sum with indices\nKADANE-WITH-INDICES(A):\n  max_ending_here = A[1]\n  max_so_far = A[1]\n  start = 1\n  end = 1\n  temp_start = 1\n  for i = 2 to A.length:\n    if A[i] > max_ending_here + A[i]:\n      max_ending_here = A[i]\n      temp_start = i\n    else:\n      max_ending_here = max_ending_here + A[i]\n    if max_ending_here > max_so_far:\n      max_so_far = max_ending_here\n      start = temp_start\n      end = i\n  return (max_so_far, start, end)\n\n// Find maximum circular subarray sum\nKADANE-CIRCULAR(A):\n  max_kadane = KADANE(A)\n  max_wrap = 0\n  for i = 1 to A.length:\n    max_wrap = max_wrap + A[i]\n    A[i] = -A[i]\n  max_wrap = max_wrap + KADANE(A)\n  return max(max_kadane, max_wrap)",
    "keySteps": []
  },
  "jump-search-algorithm": {
    "name": "Jump Search",
    "type": "Algorithm",
    "description": "Jump Search is an algorithm with time complexity O(√n). It is primarily used for search in sorted arrays",
    "timeComplexity": "O(√n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Search in sorted arrays\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Search in sorted arrays\n    ",
    "useCase": "Search in sorted arrays\n    ",
    "pseudocode": "// Jump search in sorted array\nJUMP-SEARCH(A, x):\n    n ← length[A]\n    step ← ⌊√n⌋\n    prev ← 0\n    // Jump through array\n    while A[min(step, n)] < x:\n        prev ← step\n        step ← step + ⌊√n⌋\n        if prev ≥ n:\n            return -1\n    // Linear search in block\n    while A[prev] < x:\n        prev ← prev + 1\n        if prev = min(step, n):\n            return -1\n    if A[prev] = x:\n        return prev\n    return -1\n\n// Example:\n// Input: A = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], x = 7\n//\n// Execution:\n// 1. step = 3, prev = 0\n// 2. A[3] = 4 < 7: prev = 3, step = 6\n// 3. A[6] = 7 < 7: false\n// 4. Linear search from index 3 to 6\n// 5. Found at index 6\n//\n// Output: 6",
    "keySteps": [
      "Initialize: Calculate jump step size",
      "Jump: Skip through array in fixed steps",
      "Search: Linear search in identified block"
    ]
  },
  "job-scheduling": {
    "name": "Job Scheduling",
    "type": "Algorithm",
    "description": "Job Scheduling is an algorithm with time complexity O(n log n). It is primarily used for schedule jobs to minimize       completion time",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Schedule jobs to minimize\n      completion time\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Schedule jobs to minimize\n      completion time\n    ",
    "useCase": "Schedule jobs to minimize\n      completion time\n    ",
    "pseudocode": "JOB-SCHEDULING(jobs)\n    n ← length[jobs]\n    sort jobs by finish time\n    let schedule[1‥n] be a new array\n    schedule[1] ← jobs[1]\n    j ← 1\n    for i ← 2 to n\n        do if jobs[i].start ≥ jobs[j].finish\n            then schedule[i] ← jobs[i]\n                j ← i\n    return schedule\n\n// Example:\n// Input: jobs = [\n//   {start: 1, finish: 2, profit: 50},\n//   {start: 3, finish: 5, profit: 20},\n//   {start: 6, finish: 19, profit: 100},\n//   {start: 2, finish: 100, profit: 200}\n// ]\n//\n// Step 1: Sort by finish time\n//         [{1,2,50}, {3,5,20}, {6,19,100}, {2,100,200}]\n//\n// Step 2: Select jobs\n//         Select job 1 (1-2)\n//         Skip job 2 (overlaps)\n//         Select job 3 (6-19)\n//         Skip job 4 (overlaps)\n//\n// Output: [{1,2,50}, {6,19,100}]",
    "keySteps": [
      "Sort: Jobs by finish time",
      "Select: First job",
      "Iterate: Through remaining jobs",
      "Add: Non-overlapping jobs to schedule"
    ]
  },
  "interval-scheduling": {
    "name": "Interval Scheduling",
    "type": "greedy",
    "description": "Interval Scheduling is an algorithm with time complexity O(n log n). It is primarily used for maximum non-overlapping       intervals",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Maximum non-overlapping\n      intervals\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Maximum non-overlapping\n      intervals\n    ",
    "useCase": "Maximum non-overlapping\n      intervals\n    ",
    "pseudocode": "INTERVAL-SCHEDULING(I):\n    // I is a list of intervals [start, end]\n    // Returns maximum set of non-overlapping intervals\n    \n    // Sort intervals by end time\n    SORT(I, key = end_time)\n    \n    selected ← empty list\n    last_end ← -∞\n    \n    for each interval [start, end] in I:\n        if start ≥ last_end:\n            selected.append([start, end])\n            last_end ← end\n    \n    return selected\n\n// Example:\n// Input intervals:\n// [1,4], [2,5], [3,6], [4,7], [5,8]\n//\n// Sorted by end time:\n// [1,4], [2,5], [3,6], [4,7], [5,8]\n//\n// Selected intervals:\n// [1,4], [4,7]",
    "keySteps": [
      "Greedy algorithm for interval selection",
      "Always selects interval with earliest end time",
      "Produces optimal solution for maximum non-overlapping intervals",
      "Optimal greedy solution for interval scheduling"
    ]
  },
  "interpolation-search": {
    "name": "Interpolation Search",
    "type": "searching",
    "description": "Interpolation Search is an algorithm with time complexity O(log log n). It is primarily used for find element in uniformly       distributed sorted array",
    "timeComplexity": "O(log log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find element in uniformly\n      distributed sorted array\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find element in uniformly\n      distributed sorted array\n    ",
    "useCase": "Find element in uniformly\n      distributed sorted array\n    ",
    "pseudocode": "# Interpolation Search: Find element in uniformly distributed sorted array\n# Input: Sorted array A[1..n], target value x\n# Output: Index of x in A if found, -1 otherwise\n\nAlgorithm INTERPOLATION-SEARCH(A, x)\n    low ← 1\n    high ← length[A]\n\n    while low ≤ high and x ≥ A[low] and x ≤ A[high] do\n        # Calculate position using interpolation formula\n        pos ← low + ((x - A[low]) * (high - low)) / (A[high] - A[low])\n\n        if A[pos] = x then\n            return pos\n        end if\n\n        if A[pos] < x then\n            low ← pos + 1\n        else\n            high ← pos - 1\n        end if\n    end while\n\n    return -1\n\n# Example:\n# Input: A = [10, 20, 30, 40, 50, 60, 70, 80, 90], x = 50\n#\n# Step 1: low = 1, high = 9\n#         pos = 1 + ((50-10)*(9-1))/(90-10) = 5\n#         A[5] = 50\n#\n# Output: 5",
    "keySteps": [
      "Initialize search boundaries",
      "Calculate position using interpolation formula",
      "Adjust boundaries based on comparison",
      "Return index if found, -1 otherwise"
    ]
  },
  "insertion-sort": {
    "name": "Insertion Sort",
    "type": "sorting",
    "description": "Insertion Sort is an algorithm with time complexity O(n²). It is primarily used for sorting array in-place",
    "timeComplexity": "O(n²) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Sorting array in-place\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Sorting array in-place\n    ",
    "useCase": "Sorting array in-place\n    ",
    "pseudocode": "# Insertion Sort: Build sorted array one element at a time\n# Input: Array A[1..n] of n elements\n# Output: Array A sorted in non-decreasing order\n\nINSERTION-SORT(A)\n    n ← length[A]    # Number of elements in array\n\n    # Start from second element (index 2)\n    for j ← 2 to n do\n        key ← A[j]    # Current element to insert\n        i ← j - 1     # Start comparing with previous element\n\n        # Move elements greater than key one position ahead\n        while i > 0 and A[i] > key do\n            A[i+1] ← A[i]    # Shift element right\n            i ← i - 1         # Move left\n        end while\n\n        A[i+1] ← key    # Insert key in correct position\n    end for\n\n# Example:\n# Input: A = [5, 2, 4, 6, 1, 3]\n# Pass 1: [2, 5, 4, 6, 1, 3]  # Insert 2\n# Pass 2: [2, 4, 5, 6, 1, 3]  # Insert 4\n# Pass 3: [2, 4, 5, 6, 1, 3]  # Insert 6\n# Pass 4: [1, 2, 4, 5, 6, 3]  # Insert 1\n# Pass 5: [1, 2, 3, 4, 5, 6]  # Insert 3\n# Output: [1, 2, 3, 4, 5, 6]",
    "keySteps": []
  },
  "inorder-traversal": {
    "name": "Inorder Traversal",
    "type": "tree",
    "description": "Inorder Tree Traversal is an algorithm with time complexity O(n). It is primarily used for binary tree traversal       (left-root-right)",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(h) &nbsp;|&nbsp; Use: Binary tree traversal\n      (left-root-right)\n    ",
    "spaceComplexity": "O(h) &nbsp;|&nbsp; Use: Binary tree traversal\n      (left-root-right)\n    ",
    "useCase": "Binary tree traversal\n      (left-root-right)\n    ",
    "pseudocode": "// Recursive Inorder Traversal\nINORDER-TREE-WALK(x):\n    if x ≠ NIL:\n        INORDER-TREE-WALK(x.left)\n        print x.key\n        INORDER-TREE-WALK(x.right)\n\n// Iterative Inorder Traversal using Stack\nITERATIVE-INORDER(x):\n    S ← empty stack\n    current ← x\n    while current ≠ NIL or S is not empty:\n        while current ≠ NIL:\n            PUSH(S, current)\n            current ← current.left\n        current ← POP(S)\n        print current.key\n        current ← current.right\n\n// Morris Inorder Traversal (Threaded Binary Tree)\nMORRIS-INORDER(root):\n    current ← root\n    while current ≠ NIL:\n        if current.left = NIL:\n            print current.key\n            current ← current.right\n        else:\n            // Find inorder predecessor\n            predecessor ← current.left\n            while predecessor.right ≠ NIL and predecessor.right ≠ current:\n                predecessor ← predecessor.right\n            \n            if predecessor.right = NIL:\n                predecessor.right ← current\n                current ← current.left\n            else:\n                predecessor.right ← NIL\n                print current.key\n                current ← current.right\n\n// Example:\n// Input: Binary tree\n//        4\n//      /   \\\\\n//     2     6\n//    / \\\\   / \\\\\n//   1   3 5   7\n//\n// Inorder traversal: 1 2 3 4 5 6 7",
    "keySteps": [
      "Recursive: Simple but uses call stack space",
      "Iterative: Uses explicit stack, better for large trees",
      "Morris: O(1) space, modifies tree structure temporarily",
      "Binary Search Tree validation"
    ]
  },
  "hungarian": {
    "name": "Hungarian Algorithm",
    "type": "Algorithm",
    "description": "Hungarian Algorithm is an algorithm with time complexity O(n³). It is primarily used for solve assignment problem",
    "timeComplexity": "O(n³) &nbsp;|&nbsp; Space: O(n²) &nbsp;|&nbsp; Use: Solve assignment problem\n    ",
    "spaceComplexity": "O(n²) &nbsp;|&nbsp; Use: Solve assignment problem\n    ",
    "useCase": "Solve assignment problem\n    ",
    "pseudocode": "HUNGARIAN(C)\n1  n = C.rows\n2  // Step 1: Subtract row minima\n3  for i = 1 to n\n4      row_min = min(C[i][j] for j = 1 to n)\n5      for j = 1 to n\n6          C[i][j] = C[i][j] - row_min\n7\n8  // Step 2: Subtract column minima\n9  for j = 1 to n\n10     col_min = min(C[i][j] for i = 1 to n)\n11     for i = 1 to n\n12         C[i][j] = C[i][j] - col_min\n13\n14 // Step 3: Cover all zeros with minimum lines\n15 while true\n16     // Find minimum uncovered value\n17     min_val = ∞\n18     for i = 1 to n\n19         for j = 1 to n\n20             if not covered[i] and not covered[j]\n21                 min_val = min(min_val, C[i][j])\n22\n23     // Subtract from uncovered rows, add to covered columns\n24     for i = 1 to n\n25         for j = 1 to n\n26             if not covered[i] and not covered[j]\n27                 C[i][j] = C[i][j] - min_val\n28             else if covered[i] and covered[j]\n29                 C[i][j] = C[i][j] + min_val\n30\n31     // Try to find complete matching\n32     matching = FIND-MATCHING(C)\n33     if size(matching) == n\n34         return matching\n35\n36 FIND-MATCHING(C)\n37     n = C.rows\n38     matching = {}\n39     for i = 1 to n\n40         visited = [False] * n\n41         if DFS(i, visited, matching)\n42             continue\n43     return matching\n44\n45 DFS(u, visited, matching)\n46     for v = 1 to n\n47         if not visited[v] and C[u][v] == 0\n48             visited[v] = true\n49             if v not in matching or DFS(matching[v], visited, matching)\n50                 matching[v] = u\n51                 return true\n52     return false\n\n// Example:\n// Input: C = [[5, 2, 3],\n//             [2, 4, 6],\n//             [3, 6, 8]]\n//\n// Step 1: Subtract row minima\n//         [[3, 0, 1],\n//          [0, 2, 4],\n//          [0, 3, 5]]\n//\n// Step 2: Subtract column minima\n//         [[3, 0, 0],\n//          [0, 2, 3],\n//          [0, 3, 4]]\n//\n// Step 3: Find complete matching\n//         Matching: {(1,2), (2,1), (3,3)}\n//\n// Final assignment: [(1,2), (2,1), (3,3)]",
    "keySteps": [
      "Subtract: Row and column minima",
      "Cover: All zeros with minimum lines",
      "Find: Complete matching using DFS"
    ]
  },
  "huffman-coding": {
    "name": "Huffman Coding",
    "type": "Algorithm",
    "description": "Huffman Coding is an algorithm with time complexity O(n log n). It is primarily used for optimal prefix coding for data       compression",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Optimal prefix coding for data\n      compression\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Optimal prefix coding for data\n      compression\n    ",
    "useCase": "Optimal prefix coding for data\n      compression\n    ",
    "pseudocode": "HUFFMAN(C)\n    n ← |C|\n    Q ← C  // Min-priority queue\n    for i ← 1 to n - 1\n        do allocate a new node z\n            z.left ← x ← EXTRACT-MIN(Q)\n            z.right ← y ← EXTRACT-MIN(Q)\n            z.freq ← x.freq + y.freq\n            INSERT(Q, z)\n    return EXTRACT-MIN(Q)  // Return root of tree\n\n// Example:\n// Input: C = [\n//   {char: 'a', freq: 45},\n//   {char: 'b', freq: 13},\n//   {char: 'c', freq: 12},\n//   {char: 'd', freq: 16},\n//   {char: 'e', freq: 9},\n//   {char: 'f', freq: 5}\n// ]\n//\n// Step 1: Create leaf nodes\n//         [a:45, b:13, c:12, d:16, e:9, f:5]\n//\n// Step 2: Combine f(5) and e(9) → 14\n//         [a:45, b:13, c:12, d:16, fe:14]\n//\n// Step 3: Combine c(12) and b(13) → 25\n//         [a:45, d:16, fe:14, cb:25]\n//\n// Step 4: Combine fe(14) and d(16) → 30\n//         [a:45, cb:25, fed:30]\n//\n// Step 5: Combine cb(25) and fed(30) → 55\n//         [a:45, cbfed:55]\n//\n// Step 6: Combine a(45) and cbfed(55) → 100\n//         [acbfed:100]\n//\n// Output: Huffman codes\n// a: 0\n// b: 101\n// c: 100\n// d: 111\n// e: 1101\n// f: 1100",
    "keySteps": [
      "Create: Leaf nodes for each character",
      "Build: Min-priority queue",
      "Combine: Two lowest frequency nodes",
      "Repeat: Until single tree remains"
    ]
  },
  "hopcroft-karp": {
    "name": "Hopcroft-Karp's Algorithm",
    "type": "graph",
    "description": "Hopcroft-Karp's Algorithm's Algorithm is an algorithm with time complexity O(√V E). It is primarily used for maximum bipartite matching",
    "timeComplexity": "O(√V E) &nbsp;|&nbsp; Space: O(V + E) &nbsp;|&nbsp; Use: Maximum bipartite matching\n    ",
    "spaceComplexity": "O(V + E) &nbsp;|&nbsp; Use: Maximum bipartite matching\n    ",
    "useCase": "Maximum bipartite matching\n    ",
    "pseudocode": "HOPCROFT-KARP(G):\n    // G is a bipartite graph with left set L and right set R\n    // Returns maximum matching\n    matching ← empty map  // stores current matching\n    dist ← empty map      // stores distances for BFS\n    \n    function BFS():\n        Q ← empty queue\n        for each u in L:\n            if u is unmatched:\n                dist[u] ← 0\n                Q.enqueue(u)\n            else:\n                dist[u] ← ∞\n        dist[nil] ← ∞\n        \n        while Q is not empty:\n            u ← Q.dequeue()\n            if dist[u] < dist[nil]:\n                for each v in G.adj[u]:\n                    if dist[matching[v]] = ∞:\n                        dist[matching[v]] ← dist[u] + 1\n                        Q.enqueue(matching[v])\n        return dist[nil] ≠ ∞\n    \n    function DFS(u):\n        if u ≠ nil:\n            for each v in G.adj[u]:\n                if dist[matching[v]] = dist[u] + 1:\n                    if DFS(matching[v]):\n                        matching[v] ← u\n                        matching[u] ← v\n                        return true\n            dist[u] ← ∞\n            return false\n        return true\n    \n    // Main algorithm\n    while BFS():\n        for each u in L:\n            if u is unmatched:\n                DFS(u)\n    \n    return matching\n\n// Example:\n// Bipartite graph G:\n// L = {1, 2, 3}\n// R = {4, 5, 6}\n// Edges: (1,4), (1,5), (2,5), (2,6), (3,4), (3,6)\n//\n// Maximum matching:\n// 1-4, 2-5, 3-6",
    "keySteps": [
      "Finds maximum matching in bipartite graphs",
      "Uses layered graph approach with BFS and DFS",
      "More efficient than Ford-Fulkerson Algorithm for bipartite graphs",
      "Optimal for dense bipartite graphs"
    ]
  },
  "heavy-light-decomposition": {
    "name": "Heavy Light Decomposition",
    "type": "tree",
    "description": "Heavy-Light Decomposition is an algorithm with time complexity O(log n). It is primarily used for tree path queries",
    "timeComplexity": "O(log n) per query &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Tree path queries\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Tree path queries\n    ",
    "useCase": "Tree path queries\n    ",
    "pseudocode": "HLD(G)\n    let size[1‥n] be a new array\n    let parent[1‥n] be a new array\n    let depth[1‥n] be a new array\n    let head[1‥n] be a new array\n    let pos[1‥n] be a new array\n\n    DFS-SIZE(G, 1, 0)\n    DFS-HLD(G, 1, 1)\n    return (size, parent, depth, head, pos)\n\nDFS-SIZE(G, u, p)\n    size[u] ← 1\n    parent[u] ← p\n    for each v in G.Adj[u]\n        do if v ≠ p\n            then depth[v] ← depth[u] + 1\n                DFS-SIZE(G, v, u)\n                size[u] ← size[u] + size[v]\n\nDFS-HLD(G, u, h)\n    head[u] ← h\n    let heavy ← NIL\n    let max_size ← 0\n\n    for each v in G.Adj[u]\n        do if v ≠ parent[u] and size[v] > max_size\n            then heavy ← v\n                max_size ← size[v]\n\n    if heavy ≠ NIL\n        then DFS-HLD(G, heavy, h)\n            for each v in G.Adj[u]\n                do if v ≠ parent[u] and v ≠ heavy\n                    then DFS-HLD(G, v, v)\n\n// Example:\n// Input: Tree with edges (1,2), (1,3), (2,4), (2,5), (3,6)\n//\n// DFS-SIZE:\n//   size = [6, 3, 2, 1, 1, 1]\n//   parent = [0, 1, 1, 2, 2, 3]\n//   depth = [0, 1, 1, 2, 2, 2]\n//\n// DFS-HLD:\n//   head = [1, 1, 3, 1, 1, 3]\n//   pos = [1, 2, 4, 3, 5, 6]\n//\n// Output: Decomposed tree with heavy paths",
    "keySteps": [
      "Compute: Subtree sizes and parent pointers",
      "Identify: Heavy edges and light edges",
      "Decompose: Tree into heavy paths"
    ]
  },
  "heap": {
    "name": "Heap",
    "type": "log n",
    "description": "Heap is an algorithm with time complexity O(log n). It is primarily used for priority queue implementation",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Priority queue implementation\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Priority queue implementation\n    ",
    "useCase": "Priority queue implementation\n    ",
    "pseudocode": "// Get parent index\nPARENT(i):\n  return ⌊i/2⌋\n\n// Get left child index\nLEFT(i):\n  return 2i\n\n// Get right child index\nRIGHT(i):\n  return 2i + 1\n\n// Maintain heap property\nMAX-HEAPIFY(A, i):\n  l = LEFT(i)\n  r = RIGHT(i)\n  largest = i\n  if l ≤ A.heap-size and A[l] > A[i]:\n    largest = l\n  if r ≤ A.heap-size and A[r] > A[largest]:\n    largest = r\n  if largest ≠ i:\n    exchange A[i] with A[largest]\n    MAX-HEAPIFY(A, largest)\n\n// Build max heap\nBUILD-MAX-HEAP(A):\n  A.heap-size = A.length\n  for i = ⌊A.length/2⌋ downto 1:\n    MAX-HEAPIFY(A, i)\n\n// Extract maximum element\nHEAP-EXTRACT-MAX(A):\n  if A.heap-size < 1:\n    error \"heap underflow\"\n  max = A[1]\n  A[1] = A[A.heap-size]\n  A.heap-size = A.heap-size - 1\n  MAX-HEAPIFY(A, 1)\n  return max\n\n// Increase key value\nHEAP-INCREASE-KEY(A, i, key):\n  if key < A[i]:\n    error \"new key is smaller than current key\"\n  A[i] = key\n  while i > 1 and A[PARENT(i)] < A[i]:\n    exchange A[i] with A[PARENT(i)]\n    i = PARENT(i)\n\n// Insert new element\nMAX-HEAP-INSERT(A, key):\n  A.heap-size = A.heap-size + 1\n  A[A.heap-size] = -∞\n  HEAP-INCREASE-KEY(A, A.heap-size, key)",
    "keySteps": []
  },
  "heap-sort": {
    "name": "Heap Sort",
    "type": "Algorithm",
    "description": "Heap Sort is an algorithm with time complexity O(n log n). It is primarily used for in-place sorting with guaranteed       performance",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: In-place sorting with guaranteed\n      performance\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: In-place sorting with guaranteed\n      performance\n    ",
    "useCase": "In-place sorting with guaranteed\n      performance\n    ",
    "pseudocode": "// Standard Heap Sort\nHEAP-SORT(A):\n    n = len(A)\n\n    # Build max heap\n    for i = n//2 - 1 downto 0:\n        MAX-HEAPIFY(A, n, i)\n\n    # Extract elements one by one\n    for i = n-1 downto 0:\n        # Move current root to end\n        swap(A[0], A[i])\n        # Heapify reduced heap\n        MAX-HEAPIFY(A, i, 0)\n\nMAX-HEAPIFY(A, n, i):\n    largest = i\n    left = 2*i + 1\n    right = 2*i + 2\n\n    # Find largest among root and children\n    if left < n and A[left] > A[largest]:\n        largest = left\n    if right < n and A[right] > A[largest]:\n        largest = right\n\n    # If root is not largest, swap and heapify\n    if largest != i:\n        swap(A[i], A[largest])\n        MAX-HEAPIFY(A, n, largest)\n\n// Min Heap Sort\nMIN-HEAP-SORT(A):\n    n = len(A)\n\n    # Build min heap\n    for i = n//2 - 1 downto 0:\n        MIN-HEAPIFY(A, n, i)\n\n    # Extract elements one by one\n    for i = n-1 downto 0:\n        # Move current root to end\n        swap(A[0], A[i])\n        # Heapify reduced heap\n        MIN-HEAPIFY(A, i, 0)\n\nMIN-HEAPIFY(A, n, i):\n    smallest = i\n    left = 2*i + 1\n    right = 2*i + 2\n\n    # Find smallest among root and children\n    if left < n and A[left] < A[smallest]:\n        smallest = left\n    if right < n and A[right] < A[smallest]:\n        smallest = right\n\n    # If root is not smallest, swap and heapify\n    if smallest != i:\n        swap(A[i], A[smallest])\n        MIN-HEAPIFY(A, n, smallest)\n\n// Heap Sort with Custom Comparator\nHEAP-SORT-COMPARATOR(A, compare):\n    n = len(A)\n\n    # Build heap with custom comparator\n    for i = n//2 - 1 downto 0:\n        HEAPIFY-COMPARATOR(A, n, i, compare)\n\n    # Extract elements one by one\n    for i = n-1 downto 0:\n        swap(A[0], A[i])\n        HEAPIFY-COMPARATOR(A, i, 0, compare)\n\nHEAPIFY-COMPARATOR(A, n, i, compare):\n    target = i\n    left = 2*i + 1\n    right = 2*i + 2\n\n    # Find target using comparator\n    if left < n and compare(A[left], A[target]):\n        target = left\n    if right < n and compare(A[right], A[target]):\n        target = right\n\n    # If root is not target, swap and heapify\n    if target != i:\n        swap(A[i], A[target])\n        HEAPIFY-COMPARATOR(A, n, target, compare)",
    "keySteps": []
  },
  "heap-implementation": {
    "name": "Heap Implementation",
    "type": "Algorithm",
    "description": "Heap Implementation is an algorithm with time complexity O(log n). It is primarily used for priority queue operations",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Priority queue operations\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Priority queue operations\n    ",
    "useCase": "Priority queue operations\n    ",
    "pseudocode": "// Get parent index\nPARENT(i):\n    return ⌊i/2⌋\n\n// Get left child index\nLEFT(i):\n    return 2i\n\n// Get right child index\nRIGHT(i):\n    return 2i + 1\n\n// Maintain heap property\nMAX-HEAPIFY(A, i):\n    l ← LEFT(i)\n    r ← RIGHT(i)\n    largest ← i\n    if l ≤ A.heap-size and A[l] > A[i]:\n        largest ← l\n    if r ≤ A.heap-size and A[r] > A[largest]:\n        largest ← r\n    if largest ≠ i:\n        exchange A[i] with A[largest]\n        MAX-HEAPIFY(A, largest)\n\n// Build max heap\nBUILD-MAX-HEAP(A):\n    A.heap-size ← A.length\n    for i ← ⌊A.length/2⌋ downto 1:\n        MAX-HEAPIFY(A, i)\n\n// Extract maximum element\nHEAP-EXTRACT-MAX(A):\n    if A.heap-size < 1:\n        error \"heap underflow\"\n    max ← A[1]\n    A[1] ← A[A.heap-size]\n    A.heap-size ← A.heap-size - 1\n    MAX-HEAPIFY(A, 1)\n    return max\n\n// Increase key value\nHEAP-INCREASE-KEY(A, i, key):\n    if key < A[i]:\n        error \"new key is smaller than current key\"\n    A[i] ← key\n    while i > 1 and A[PARENT(i)] < A[i]:\n        exchange A[i] with A[PARENT(i)]\n        i ← PARENT(i)\n\n// Insert new element\nMAX-HEAP-INSERT(A, key):\n    A.heap-size ← A.heap-size + 1\n    A[A.heap-size] ← -∞\n    HEAP-INCREASE-KEY(A, A.heap-size, key)\n\n// Example:\n// Input: [4, 1, 3, 2, 16, 9, 10, 14, 8, 7]\n//\n// After BUILD-MAX-HEAP:\n//       16\n//     /    \\\\\n//   14      10\n//  /  \\\\    /  \\\\\n// 8    7  9    3\n// / \\\\  /\n// 2  4 1\n//\n// After HEAP-EXTRACT-MAX:\n//       14\n//     /    \\\\\n//   8       10\n//  / \\\\     / \\\\\n// 2   7   9   3\n// / \\\\\n// 1   4\n//\n// After MAX-HEAP-INSERT(15):\n//       15\n//     /    \\\\\n//   14      10\n//  /  \\\\    /  \\\\\n// 8    7  9    3\n// / \\\\  /\n// 2  4 1",
    "keySteps": [
      "Build: Create max heap from array using heapify",
      "Extract: Remove and return maximum element",
      "Insert: Add new element maintaining heap property"
    ]
  },
  "hash-table": {
    "name": "Hash Table",
    "type": "data-structures",
    "description": "Hash Table is an algorithm with time complexity O(1). It is primarily used for fast key-value storage",
    "timeComplexity": "O(1) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Fast key-value storage\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Fast key-value storage\n    ",
    "useCase": "Fast key-value storage\n    ",
    "pseudocode": "// Hash function\nHASH(k, m):\n  return k mod m\n\n// Initialize table\nHASH-TABLE-INIT(T, m):\n  T.size = m\n  T.table = new array[m]\n  for i = 1 to m:\n    T.table[i] = NIL\n\n// Insert key-value pair\nHASH-INSERT(T, k, v):\n  h = HASH(k, T.size)\n  if T.table[h] == NIL:\n    T.table[h] = new list\n  LIST-INSERT(T.table[h], (k, v))\n\n// Search for key\nHASH-SEARCH(T, k):\n  h = HASH(k, T.size)\n  if T.table[h] == NIL:\n    return NIL\n  for each (key, value) in T.table[h]:\n    if key == k:\n      return value\n  return NIL\n\n// Delete key\nHASH-DELETE(T, k):\n  h = HASH(k, T.size)\n  if T.table[h] == NIL:\n    return\n  for each (key, value) in T.table[h]:\n    if key == k:\n      LIST-DELETE(T.table[h], (key, value))\n      return",
    "keySteps": []
  },
  "grid-traversal": {
    "name": "Grid Traversal",
    "type": "Algorithm",
    "description": "Grid Traversal is an algorithm with time complexity O(mn). It is primarily used for matrix traversal and path finding",
    "timeComplexity": "O(mn) &nbsp;|&nbsp; Space: O(mn) &nbsp;|&nbsp; Use: Matrix traversal and path finding\n    ",
    "spaceComplexity": "O(mn) &nbsp;|&nbsp; Use: Matrix traversal and path finding\n    ",
    "useCase": "Matrix traversal and path finding\n    ",
    "pseudocode": "GRID-TRAVERSAL(G)\n    let m be the number of rows in G\n    let n be the number of columns in G\n    let visited[1‥m][1‥n] be a new array\n    let result[1‥m][1‥n] be a new array\n\n    for i ← 1 to m\n        do for j ← 1 to n\n            do visited[i][j] ← false\n               result[i][j] ← 0\n\n    let queue be a new empty queue\n    queue.enqueue((1,1))\n    visited[1][1] ← true\n    result[1][1] ← 1\n\n    while queue is not empty\n        do (i,j) ← queue.dequeue()\n           for each (di,dj) in [(0,1), (1,0), (0,-1), (-1,0)]\n               do ni ← i + di\n                  nj ← j + dj\n                  if 1 ≤ ni ≤ m and 1 ≤ nj ≤ n and not visited[ni][nj]\n                      then visited[ni][nj] ← true\n                           result[ni][nj] ← result[i][j] + 1\n                           queue.enqueue((ni,nj))\n\n    return result\n\n// Example:\n// Input: G = [\n//   [1, 1, 1],\n//   [1, 0, 1],\n//   [1, 1, 1]\n// ]\n//\n// Initial state:\n//   visited = [\n//     [true, false, false],\n//     [false, false, false],\n//     [false, false, false]\n//   ]\n//   result = [\n//     [1, 0, 0],\n//     [0, 0, 0],\n//     [0, 0, 0]\n//   ]\n//\n// After first iteration:\n//   visited = [\n//     [true, true, false],\n//     [true, false, false],\n//     [false, false, false]\n//   ]\n//   result = [\n//     [1, 2, 0],\n//     [2, 0, 0],\n//     [0, 0, 0]\n//   ]\n//\n// Final result:\n//   [\n//     [1, 2, 3],\n//     [2, 0, 4],\n//     [3, 4, 5]\n//   ]",
    "keySteps": [
      "Initialize: Create visited and result matrices",
      "Process: Use BFS to traverse grid in all directions",
      "Update: Track visited cells and distance from start"
    ]
  },
  "greedy": {
    "name": "Greedy",
    "type": "greedy",
    "description": "Greedy is an algorithm with time complexity O(n log n). It is primarily used for make locally optimal choices",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Make locally optimal choices\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Make locally optimal choices\n    ",
    "useCase": "Make locally optimal choices\n    ",
    "pseudocode": "// Activity Selection\nACTIVITY-SELECTION(S):\n  sort S by finish time\n  A = [S[0]]\n  last = 0\n  for i from 1 to n-1:\n    if S[i].start ≥ S[last].finish:\n      A.append(S[i])\n      last = i\n  return A\n\n// Fractional Knapsack\nKNAPSACK(W, V, C):\n  sort items by value/weight ratio\n  total = 0\n  for i from 0 to n-1:\n    if C ≥ W[i]:\n      total += V[i]\n      C -= W[i]\n    else:\n      total += (C/W[i]) * V[i]\n      break\n  return total\n\n// Huffman Coding\nHUFFMAN(C):\n  Q = priority queue of C\n  for i from 1 to n-1:\n    x = EXTRACT-MIN(Q)\n    y = EXTRACT-MIN(Q)\n    z = new node\n    z.left = x\n    z.right = y\n    z.freq = x.freq + y.freq\n    INSERT(Q, z)\n  return EXTRACT-MIN(Q)\n\n// Dijkstra's Algorithm\nDIJKSTRA(G, s):\n  dist = [∞] * n\n  prev = [NIL] * n\n  dist[s] = 0\n  Q = priority queue of all vertices\n  while Q is not empty:\n    u = EXTRACT-MIN(Q)\n    for each v in G.adj[u]:\n      if dist[v] > dist[u] + G.weight(u, v):\n        dist[v] = dist[u] + G.weight(u, v)\n        prev[v] = u\n  return (dist, prev)",
    "keySteps": []
  },
  "greedy-prim": {
    "name": "Prim's Algorithm",
    "type": "graph",
    "description": "Prim's Algorithm is an algorithm with time complexity O((V+E). It is primarily used for finding minimum spanning tree",
    "timeComplexity": "O((V+E)logV) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree\n    ",
    "useCase": "Finding minimum spanning tree\n    ",
    "pseudocode": "// Standard Prim's Algorithm\ndef prim(graph, start):\n    # Initialize MST and visited set\n    mst = []\n    visited = {start}\n\n    # Priority queue for edges\n    import heapq\n    edges = [(weight, start, neighbor)\n             for neighbor, weight in graph[start].items()]\n    heapq.heapify(edges)\n\n    while edges and len(visited) < len(graph):\n        # Get minimum weight edge\n        weight, u, v = heapq.heappop(edges)\n\n        if v not in visited:\n            visited.add(v)\n            mst.append((u, v, weight))\n\n            # Add new edges to queue\n            for neighbor, weight in graph[v].items():\n                if neighbor not in visited:\n                    heapq.heappush(edges, (weight, v, neighbor))\n\n    return mst\n\n// Prim's with Early Exit\ndef prim_with_max_weight(graph, start, max_weight):\n    mst = []\n    visited = {start}\n    total_weight = 0\n\n    edges = [(weight, start, neighbor)\n             for neighbor, weight in graph[start].items()]\n    heapq.heapify(edges)\n\n    while edges and len(visited) < len(graph):\n        weight, u, v = heapq.heappop(edges)\n\n        if v not in visited and total_weight + weight <= max_weight:\n            visited.add(v)\n            mst.append((u, v, weight))\n            total_weight += weight\n\n            for neighbor, weight in graph[v].items():\n                if neighbor not in visited:\n                    heapq.heappush(edges, (weight, v, neighbor))\n        elif total_weight + weight > max_weight:\n            break\n\n    return mst, total_weight\n\n// Prim's with Maximum Degree\ndef prim_with_max_degree(graph, start, max_degree):\n    mst = []\n    visited = {start}\n    degree = {node: 0 for node in graph}\n    degree[start] = 0\n\n    edges = [(weight, start, neighbor)\n             for neighbor, weight in graph[start].items()]\n    heapq.heapify(edges)\n\n    while edges and len(visited) < len(graph):\n        weight, u, v = heapq.heappop(edges)\n\n        if v not in visited and degree[u] < max_degree and degree[v] < max_degree:\n            visited.add(v)\n            mst.append((u, v, weight))\n            degree[u] += 1\n            degree[v] += 1\n\n            for neighbor, weight in graph[v].items():\n                if neighbor not in visited:\n                    heapq.heappush(edges, (weight, v, neighbor))\n\n    return mst",
    "keySteps": []
  },
  "greedy-kruskal": {
    "name": "Kruskal's Algorithm's Algorithm",
    "type": "E log E",
    "description": "Kruskal's Algorithm's Algorithm is an algorithm with time complexity O(E log E). It is primarily used for finding minimum spanning tree",
    "timeComplexity": "O(E log E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree\n    ",
    "useCase": "Finding minimum spanning tree\n    ",
    "pseudocode": "// Standard Kruskal's Algorithm's Algorithm\ndef kruskal(graph):\n    # Initialize MST and parent array\n    mst = []\n    parent = {node: node for node in graph}\n    rank = {node: 0 for node in graph}\n\n    # Sort edges by weight\n    edges = [(weight, u, v)\n             for u in graph\n             for v, weight in graph[u].items()]\n    edges.sort()\n\n    def find(u):\n        if parent[u] != u:\n            parent[u] = find(parent[u])\n        return parent[u]\n\n    def union(u, v):\n        u_root = find(u)\n        v_root = find(v)\n        if u_root == v_root:\n            return False\n        if rank[u_root] > rank[v_root]:\n            parent[v_root] = u_root\n        else:\n            parent[u_root] = v_root\n            if rank[u_root] == rank[v_root]:\n                rank[v_root] += 1\n        return True\n\n    # Process edges\n    for weight, u, v in edges:\n        if union(u, v):\n            mst.append((u, v, weight))\n\n    return mst\n\n// Kruskal's Algorithm's with Maximum Degree\ndef kruskal_with_max_degree(graph, max_degree):\n    mst = []\n    parent = {node: node for node in graph}\n    rank = {node: 0 for node in graph}\n    degree = {node: 0 for node in graph}\n\n    edges = [(weight, u, v)\n             for u in graph\n             for v, weight in graph[u].items()]\n    edges.sort()\n\n    def find(u):\n        if parent[u] != u:\n            parent[u] = find(parent[u])\n        return parent[u]\n\n    def union(u, v):\n        if degree[u] >= max_degree or degree[v] >= max_degree:\n            return False\n        u_root = find(u)\n        v_root = find(v)\n        if u_root == v_root:\n            return False\n        if rank[u_root] > rank[v_root]:\n            parent[v_root] = u_root\n        else:\n            parent[u_root] = v_root\n            if rank[u_root] == rank[v_root]:\n                rank[v_root] += 1\n        degree[u] += 1\n        degree[v] += 1\n        return True\n\n    for weight, u, v in edges:\n        if union(u, v):\n            mst.append((u, v, weight))\n\n    return mst\n\n// Kruskal's Algorithm's with Edge Limit\ndef kruskal_with_edge_limit(graph, max_edges):\n    mst = []\n    parent = {node: node for node in graph}\n    rank = {node: 0 for node in graph}\n\n    edges = [(weight, u, v)\n             for u in graph\n             for v, weight in graph[u].items()]\n    edges.sort()\n\n    def find(u):\n        if parent[u] != u:\n            parent[u] = find(parent[u])\n        return parent[u]\n\n    def union(u, v):\n        u_root = find(u)\n        v_root = find(v)\n        if u_root == v_root:\n            return False\n        if rank[u_root] > rank[v_root]:\n            parent[v_root] = u_root\n        else:\n            parent[u_root] = v_root\n            if rank[u_root] == rank[v_root]:\n                rank[v_root] += 1\n        return True\n\n    for weight, u, v in edges:\n        if len(mst) >= max_edges:\n            break\n        if union(u, v):\n            mst.append((u, v, weight))\n\n    return mst",
    "keySteps": []
  },
  "greedy-job-scheduling": {
    "name": "Job Scheduling",
    "type": "Algorithm",
    "description": "Job Scheduling is an algorithm with time complexity O(n log n). It is primarily used for scheduling jobs to maximize       profit or minimize completion time",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Scheduling jobs to maximize\n      profit or minimize completion time\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Scheduling jobs to maximize\n      profit or minimize completion time\n    ",
    "useCase": "Scheduling jobs to maximize\n      profit or minimize completion time\n    ",
    "pseudocode": "// Standard Job Scheduling\ndef job_scheduling(jobs):\n    # Sort jobs by finish time\n    jobs.sort(key=lambda x: x[1])\n\n    selected = []\n    last_finish = 0\n\n    for job in jobs:\n        start, finish, profit = job\n        if start >= last_finish:\n            selected.append(job)\n            last_finish = finish\n\n    return selected\n\n// Job Scheduling with Deadlines\ndef job_scheduling_deadlines(jobs):\n    # Sort jobs by profit in descending order\n    jobs.sort(key=lambda x: x[2], reverse=True)\n\n    max_deadline = max(job[1] for job in jobs)\n    schedule = [None] * (max_deadline + 1)\n\n    for job in jobs:\n        start, deadline, profit = job\n        # Find latest available slot\n        for slot in range(deadline, 0, -1):\n            if schedule[slot] is None:\n                schedule[slot] = job\n                break\n\n    return [job for job in schedule if job is not None]\n\n// Job Scheduling with Weights\ndef job_scheduling_weights(jobs):\n    # Sort jobs by profit/weight ratio\n    jobs.sort(key=lambda x: x[2]/x[1], reverse=True)\n\n    current_time = 0\n    total_profit = 0\n\n    for job in jobs:\n        duration, weight, profit = job\n        current_time += duration\n        total_profit += profit\n\n    return total_profit\n\n# Examples:\n\n# Standard Job Scheduling\n# Input:\n# jobs = [\n#     (1, 3, 5),  # (start, finish, profit)\n#     (2, 5, 6),\n#     (4, 6, 5),\n#     (6, 7, 4),\n#     (5, 8, 11)\n# ]\n# Output:\n# selected = [(1, 3, 5), (4, 6, 5), (6, 7, 4)]\n# Total profit: 14\n\n# Job Scheduling with Deadlines\n# Input:\n# jobs = [\n#     (1, 2, 100),  # (duration, deadline, profit)\n#     (1, 1, 19),\n#     (2, 2, 27),\n#     (1, 1, 25),\n#     (3, 1, 15)\n# ]\n# Output:\n# schedule = [(1, 2, 100), (1, 1, 25)]\n# Total profit: 125\n\n# Job Scheduling with Weights\n# Input:\n# jobs = [\n#     (2, 1, 100),  # (duration, weight, profit)\n#     (1, 1, 19),\n#     (2, 1, 27),\n#     (1, 1, 25),\n#     (3, 1, 15)\n# ]\n# Output:\n# total_profit = 186",
    "keySteps": [
      "Sort: Jobs by finish time, profit, or profit/weight ratio",
      "Select: Jobs that don't conflict with previous selections",
      "Update: Schedule or profit based on selected jobs"
    ]
  },
  "greedy-hungarian": {
    "name": "Hungarian Algorithm",
    "type": "Algorithm",
    "description": "Hungarian Algorithm is an algorithm with time complexity O(n³). It is primarily used for solve assignment problem",
    "timeComplexity": "O(n³) &nbsp;|&nbsp; Space: O(n²) &nbsp;|&nbsp; Use: Solve assignment problem\n    ",
    "spaceComplexity": "O(n²) &nbsp;|&nbsp; Use: Solve assignment problem\n    ",
    "useCase": "Solve assignment problem\n    ",
    "pseudocode": "// Hungarian algorithm for assignment problem\nHUNGARIAN(C):\n    n ← rows[C]\n    // Step 1: Subtract row minima\n    for i ← 1 to n:\n        row_min ← min(C[i, 1..n])\n        for j ← 1 to n:\n            C[i, j] ← C[i, j] - row_min\n\n    // Step 2: Subtract column minima\n    for j ← 1 to n:\n        col_min ← min(C[1..n, j])\n        for i ← 1 to n:\n            C[i, j] ← C[i, j] - col_min\n\n    // Step 3: Find minimum number of lines\n    while true:\n        // Find maximum matching\n        matching ← FIND-MAX-MATCHING(C)\n        if size(matching) = n:\n            return matching\n\n        // Find minimum uncovered value\n        min_val ← ∞\n        for i ← 1 to n:\n            for j ← 1 to n:\n                if not covered[i] and not covered[j]:\n                    min_val ← min(min_val, C[i, j])\n\n        // Update matrix\n        for i ← 1 to n:\n            for j ← 1 to n:\n                if not covered[i] and not covered[j]:\n                    C[i, j] ← C[i, j] - min_val\n                else if covered[i] and covered[j]:\n                    C[i, j] ← C[i, j] + min_val\n\n// Example:\n// Input: C = [\n//   [3, 5, 6],\n//   [2, 4, 7],\n//   [3, 5, 8]\n// ]\n//\n// Step 1: Subtract row minima\n// [\n//   [0, 2, 3],\n//   [0, 2, 5],\n//   [0, 2, 5]\n// ]\n//\n// Step 2: Subtract column minima\n// [\n//   [0, 0, 0],\n//   [0, 0, 2],\n//   [0, 0, 2]\n// ]\n//\n// Step 3: Find matching\n// Output: {(1,1), (2,2), (3,3)}",
    "keySteps": [
      "Reduce: Subtract row and column minima",
      "Match: Find maximum matching",
      "Update: Adjust matrix until perfect matching"
    ]
  },
  "greedy-huffman-coding": {
    "name": "Huffman Coding",
    "type": "Algorithm",
    "description": "Huffman Coding is an algorithm with time complexity O(n log n). It is primarily used for data compression",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Data compression\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Data compression\n    ",
    "useCase": "Data compression\n    ",
    "pseudocode": "// Standard Huffman Coding\nclass Node:\n    def __init__(self, symbol=None, freq=0, left=None, right=None):\n        self.symbol = symbol\n        self.freq = freq\n        self.left = left\n        self.right = right\n\ndef build_huffman_tree(frequencies):\n    # Create leaf nodes\n    nodes = [Node(symbol, freq) for symbol, freq in frequencies.items()]\n\n    # Build tree\n    while len(nodes) > 1:\n        # Get two nodes with minimum frequency\n        nodes.sort(key=lambda x: x.freq)\n        left = nodes.pop(0)\n        right = nodes.pop(0)\n\n        # Create new internal node\n        internal = Node(freq=left.freq + right.freq, left=left, right=right)\n        nodes.append(internal)\n\n    return nodes[0]\n\ndef build_codes(node, prefix=\"\", codes={}):\n    if node.symbol is not None:\n        codes[node.symbol] = prefix\n    else:\n        build_codes(node.left, prefix + \"0\", codes)\n        build_codes(node.right, prefix + \"1\", codes)\n    return codes\n\n// Adaptive Huffman Coding\nclass AdaptiveNode:\n    def __init__(self, symbol=None, freq=0, left=None, right=None, parent=None):\n        self.symbol = symbol\n        self.freq = freq\n        self.left = left\n        self.right = right\n        self.parent = parent\n\ndef update_tree(node):\n    # Update frequencies\n    while node is not None:\n        node.freq += 1\n        node = node.parent\n\n// Canonical Huffman Coding\ndef build_canonical_codes(lengths):\n    # Sort symbols by code length\n    symbols = sorted(lengths.items(), key=lambda x: (x[1], x[0]))\n\n    # Generate canonical codes\n    code = 0\n    prev_length = 0\n    codes = {}\n\n    for symbol, length in symbols:\n        if length > prev_length:\n            code <<= (length - prev_length)\n        codes[symbol] = format(code, f'0{length}b')\n        code += 1\n        prev_length = length\n\n    return codes",
    "keySteps": []
  },
  "greedy-fractional-knapsack": {
    "name": "Fractional Knapsack Problem",
    "type": "Algorithm",
    "description": "Fractional Knapsack Problem is an algorithm with time complexity O(nW). It is primarily used for optimal item selection with weight       constraint",
    "timeComplexity": "O(nW) &nbsp;|&nbsp; Space: O(nW) &nbsp;|&nbsp; Use: Optimal item selection with weight\n      constraint\n    ",
    "spaceComplexity": "O(nW) &nbsp;|&nbsp; Use: Optimal item selection with weight\n      constraint\n    ",
    "useCase": "Optimal item selection with weight\n      constraint\n    ",
    "pseudocode": "// 0-1 Knapsack problem\nKNAPSACK(w, v, W):\n    n ← length[w]\n    // Initialize DP table\n    let dp[0..n, 0..W] be a new table\n    for i ← 0 to n:\n        for j ← 0 to W:\n            dp[i, j] ← 0\n\n    // Fill DP table\n    for i ← 1 to n:\n        for j ← 0 to W:\n            if w[i] > j:\n                dp[i, j] ← dp[i-1, j]\n            else:\n                dp[i, j] ← max(dp[i-1, j], v[i] + dp[i-1, j-w[i]])\n\n    // Reconstruct solution\n    j ← W\n    S ← ∅\n    for i ← n downto 1:\n        if dp[i, j] ≠ dp[i-1, j]:\n            S ← S ∪ {i}\n            j ← j - w[i]\n\n    return dp[n, W], S\n\n// Example:\n// Input: w = [2, 3, 4, 5], v = [3, 4, 5, 6], W = 5\n//\n// DP Table:\n//   0 1 2 3 4 5\n// 0 0 0 0 0 0 0\n// 1 0 0 3 3 3 3\n// 2 0 0 3 4 4 7\n// 3 0 0 3 4 5 7\n// 4 0 0 3 4 5 7\n//\n// Output: max_value = 7, items = {1, 2}",
    "keySteps": [
      "Initialize: Create DP table",
      "Fill: Compute optimal values",
      "Reconstruct: Find selected items"
    ]
  },
  "greedy-ford-fulkerson": {
    "name": "Ford-Fulkerson Algorithm",
    "type": "Algorithm",
    "description": "Ford-Fulkerson Algorithm is an algorithm with time complexity O(E * max_flow). It is primarily used for finding maximum flow in       networks",
    "timeComplexity": "O(E * max_flow) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding maximum flow in\n      networks\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding maximum flow in\n      networks\n    ",
    "useCase": "Finding maximum flow in\n      networks\n    ",
    "pseudocode": "// Standard Ford-Fulkerson Algorithm\ndef ford_fulkerson(graph, source, sink):\n    # Initialize residual graph and max flow\n    residual = {u: {v: graph[u][v] for v in graph[u]}\n                for u in graph}\n    max_flow = 0\n\n    def bfs():\n        # Find augmenting path using BFS\n        parent = {source: None}\n        queue = [source]\n\n        while queue:\n            u = queue.pop(0)\n            for v in residual[u]:\n                if v not in parent and residual[u][v] > 0:\n                    parent[v] = u\n                    if v == sink:\n                        return parent\n                    queue.append(v)\n        return None\n\n    # Find and process augmenting paths\n    while True:\n        parent = bfs()\n        if not parent:\n            break\n\n        # Find minimum residual capacity\n        path_flow = float('inf')\n        v = sink\n        while v != source:\n            u = parent[v]\n            path_flow = min(path_flow, residual[u][v])\n            v = u\n\n        # Update residual capacities\n        v = sink\n        while v != source:\n            u = parent[v]\n            residual[u][v] -= path_flow\n            residual[v][u] += path_flow\n            v = u\n\n        max_flow += path_flow\n\n    return max_flow\n\n// Ford-Fulkerson with Capacity Scaling\ndef ford_fulkerson_capacity_scaling(graph, source, sink):\n    residual = {u: {v: graph[u][v] for v in graph[u]}\n                for u in graph}\n    max_flow = 0\n\n    # Find maximum capacity\n    max_capacity = max(graph[u][v]\n                      for u in graph\n                      for v in graph[u])\n\n    # Start with largest power of 2\n    delta = 1\n    while delta * 2 <= max_capacity:\n        delta *= 2\n\n    def bfs(delta):\n        parent = {source: None}\n        queue = [source]\n\n        while queue:\n            u = queue.pop(0)\n            for v in residual[u]:\n                if v not in parent and residual[u][v] >= delta:\n                    parent[v] = u\n                    if v == sink:\n                        return parent\n                    queue.append(v)\n        return None\n\n    while delta >= 1:\n        while True:\n            parent = bfs(delta)\n            if not parent:\n                break\n\n            path_flow = float('inf')\n            v = sink\n            while v != source:\n                u = parent[v]\n                path_flow = min(path_flow, residual[u][v])\n                v = u\n\n            v = sink\n            while v != source:\n                u = parent[v]\n                residual[u][v] -= path_flow\n                residual[v][u] += path_flow\n                v = u\n\n            max_flow += path_flow\n\n        delta //= 2\n\n    return max_flow\n\n// Ford-Fulkerson with Multiple Sources/Sinks\ndef ford_fulkerson_multiple(graph, sources, sinks):\n    # Add super source and super sink\n    super_source = 'S'\n    super_sink = 'T'\n\n    # Initialize residual graph\n    residual = {u: {v: graph[u][v] for v in graph[u]}\n                for u in graph}\n    residual[super_source] = {s: float('inf') for s in sources}\n    residual[super_sink] = {}\n\n    for u in graph:\n        if u not in residual:\n            residual[u] = {}\n        if u in sinks:\n            residual[u][super_sink] = float('inf')\n\n    max_flow = 0\n\n    def bfs():\n        parent = {super_source: None}\n        queue = [super_source]\n\n        while queue:\n            u = queue.pop(0)\n            for v in residual[u]:\n                if v not in parent and residual[u][v] > 0:\n                    parent[v] = u\n                    if v == super_sink:\n                        return parent\n                    queue.append(v)\n        return None\n\n    while True:\n        parent = bfs()\n        if not parent:\n            break\n\n        path_flow = float('inf')\n        v = super_sink\n        while v != super_source:\n            u = parent[v]\n            path_flow = min(path_flow, residual[u][v])\n            v = u\n\n        v = super_sink\n        while v != super_source:\n            u = parent[v]\n            residual[u][v] -= path_flow\n            residual[v][u] += path_flow\n            v = u\n\n        max_flow += path_flow\n\n    return max_flow",
    "keySteps": []
  },
  "greedy-edmonds-karp": {
    "name": "Edmonds-Karp Algorithm",
    "type": "Algorithm",
    "description": "Edmonds-Karp Algorithm is an algorithm with time complexity O(VE²). It is primarily used for finding maximum flow in networks",
    "timeComplexity": "O(VE²) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding maximum flow in networks\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding maximum flow in networks\n    ",
    "useCase": "Finding maximum flow in networks\n    ",
    "pseudocode": "// Standard Edmonds-Karp\ndef edmonds_karp(graph, source, sink):\n    # Initialize residual graph and max flow\n    residual = {u: {v: graph[u][v] for v in graph[u]}\n                for u in graph}\n    max_flow = 0\n\n    def bfs():\n        # Find shortest augmenting path using BFS\n        parent = {source: None}\n        queue = [source]\n\n        while queue:\n            u = queue.pop(0)\n            for v in residual[u]:\n                if v not in parent and residual[u][v] > 0:\n                    parent[v] = u\n                    if v == sink:\n                        return parent\n                    queue.append(v)\n        return None\n\n    # Find and process augmenting paths\n    while True:\n        parent = bfs()\n        if not parent:\n            break\n\n        # Find minimum residual capacity\n        path_flow = float('inf')\n        v = sink\n        while v != source:\n            u = parent[v]\n            path_flow = min(path_flow, residual[u][v])\n            v = u\n\n        # Update residual capacities\n        v = sink\n        while v != source:\n            u = parent[v]\n            residual[u][v] -= path_flow\n            residual[v][u] += path_flow\n            v = u\n\n        max_flow += path_flow\n\n    return max_flow\n\n// Edmonds-Karp with Edge Capacities\ndef edmonds_karp_edge_capacities(graph, source, sink, min_capacity):\n    residual = {u: {v: graph[u][v] for v in graph[u]}\n                for u in graph}\n    max_flow = 0\n\n    def bfs():\n        parent = {source: None}\n        queue = [source]\n\n        while queue:\n            u = queue.pop(0)\n            for v in residual[u]:\n                if v not in parent and residual[u][v] >= min_capacity:\n                    parent[v] = u\n                    if v == sink:\n                        return parent\n                    queue.append(v)\n        return None\n\n    while True:\n        parent = bfs()\n        if not parent:\n            break\n\n        path_flow = float('inf')\n        v = sink\n        while v != source:\n            u = parent[v]\n            path_flow = min(path_flow, residual[u][v])\n            v = u\n\n        v = sink\n        while v != source:\n            u = parent[v]\n            residual[u][v] -= path_flow\n            residual[v][u] += path_flow\n            v = u\n\n        max_flow += path_flow\n\n    return max_flow\n\n// Edmonds-Karp with Vertex Capacities\ndef edmonds_karp_vertex_capacities(graph, source, sink, vertex_capacities):\n    # Split each vertex into in and out nodes\n    residual = {}\n    for u in graph:\n        residual[f\"{u}_in\"] = {f\"{u}_out\": vertex_capacities[u]}\n        residual[f\"{u}_out\"] = {}\n\n    # Add original edges\n    for u in graph:\n        for v in graph[u]:\n            residual[f\"{u}_out\"][f\"{v}_in\"] = graph[u][v]\n\n    # Add source and sink\n    residual[source] = {f\"{source}_in\": float('inf')}\n    residual[f\"{sink}_out\"] = {sink: float('inf')}\n\n    max_flow = 0\n\n    def bfs():\n        parent = {source: None}\n        queue = [source]\n\n        while queue:\n            u = queue.pop(0)\n            for v in residual[u]:\n                if v not in parent and residual[u][v] > 0:\n                    parent[v] = u\n                    if v == sink:\n                        return parent\n                    queue.append(v)\n        return None\n\n    while True:\n        parent = bfs()\n        if not parent:\n            break\n\n        path_flow = float('inf')\n        v = sink\n        while v != source:\n            u = parent[v]\n            path_flow = min(path_flow, residual[u][v])\n            v = u\n\n        v = sink\n        while v != source:\n            u = parent[v]\n            residual[u][v] -= path_flow\n            residual[v][u] += path_flow\n            v = u\n\n        max_flow += path_flow\n\n    return max_flow",
    "keySteps": []
  },
  "greedy-dinic": {
    "name": "Dinic's Algorithm",
    "type": "Algorithm",
    "description": "Dinic's Algorithm is an algorithm with time complexity O(V²E). It is primarily used for finding maximum flow in networks",
    "timeComplexity": "O(V²E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding maximum flow in networks\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding maximum flow in networks\n    ",
    "useCase": "Finding maximum flow in networks\n    ",
    "pseudocode": "// Standard Dinic's Algorithm\ndef dinic(graph, source, sink):\n    # Initialize residual graph and max flow\n    residual = {u: {v: graph[u][v] for v in graph[u]}\n                for u in graph}\n    max_flow = 0\n\n    def bfs():\n        # Build level graph using BFS\n        level = {source: 0}\n        queue = [source]\n\n        while queue:\n            u = queue.pop(0)\n            for v in residual[u]:\n                if v not in level and residual[u][v] > 0:\n                    level[v] = level[u] + 1\n                    if v == sink:\n                        return level\n                    queue.append(v)\n        return None\n\n    def dfs(u, flow):\n        if u == sink:\n            return flow\n\n        for v in residual[u]:\n            if level[v] == level[u] + 1 and residual[u][v] > 0:\n                path_flow = dfs(v, min(flow, residual[u][v]))\n                if path_flow > 0:\n                    residual[u][v] -= path_flow\n                    residual[v][u] += path_flow\n                    return path_flow\n        return 0\n\n    # Find blocking flows\n    while True:\n        level = bfs()\n        if not level:\n            break\n\n        while True:\n            flow = dfs(source, float('inf'))\n            if flow == 0:\n                break\n            max_flow += flow\n\n    return max_flow",
    "keySteps": [
      "Initialize: Residual graph and max flow",
      "Build: Level graph using BFS",
      "Find: Blocking flow using DFS"
    ]
  },
  "greedy-activity-selection": {
    "name": "Greedy Activity Selection",
    "type": "Algorithm",
    "description": "Greedy Activity Selection is an algorithm with time complexity O(n log n). It is primarily used for select maximum number of       non-overlapping activities",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Select maximum number of\n      non-overlapping activities\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Select maximum number of\n      non-overlapping activities\n    ",
    "useCase": "Select maximum number of\n      non-overlapping activities\n    ",
    "pseudocode": "GREEDY-ACTIVITY-SELECTOR(s, f)\n    n ← length[s]\n    A ← {a₁}  // First activity is always selected\n    k ← 1\n    for m ← 2 to n\n        do if s[m] ≥ f[k]\n            then A ← A ∪ {aₘ}\n                k ← m\n    return A\n\n// Example:\n// Input: s = [1, 3, 0, 5, 8, 5]  // Start times\n//        f = [2, 4, 6, 7, 9, 9]  // Finish times\n//\n// Step 1: Sort activities by finish time\n//         a₁: (1,2)\n//         a₂: (3,4)\n//         a₃: (0,6)\n//         a₄: (5,7)\n//         a₅: (8,9)\n//         a₆: (5,9)\n//\n// Step 2: Select activities\n//         Select a₁ (1-2)\n//         Skip a₃ (overlaps)\n//         Select a₂ (3-4)\n//         Skip a₆ (overlaps)\n//         Select a₄ (5-7)\n//         Select a₅ (8-9)\n//\n// Output: {a₁, a₂, a₄, a₅}",
    "keySteps": [
      "Sort: Activities by finish time",
      "Select: First activity",
      "Iterate: Through remaining activities",
      "Add: Non-overlapping activities to set"
    ]
  },
  "graph-topological-sort": {
    "name": "Topological Sort",
    "type": "Algorithm",
    "description": "Topological Sort is an algorithm with time complexity O(V + E). It is primarily used for linear ordering of vertices in a       dag",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Linear ordering of vertices in a\n      DAG\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Linear ordering of vertices in a\n      DAG\n    ",
    "useCase": "Linear ordering of vertices in a\n      DAG\n    ",
    "pseudocode": "// DFS-based Topological Sort\nTOPOLOGICAL-SORT(G):\n    visited = [False] * |V|\n    order = []\n    for v in V:\n        if not visited[v]:\n            DFS(G, v, visited, order)\n    return reversed(order)\n\n// Kahn's Algorithm\nKAHN-TOPOLOGICAL-SORT(G):\n    in_degree = [0] * |V|\n    for v in V:\n        for u in G.adj[v]:\n            in_degree[u] += 1\n\n    queue = []\n    for v in V:\n        if in_degree[v] == 0:\n            queue.append(v)\n\n    order = []\n    while queue:\n        v = queue.pop(0)\n        order.append(v)\n        for u in G.adj[v]:\n            in_degree[u] -= 1\n            if in_degree[u] == 0:\n                queue.append(u)\n\n    if len(order) != |V|:\n        return \"Graph has a cycle\"\n    return order\n\n// Topological Sort with Cycle Detection\nTOPOLOGICAL-SORT-CYCLE(G):\n    visited = [False] * |V|\n    recursion_stack = [False] * |V|\n    order = []\n\n    for v in V:\n        if not visited[v]:\n            if DFS-CYCLE(G, v, visited, recursion_stack, order):\n                return \"Graph has a cycle\"\n\n    return reversed(order)\n\nDFS-CYCLE(G, v, visited, recursion_stack, order):\n    visited[v] = True\n    recursion_stack[v] = True\n\n    for u in G.adj[v]:\n        if not visited[u]:\n            if DFS-CYCLE(G, u, visited, recursion_stack, order):\n                return True\n        elif recursion_stack[u]:\n            return True\n\n    recursion_stack[v] = False\n    order.append(v)\n    return False",
    "keySteps": []
  },
  "graph-scc": {
    "name": "Strongly Connected Components",
    "type": "Algorithm",
    "description": "Strongly Connected Components is an algorithm with time complexity O(V + E). It is primarily used for finding strongly connected       components in directed graphs",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding strongly connected\n      components in directed graphs\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding strongly connected\n      components in directed graphs\n    ",
    "useCase": "Finding strongly connected\n      components in directed graphs\n    ",
    "pseudocode": "// Kosaraju's Algorithm\nKOSARAJU-SCC(G):\n    # First DFS pass\n    visited = [False] * |V|\n    order = []\n    for v in V:\n        if not visited[v]:\n            DFS(G, v, visited, order)\n\n    # Reverse graph\n    G_rev = REVERSE-GRAPH(G)\n\n    # Second DFS pass\n    visited = [False] * |V|\n    components = []\n    for v in reversed(order):\n        if not visited[v]:\n            component = []\n            DFS(G_rev, v, visited, component)\n            components.append(component)\n    return components\n\n// Tarjan's Algorithm\nTARJAN-SCC(G):\n    index = 0\n    indices = [-1] * |V|\n    low = [-1] * |V|\n    on_stack = [False] * |V|\n    stack = []\n    components = []\n\n    for v in V:\n        if indices[v] == -1:\n            STRONGLY-CONNECTED(v)\n    return components\n\nSTRONGLY-CONNECTED(v):\n    indices[v] = index\n    low[v] = index\n    index = index + 1\n    stack.append(v)\n    on_stack[v] = True\n\n    for w in G.adj[v]:\n        if indices[w] == -1:\n            STRONGLY-CONNECTED(w)\n            low[v] = min(low[v], low[w])\n        elif on_stack[w]:\n            low[v] = min(low[v], indices[w])\n\n    if low[v] == indices[v]:\n        component = []\n        while True:\n            w = stack.pop()\n            on_stack[w] = False\n            component.append(w)\n            if w == v:\n                break\n        components.append(component)\n\n// Gabow's Algorithm\nGABOW-SCC(G):\n    index = 0\n    indices = [-1] * |V|\n    path = []\n    components = []\n\n    for v in V:\n        if indices[v] == -1:\n            GABOW-DFS(v)\n    return components\n\nGABOW-DFS(v):\n    indices[v] = index\n    index = index + 1\n    path.append(v)\n\n    for w in G.adj[v]:\n        if indices[w] == -1:\n            GABOW-DFS(w)\n        else:\n            while path and indices[path[-1]] > indices[w]:\n                path.pop()\n\n    if path[-1] == v:\n        component = []\n        while True:\n            w = path.pop()\n            component.append(w)\n            if w == v:\n                break\n        components.append(component)",
    "keySteps": []
  },
  "graph-representation": {
    "name": "Graph Representation",
    "type": "graph",
    "description": "Graph Representation is an algorithm with time complexity O(V+E). It is primarily used for efficient graph storage and       traversal",
    "timeComplexity": "O(V+E) &nbsp;|&nbsp; Space: O(V+E) &nbsp;|&nbsp; Use: Efficient graph storage and\n      traversal\n    ",
    "spaceComplexity": "O(V+E) &nbsp;|&nbsp; Use: Efficient graph storage and\n      traversal\n    ",
    "useCase": "Efficient graph storage and\n      traversal\n    ",
    "pseudocode": "// Adjacency List Representation\nADJ-LIST-REP(G):\n    n ← |G.V|\n    Adj[1..n] ← empty lists\n    for each edge (u, v) ∈ G.E:\n        APPEND(Adj[u], v)\n        if G is undirected:\n            APPEND(Adj[v], u)\n    return Adj\n\n// Adjacency Matrix Representation\nADJ-MATRIX-REP(G):\n    n ← |G.V|\n    M[1..n, 1..n] ← 0\n    for each edge (u, v) ∈ G.E:\n        M[u, v] ← 1\n        if G is undirected:\n            M[v, u] ← 1\n    return M\n\n// Edge List Representation\nEDGE-LIST-REP(G):\n    E ← empty list\n    for each edge (u, v) ∈ G.E:\n        APPEND(E, (u, v))\n    return E\n\n// Example:\n// Input: G = (V, E) where\n// V = {1, 2, 3, 4}\n// E = {(1,2), (2,3), (3,4), (4,1)}\n//\n// Adjacency List:\n// 1: [2, 4]\n// 2: [1, 3]\n// 3: [2, 4]\n// 4: [3, 1]\n//\n// Adjacency Matrix:\n//   1 2 3 4\n// 1 0 1 0 1\n// 2 1 0 1 0\n// 3 0 1 0 1\n// 4 1 0 1 0\n//\n// Edge List:\n// [(1,2), (2,3), (3,4), (4,1)]",
    "keySteps": [
      "Adjacency List: O(V+E) space, efficient for sparse graphs",
      "Adjacency Matrix: O(V²) space, efficient for dense graphs",
      "Edge List: O(E) space, useful for algorithms that process edges",
      "Check edge existence: O(1) matrix, O(deg(v)) list"
    ]
  },
  "graph-prim": {
    "name": "Prim's Algorithm",
    "type": "graph",
    "description": "Prim's Algorithm is an algorithm with time complexity O(E log V). It is primarily used for finding minimum spanning tree in       weighted graphs",
    "timeComplexity": "O(E log V) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree in\n      weighted graphs\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree in\n      weighted graphs\n    ",
    "useCase": "Finding minimum spanning tree in\n      weighted graphs\n    ",
    "pseudocode": "// Standard Prim's Algorithm\nPRIM(G):\n    # Initialize\n    key = [∞] * |V|\n    parent = [None] * |V|\n    in_mst = [False] * |V|\n\n    # Start with vertex 0\n    key[0] = 0\n\n    for _ in range(|V|):\n        # Find minimum key vertex\n        u = min((v for v in range(|V|) if not in_mst[v]), key=lambda v: key[v])\n        in_mst[u] = True\n\n        # Update keys of adjacent vertices\n        for v in G.adj[u]:\n            if not in_mst[v] and G.weight(u, v) < key[v]:\n                key[v] = G.weight(u, v)\n                parent[v] = u\n\n    return parent\n\n// Prim's with Priority Queue\nPRIM-PQ(G):\n    # Initialize\n    key = [∞] * |V|\n    parent = [None] * |V|\n    in_mst = [False] * |V|\n    pq = PriorityQueue()\n\n    # Start with vertex 0\n    key[0] = 0\n    pq.put((0, 0))\n\n    while not pq.empty():\n        _, u = pq.get()\n        if in_mst[u]:\n            continue\n\n        in_mst[u] = True\n        for v in G.adj[u]:\n            weight = G.weight(u, v)\n            if not in_mst[v] and weight < key[v]:\n                key[v] = weight\n                parent[v] = u\n                pq.put((weight, v))\n\n    return parent\n\n// Prim's with Fibonacci Heap\nPRIM-FH(G):\n    # Initialize\n    key = [∞] * |V|\n    parent = [None] * |V|\n    in_mst = [False] * |V|\n    fh = FibonacciHeap()\n\n    # Start with vertex 0\n    key[0] = 0\n    nodes = [fh.insert(key[v], v) for v in range(|V|)]\n\n    while not fh.empty():\n        u = fh.extract_min().value\n        in_mst[u] = True\n\n        for v in G.adj[u]:\n            weight = G.weight(u, v)\n            if not in_mst[v] and weight < key[v]:\n                key[v] = weight\n                parent[v] = u\n                fh.decrease_key(nodes[v], weight)\n\n    return parent",
    "keySteps": []
  },
  "graph-kosaraju": {
    "name": "Kosaraju's Algorithm",
    "type": "graph",
    "description": "Kosaraju's Algorithm is an algorithm with time complexity O(V + E). It is primarily used for find strongly connected components",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find strongly connected components\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find strongly connected components\n    ",
    "useCase": "Find strongly connected components\n    ",
    "pseudocode": "KOSARAJU(G)\n    let n be the number of vertices in G\n    let visited[1‥n] be a new array\n    let order be a new empty stack\n    let components be a new empty list\n\n    for each vertex u in G.V\n        do visited[u] ← FALSE\n\n    for each vertex u in G.V\n        do if not visited[u]\n            then DFS-FIRST(G, u, visited, order)\n\n    let G^T be the transpose of G\n    for each vertex u in G.V\n        do visited[u] ← FALSE\n\n    while order is not empty\n        do let u ← order.pop()\n            if not visited[u]\n                then let component be a new empty list\n                    DFS-SECOND(G^T, u, visited, component)\n                    components.append(component)\n\n    return components\n\nDFS-FIRST(G, u, visited, order)\n    visited[u] ← TRUE\n    for each v in G.Adj[u]\n        do if not visited[v]\n            then DFS-FIRST(G, v, visited, order)\n    order.push(u)\n\nDFS-SECOND(G, u, visited, component)\n    visited[u] ← TRUE\n    component.append(u)\n    for each v in G.Adj[u]\n        do if not visited[v]\n            then DFS-SECOND(G, v, visited, component)\n\n// Example:\n// Input: G with edges (1,2), (2,3), (3,1), (2,4), (4,5), (5,6), (6,4)\n//\n// First DFS:\n//   Order: [3, 2, 1, 6, 5, 4]\n//\n// Second DFS on G^T:\n//   Component 1: [1, 2, 3]\n//   Component 2: [4, 5, 6]\n//\n// Output: [[1, 2, 3], [4, 5, 6]]",
    "keySteps": [
      "First DFS: Fill order with vertices by finish time",
      "Transpose: Create reverse graph",
      "Second DFS: Process vertices in reverse order"
    ]
  },
  "graph-implementation": {
    "name": "Graph Implementation",
    "type": "graph",
    "description": "Graph Implementation is an algorithm with time complexity O(V+E). It is primarily used for graph representation and traversal",
    "timeComplexity": "O(V+E) &nbsp;|&nbsp; Space: O(V+E) &nbsp;|&nbsp; Use: Graph representation and traversal\n    ",
    "spaceComplexity": "O(V+E) &nbsp;|&nbsp; Use: Graph representation and traversal\n    ",
    "useCase": "Graph representation and traversal\n    ",
    "pseudocode": "// Adjacency list representation\nGRAPH-ADJ-LIST(V, E):\n    n ← length[V]\n    Adj[1..n] ← empty lists\n    for each edge (u, v) ∈ E:\n        APPEND(Adj[u], v)\n        if graph is undirected:\n            APPEND(Adj[v], u)\n    return Adj\n\n// Adjacency matrix representation\nGRAPH-ADJ-MATRIX(V, E):\n    n ← length[V]\n    M[1..n, 1..n] ← 0\n    for each edge (u, v) ∈ E:\n        M[u, v] ← 1\n        if graph is undirected:\n            M[v, u] ← 1\n    return M\n\n// Depth-first search\nDFS(G):\n    for each vertex u ∈ G.V:\n        color[u] ← WHITE\n        π[u] ← NIL\n    time ← 0\n    for each vertex u ∈ G.V:\n        if color[u] = WHITE:\n            DFS-VISIT(G, u)\n\nDFS-VISIT(G, u):\n    time ← time + 1\n    d[u] ← time\n    color[u] ← GRAY\n    for each v ∈ G.Adj[u]:\n        if color[v] = WHITE:\n            π[v] ← u\n            DFS-VISIT(G, v)\n    color[u] ← BLACK\n    time ← time + 1\n    f[u] ← time\n\n// Breadth-first search\nBFS(G, s):\n    for each vertex u ∈ G.V - {s}:\n        color[u] ← WHITE\n        d[u] ← ∞\n        π[u] ← NIL\n    color[s] ← GRAY\n    d[s] ← 0\n    π[s] ← NIL\n    Q ← empty queue\n    ENQUEUE(Q, s)\n    while Q not empty:\n        u ← DEQUEUE(Q)\n        for each v ∈ G.Adj[u]:\n            if color[v] = WHITE:\n                color[v] ← GRAY\n                d[v] ← d[u] + 1\n                π[v] ← u\n                ENQUEUE(Q, v)\n        color[u] ← BLACK\n\n// Example:\n// Input: V = {1, 2, 3, 4}, E = {(1,2), (2,3), (3,4), (4,1)}\n//\n// Adjacency List:\n//   1: [2, 4]\n//   2: [1, 3]\n//   3: [2, 4]\n//   4: [3, 1]\n//\n// Adjacency Matrix:\n//   1 2 3 4\n// 1 0 1 0 1\n// 2 1 0 1 0\n// 3 0 1 0 1\n// 4 1 0 1 0",
    "keySteps": [
      "Representation: Choose between adjacency list or matrix",
      "Traversal: Implement DFS and BFS algorithms",
      "Properties: Track discovery/finish times and predecessors"
    ]
  },
  "graph-floyd-warshall": {
    "name": "Floyd-Warshall Algorithm",
    "type": "graph",
    "description": "Floyd-Warshall's Algorithm is an algorithm with time complexity O(V³). It is primarily used for finding all pairs shortest paths in       weighted graphs",
    "timeComplexity": "O(V³) &nbsp;|&nbsp; Space: O(V²) &nbsp;|&nbsp; Use: Finding all pairs shortest paths in\n      weighted graphs\n    ",
    "spaceComplexity": "O(V²) &nbsp;|&nbsp; Use: Finding all pairs shortest paths in\n      weighted graphs\n    ",
    "useCase": "Finding all pairs shortest paths in\n      weighted graphs\n    ",
    "pseudocode": "// Standard Floyd-Warshall Algorithm\nFLOYD-WARSHALL(G):\n    # Initialize distance matrix\n    dist = [[∞] * |V| for _ in range(|V|)]\n    for i in range(|V|):\n        dist[i][i] = 0\n    for (u, v, w) in G.E:\n        dist[u][v] = w\n\n    # Main algorithm\n    for k in range(|V|):\n        for i in range(|V|):\n            for j in range(|V|):\n                if dist[i][k] + dist[k][j] < dist[i][j]:\n                    dist[i][j] = dist[i][k] + dist[k][j]\n\n    return dist\n\n// Floyd-Warshall Algorithm with Path Reconstruction\nFLOYD-WARSHALL-PATH(G):\n    # Initialize distance and next matrices\n    dist = [[∞] * |V| for _ in range(|V|)]\n    next = [[None] * |V| for _ in range(|V|)]\n\n    for i in range(|V|):\n        dist[i][i] = 0\n    for (u, v, w) in G.E:\n        dist[u][v] = w\n        next[u][v] = v\n\n    # Main algorithm\n    for k in range(|V|):\n        for i in range(|V|):\n            for j in range(|V|):\n                if dist[i][k] + dist[k][j] < dist[i][j]:\n                    dist[i][j] = dist[i][k] + dist[k][j]\n                    next[i][j] = next[i][k]\n\n    return dist, next\n\n// Path reconstruction\nRECONSTRUCT-PATH(u, v, next):\n    if next[u][v] is None:\n        return []\n    path = [u]\n    while u != v:\n        u = next[u][v]\n        path.append(u)\n    return path\n\n// Floyd-Warshall Algorithm with Negative Cycle Detection\nFLOYD-WARSHALL-NEGATIVE(G):\n    # Initialize distance matrix\n    dist = [[∞] * |V| for _ in range(|V|)]\n    for i in range(|V|):\n        dist[i][i] = 0\n    for (u, v, w) in G.E:\n        dist[u][v] = w\n\n    # Main algorithm\n    for k in range(|V|):\n        for i in range(|V|):\n            for j in range(|V|):\n                if dist[i][k] + dist[k][j] < dist[i][j]:\n                    dist[i][j] = dist[i][k] + dist[k][j]\n\n    # Check for negative cycles\n    for i in range(|V|):\n        if dist[i][i] < 0:\n            return \"Graph contains negative cycle\"\n\n    return dist",
    "keySteps": []
  },
  "graph-dijkstra": {
    "name": "Dijkstra's Algorithm",
    "type": "graph",
    "description": "Dijkstra's Algorithm is an algorithm with time complexity O((V + E). It is primarily used for single-source shortest       paths in weighted graphs",
    "timeComplexity": "O((V + E) log V) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Single-source shortest\n      paths in weighted graphs\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Single-source shortest\n      paths in weighted graphs\n    ",
    "useCase": "Single-source shortest\n      paths in weighted graphs\n    ",
    "pseudocode": "// Standard Dijkstra\nDIJKSTRA(G, w, s):\n  INITIALIZE-SINGLE-SOURCE(G, s)\n  S = ∅\n  Q = G.V\n  while Q ≠ ∅:\n    u = EXTRACT-MIN(Q)\n    S = S ∪ {u}\n    for each v in G.adj[u]:\n      RELAX(u, v, w)\n\nINITIALIZE-SINGLE-SOURCE(G, s):\n  for each vertex v in G.V:\n    v.d = ∞\n    v.π = NIL\n  s.d = 0\n\nRELAX(u, v, w):\n  if v.d > u.d + w(u, v):\n    v.d = u.d + w(u, v)\n    v.π = u\n\n// Priority Queue Implementation\nDIJKSTRA-PQ(G, w, s):\n  dist = [∞] * n\n  prev = [NIL] * n\n  dist[s] = 0\n  Q = priority queue of (vertex, distance)\n  while Q is not empty:\n    u = EXTRACT-MIN(Q)\n    for each v in G.adj[u]:\n      if dist[v] > dist[u] + w(u, v):\n        dist[v] = dist[u] + w(u, v)\n        prev[v] = u\n        DECREASE-KEY(Q, v, dist[v])\n  return (dist, prev)\n\n// Path Reconstruction\nGET-PATH(prev, s, t):\n  path = []\n  u = t\n  while u ≠ NIL:\n    path.append(u)\n    u = prev[u]\n  return reverse(path)",
    "keySteps": []
  },
  "graph-bridges": {
    "name": "Bridges",
    "type": "graph",
    "description": "Bridges is an algorithm with time complexity O(V + E). It is primarily used for find critical edges in graph",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find critical edges in graph\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find critical edges in graph\n    ",
    "useCase": "Find critical edges in graph\n    ",
    "pseudocode": "FIND-BRIDGES(G)\n    let n be the number of vertices in G\n    let disc[1‥n] be a new array\n    let low[1‥n] be a new array\n    let parent[1‥n] be a new array\n    let bridges be a new empty list\n    let time ← 0\n\n    for each vertex u in G.V\n        do disc[u] ← -1\n            low[u] ← -1\n            parent[u] ← NIL\n\n    for each vertex u in G.V\n        do if disc[u] = -1\n            then DFS-BRIDGES(G, u, disc, low, parent, bridges, time)\n\n    return bridges\n\nDFS-BRIDGES(G, u, disc, low, parent, bridges, time)\n    time ← time + 1\n    disc[u] ← time\n    low[u] ← time\n\n    for each v in G.Adj[u]\n        do if disc[v] = -1\n            then parent[v] ← u\n                DFS-BRIDGES(G, v, disc, low, parent, bridges, time)\n                low[u] ← min(low[u], low[v])\n                if low[v] > disc[u]\n                    then bridges.append((u,v))\n            else if v ≠ parent[u]\n                then low[u] ← min(low[u], disc[v])\n\n// Example:\n// Input: G with edges (1,2), (2,3), (3,4), (4,1), (1,3)\n//\n// DFS from vertex 1:\n//   disc = [1, 2, 3, 4]\n//   low = [1, 1, 1, 1]\n//   parent = [NIL, 1, 2, 3]\n//\n// Bridge check:\n//   Edge (2,3): low[3] = 1 > disc[2] = 2? No\n//   Edge (3,4): low[4] = 1 > disc[3] = 3? No\n//   Edge (4,1): low[1] = 1 > disc[4] = 4? No\n//   Edge (1,3): low[3] = 1 > disc[1] = 1? No\n//\n// Output: [] (no bridges)",
    "keySteps": [
      "Initialize: Set up discovery and low values",
      "DFS: Track discovery time and low values",
      "Identify: Check conditions for bridge edges"
    ]
  },
  "graph-bellman-ford": {
    "name": "Bellman-Ford",
    "type": "graph",
    "description": "Bellman-Ford is an algorithm with time complexity O(VE). It is primarily used for finding single-source shortest paths       with negative weights",
    "timeComplexity": "O(VE) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding single-source shortest paths\n      with negative weights\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding single-source shortest paths\n      with negative weights\n    ",
    "useCase": "Finding single-source shortest paths\n      with negative weights\n    ",
    "pseudocode": "// Standard Bellman-Ford\nBELLMAN-FORD(G, s):\n    # Initialize\n    dist = [∞] * |V|\n    parent = [None] * |V|\n    dist[s] = 0\n\n    # Relax edges |V|-1 times\n    for i in range(|V|-1):\n        for (u, v, w) in G.E:\n            if dist[u] + w < dist[v]:\n                dist[v] = dist[u] + w\n                parent[v] = u\n\n    # Check for negative cycles\n    for (u, v, w) in G.E:\n        if dist[u] + w < dist[v]:\n            return \"Graph contains negative cycle\"\n\n    return dist, parent\n\n// Bellman-Ford with Path Reconstruction\nBELLMAN-FORD-PATH(G, s):\n    # Initialize\n    dist = [∞] * |V|\n    parent = [None] * |V|\n    dist[s] = 0\n\n    # Relax edges |V|-1 times\n    for i in range(|V|-1):\n        for (u, v, w) in G.E:\n            if dist[u] + w < dist[v]:\n                dist[v] = dist[u] + w\n                parent[v] = u\n\n    # Check for negative cycles\n    for (u, v, w) in G.E:\n        if dist[u] + w < dist[v]:\n            return \"Graph contains negative cycle\"\n\n    return dist, parent\n\n// Path reconstruction\nRECONSTRUCT-PATH(s, v, parent):\n    if v == s:\n        return [s]\n    if parent[v] is None:\n        return []\n    path = RECONSTRUCT-PATH(s, parent[v], parent)\n    path.append(v)\n    return path\n\n// Bellman-Ford with Early Termination\nBELLMAN-FORD-EARLY(G, s):\n    # Initialize\n    dist = [∞] * |V|\n    parent = [None] * |V|\n    dist[s] = 0\n\n    # Relax edges until no improvement\n    for i in range(|V|-1):\n        improved = False\n        for (u, v, w) in G.E:\n            if dist[u] + w < dist[v]:\n                dist[v] = dist[u] + w\n                parent[v] = u\n                improved = True\n        if not improved:\n            break\n\n    # Check for negative cycles\n    for (u, v, w) in G.E:\n        if dist[u] + w < dist[v]:\n            return \"Graph contains negative cycle\"\n\n    return dist, parent",
    "keySteps": []
  },
  "graph-basics": {
    "name": "Graph Basics",
    "type": "Data Structure",
    "description": "Graph Basics is an algorithm with time complexity O(V + E). It is primarily used for representing relationships between       objects",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Representing relationships between\n      objects\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Representing relationships between\n      objects\n    ",
    "useCase": "Representing relationships between\n      objects\n    ",
    "pseudocode": "// Graph representation\nGRAPH-REPRESENTATION(V, E):\n  G = new Graph\n  G.V = V  // Set of vertices\n  G.E = E  // Set of edges\n  G.adj = new Array(V.length + 1)  // Adjacency list\n  for v in V:\n    G.adj[v] = new List\n  for (u, v) in E:\n    G.adj[u].append(v)\n    G.adj[v].append(u)  // For undirected graph\n  return G\n\n// Depth-first search\nDFS(G, s):\n  for v in G.V:\n    v.color = WHITE\n    v.parent = NIL\n  time = 0\n  for v in G.V:\n    if v.color = WHITE:\n      DFS-VISIT(G, v)\n\nDFS-VISIT(G, u):\n  time = time + 1\n  u.d = time\n  u.color = GRAY\n  for v in G.adj[u]:\n    if v.color = WHITE:\n      v.parent = u\n      DFS-VISIT(G, v)\n  u.color = BLACK\n  time = time + 1\n  u.f = time\n\n// Breadth-first search\nBFS(G, s):\n  for v in G.V:\n    v.color = WHITE\n    v.d = ∞\n    v.parent = NIL\n  s.color = GRAY\n  s.d = 0\n  s.parent = NIL\n  Q = new Queue\n  Q.enqueue(s)\n  while Q is not empty:\n    u = Q.dequeue()\n    for v in G.adj[u]:\n      if v.color = WHITE:\n        v.color = GRAY\n        v.d = u.d + 1\n        v.parent = u\n        Q.enqueue(v)\n    u.color = BLACK",
    "keySteps": []
  },
  "graph-articulation-points": {
    "name": "Articulation Points",
    "type": "Graph Algorithm",
    "description": "Articulation Points is an algorithm with time complexity O(V + E). It is primarily used for find critical vertices in graph",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find critical vertices in graph\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find critical vertices in graph\n    ",
    "useCase": "Find critical vertices in graph\n    ",
    "pseudocode": "FIND-ARTICULATION-POINTS(G)\n    let n be the number of vertices in G\n    let disc[1‥n] be a new array\n    let low[1‥n] be a new array\n    let parent[1‥n] be a new array\n    let ap[1‥n] be a new array\n    let time ← 0\n\n    for each vertex u in G.V\n        do disc[u] ← -1\n            low[u] ← -1\n            parent[u] ← NIL\n            ap[u] ← FALSE\n\n    for each vertex u in G.V\n        do if disc[u] = -1\n            then DFS-AP(G, u, disc, low, parent, ap, time)\n\n    return ap\n\nDFS-AP(G, u, disc, low, parent, ap, time)\n    let children ← 0\n    time ← time + 1\n    disc[u] ← time\n    low[u] ← time\n\n    for each v in G.Adj[u]\n        do if disc[v] = -1\n            then children ← children + 1\n                parent[v] ← u\n                DFS-AP(G, v, disc, low, parent, ap, time)\n                low[u] ← min(low[u], low[v])\n                if parent[u] = NIL and children > 1\n                    then ap[u] ← TRUE\n                if parent[u] ≠ NIL and low[v] ≥ disc[u]\n                    then ap[u] ← TRUE\n            else if v ≠ parent[u]\n                then low[u] ← min(low[u], disc[v])\n\n// Example:\n// Input: G with edges (1,2), (2,3), (3,4), (4,1), (1,3)\n//\n// DFS from vertex 1:\n//   disc = [1, 2, 3, 4]\n//   low = [1, 1, 1, 1]\n//   parent = [NIL, 1, 2, 3]\n//\n// Articulation points:\n//   Vertex 1: TRUE (root with multiple children)\n//   Vertex 2: FALSE\n//   Vertex 3: FALSE\n//   Vertex 4: FALSE\n//\n// Output: [TRUE, FALSE, FALSE, FALSE]",
    "keySteps": [
      "Initialize: Set up discovery and low values",
      "DFS: Track discovery time and low values",
      "Identify: Check conditions for articulation points"
    ]
  },
  "fractional-knapsack": {
    "name": "Fractional Knapsack",
    "type": "Algorithm",
    "description": "Fractional Knapsack is an algorithm with time complexity O(n log n). It is primarily used for maximize value while keeping       weight under capacity",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Maximize value while keeping\n      weight under capacity\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Maximize value while keeping\n      weight under capacity\n    ",
    "useCase": "Maximize value while keeping\n      weight under capacity\n    ",
    "pseudocode": "FRACTIONAL-KNAPSACK(W, w, v)\n    n ← length[w]\n    for i ← 1 to n\n        do x[i] ← 0\n    weight ← 0\n    for i ← 1 to n\n        do if weight + w[i] ≤ W\n            then x[i] ← 1\n                weight ← weight + w[i]\n            else x[i] ← (W - weight) / w[i]\n                weight ← W\n                return x\n\n// Example:\n// Input: W = 50\n//        w = [10, 20, 30]\n//        v = [60, 100, 120]\n//\n// Step 1: Sort items by value/weight ratio\n//        [6, 5, 4]\n//\n// Step 2: Take items in order\n//        Take all of item 1 (10 units)\n//        Take all of item 2 (20 units)\n//        Take 20/30 of item 3\n//\n// Output: [1, 1, 0.666...]",
    "keySteps": [
      "Sort: Items by value/weight ratio",
      "Take: Items in order of highest ratio",
      "Fill: Take fraction of last item if needed"
    ]
  },
  "ford-fulkerson": {
    "name": "Ford-Fulkerson Algorithm",
    "type": "Ef*",
    "description": "Ford-Fulkerson Algorithm is an algorithm with time complexity O(E|f*|). It is primarily used for maximum flow in networks",
    "timeComplexity": "O(E|f*|) &nbsp;|&nbsp; Space: O(V + E) &nbsp;|&nbsp; Use: Maximum flow in networks\n    ",
    "spaceComplexity": "O(V + E) &nbsp;|&nbsp; Use: Maximum flow in networks\n    ",
    "useCase": "Maximum flow in networks\n    ",
    "pseudocode": "FORD-FULKERSON(G, s, t):\n    // G is a flow network with source s and sink t\n    // Returns maximum flow value\n    for each edge (u,v) in G.E:\n        f[u,v] ← 0\n        f[v,u] ← 0\n    \n    while there exists path p from s to t in residual network Gf:\n        cf(p) ← min{cf(u,v): (u,v) is in p}\n        for each edge (u,v) in p:\n            f[u,v] ← f[u,v] + cf(p)\n            f[v,u] ← -f[u,v]\n    \n    return sum of f[s,v] for all v\n\n// Example:\n// Flow network G:\n// s → 1 → t\n//   ↘ 2 ↗\n//\n// Capacities:\n// s→1: 10, s→2: 8\n// 1→t: 4, 2→t: 9\n//\n// Initial flow: 0\n// After first augmentation: 4\n// After second augmentation: 8\n// Final maximum flow: 12",
    "keySteps": [
      "Finds maximum flow in a flow network",
      "Uses residual networks and augmenting paths",
      "Can be implemented with different path-finding methods",
      "With Edmonds-Karp: O(VE²) time complexity"
    ]
  },
  "floyd-warshall": {
    "name": "Floyd-Warshall Algorithm",
    "type": "graph",
    "description": "Floyd-Warshall Algorithm is an algorithm with time complexity O(V³). It is primarily used for all-pairs shortest paths",
    "timeComplexity": "O(V³) &nbsp;|&nbsp; Space: O(V²) &nbsp;|&nbsp; Use: All-pairs shortest paths\n    ",
    "spaceComplexity": "O(V²) &nbsp;|&nbsp; Use: All-pairs shortest paths\n    ",
    "useCase": "All-pairs shortest paths\n    ",
    "pseudocode": "FLOYD-WARSHALL(G):\n    // G is a weighted directed graph\n    // Returns shortest paths between all pairs of vertices\n    n ← number of vertices in G\n    dist[1..n][1..n] ← ∞\n    next[1..n][1..n] ← null\n    \n    // Initialize distances\n    for each vertex v in G:\n        dist[v][v] ← 0\n    for each edge (u,v) in G:\n        dist[u][v] ← weight(u,v)\n        next[u][v] ← v\n    \n    // Main algorithm\n    for k ← 1 to n:\n        for i ← 1 to n:\n            for j ← 1 to n:\n                if dist[i][k] + dist[k][j] < dist[i][j]:\n                    dist[i][j] ← dist[i][k] + dist[k][j]\n                    next[i][j] ← next[i][k]\n    \n    return dist, next\n\n// Example:\n// Graph G:\n// 1 → 2 (weight: 3)\n// 2 → 3 (weight: 4)\n// 3 → 1 (weight: 2)\n// 1 → 3 (weight: 6)\n//\n// Initial dist matrix:\n// 0 3 6\n// ∞ 0 4\n// 2 ∞ 0\n//\n// Final dist matrix:\n// 0 3 6\n// 6 0 4\n// 2 5 0",
    "keySteps": [
      "Finds shortest paths between all pairs of vertices",
      "Handles negative edge weights (but not negative cycles)",
      "Can detect negative cycles through diagonal elements",
      "More efficient than running Dijkstra's Algorithm V times for dense graphs"
    ]
  },
  "floyd-cycle-detection": {
    "name": "Floyd Cycle Detection",
    "type": "Algorithm",
    "description": "\n        A technique to detect cycles in linked lists using two pointers moving at different speeds\n      ",
    "timeComplexity": "O(n) where n is the number of nodes",
    "spaceComplexity": "O(1) using only two pointers",
    "useCase": "Detect cycles in linked lists, find cycle start node",
    "pseudocode": "FLOYD-CYCLE-DETECTION(head)\n    let slow ← head\n    let fast ← head\n\n    while fast ≠ null and fast.next ≠ null\n        do slow ← slow.next\n           fast ← fast.next.next\n           if slow = fast\n               then return true\n\n    return false\n\nFIND-CYCLE-START(head)\n    let slow ← head\n    let fast ← head\n\n    while fast ≠ null and fast.next ≠ null\n        do slow ← slow.next\n           fast ← fast.next.next\n           if slow = fast\n               then break\n\n    if fast = null or fast.next = null\n        then return null\n\n    slow ← head\n    while slow ≠ fast\n        do slow ← slow.next\n           fast ← fast.next\n\n    return slow\n\n// Example:\n// Input: 1 → 2 → 3 → 4 → 5 → 3 (cycle back to 3)\n//\n// Initial state:\n//   slow = 1, fast = 1\n//\n// First iteration:\n//   slow = 2, fast = 3\n//\n// Second iteration:\n//   slow = 3, fast = 5\n//\n// Third iteration:\n//   slow = 4, fast = 3\n//\n// Fourth iteration:\n//   slow = 5, fast = 5 (cycle detected)\n//\n// Finding cycle start:\n//   slow = 1, fast = 5\n//   slow = 2, fast = 3\n//   slow = 3, fast = 3 (cycle start found)\n//\n// Output: Cycle exists, starts at node 3",
    "keySteps": [
      "Initialize: Set slow and fast pointers to head",
      "Detect: Move pointers at different speeds until they meet",
      "Find: Reset slow pointer and move both at same speed"
    ]
  },
  "fibonacci": {
    "name": "Fibonacci",
    "type": "Algorithm",
    "description": "A sequence where each number is the sum of the two preceding ones",
    "timeComplexity": "O(n) for iterative approach, O(2^n) for recursive",
    "spaceComplexity": "O(1) for iterative, O(n) for recursive call stack",
    "useCase": "Dynamic programming, sequence generation, mathematical modeling",
    "pseudocode": "function fibonacci(n):\n    if n <= 1:\n        return n\n    \n    a, b = 0, 1\n    for i in range(2, n + 1):\n        a, b = b, a + b\n    \n    return b",
    "keySteps": [
      "Initialize first two numbers (0 and 1)",
      "Iterate through sequence, updating values",
      "Use two variables to track previous numbers",
      "Return the nth number in the sequence"
    ]
  },
  "fibonacci-search": {
    "name": "Fibonacci Search",
    "type": "Algorithm",
    "description": "Fibonacci Search is an algorithm with time complexity O(log n). It is primarily used for search in sorted array using       fibonacci numbers",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Search in sorted array using\n      Fibonacci numbers\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Search in sorted array using\n      Fibonacci numbers\n    ",
    "useCase": "Search in sorted array using\n      Fibonacci numbers\n    ",
    "pseudocode": "FIBONACCI-SEARCH(A, x)\n1  // Initialize Fibonacci numbers\n2  fib2 = 0  // (m-2)'th Fibonacci number\n3  fib1 = 1  // (m-1)'th Fibonacci number\n4  fib = fib2 + fib1  // m'th Fibonacci number\n5\n6  // Find smallest Fibonacci number >= n\n7  while fib < n\n8      fib2 = fib1\n9      fib1 = fib\n10     fib = fib2 + fib1\n11\n12 // Initialize offset\n13 offset = -1\n14\n15 while fib {'>'} 1\n16     // Check if fib2 is valid index\n17     i = min(offset + fib2, n - 1)\n18\n19     // If x is greater than value at i,\n20     // cut the subarray from offset to i\n21     if A[i] < x\n22         fib = fib1\n23         fib1 = fib2\n24         fib2 = fib - fib1\n25         offset = i\n26\n27     // If x is less than value at i,\n28     // cut the subarray after i+1\n29     else if A[i] {'>'} x\n30         fib = fib2\n31         fib1 = fib1 - fib2\n32         fib2 = fib - fib1\n33\n34     // Element found\n35     else\n36         return i\n37\n38 // Compare last element\n39 if fib1 and A[offset + 1] == x\n40     return offset + 1\n41\n42 // Element not found\n43 return -1\n\n// Example:\n// Input: A = [1, 4, 6, 8, 9, 10, 14, 15, 16], x = 14\n//\n// Step 1: Find Fibonacci numbers\n//         fib2 = 5, fib1 = 8, fib = 13\n//\n// Step 2: Compare A[5] = 10 < 14\n//         offset = 5, fib2 = 3, fib1 = 5, fib = 8\n//\n// Step 3: Compare A[8] = 16 {'>'} 14\n//         fib2 = 2, fib1 = 3, fib = 5\n//\n// Step 4: Compare A[7] = 15 {'>'} 14\n//         fib2 = 1, fib1 = 2, fib = 3\n//\n// Step 5: Compare A[6] = 14 = 14\n//         Return 6",
    "keySteps": [
      "Initialize: Find smallest Fibonacci number {\">=\"} array length",
      "Compare: Use Fibonacci numbers to divide search space",
      "Update: Fibonacci numbers based on comparison result",
      "Return: Index if found, -1 if not found"
    ]
  },
  "fenwick-tree": {
    "name": "Fenwick Tree",
    "type": "tree",
    "description": "Fenwick Tree is an algorithm with time complexity O(log n). It is primarily used for efficient prefix sums and point       updates",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Efficient prefix sums and point\n      updates\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Efficient prefix sums and point\n      updates\n    ",
    "useCase": "Efficient prefix sums and point\n      updates\n    ",
    "pseudocode": "FENWICK-TREE(A)\n    let n be the length of A\n    let tree[1‥n] be a new array\n\n    for i ← 1 to n\n        do tree[i] ← 0\n\n    for i ← 1 to n\n        do UPDATE(tree, i, A[i])\n\n    return tree\n\nUPDATE(tree, idx, delta)\n    while idx ≤ n\n        do tree[idx] ← tree[idx] + delta\n            idx ← idx + (idx & -idx)\n\nQUERY(tree, idx)\n    let sum ← 0\n    while idx > 0\n        do sum ← sum + tree[idx]\n            idx ← idx - (idx & -idx)\n    return sum\n\n// Example:\n// Input: A = [1, 3, 5, 7, 9, 11]\n//\n// Initial tree:\n//   tree = [0, 0, 0, 0, 0, 0]\n//\n// After updates:\n//   tree = [1, 4, 5, 16, 9, 20]\n//\n// Query(4):\n//   idx = 4: sum = 16\n//   idx = 0: return 16\n//\n// Query(6):\n//   idx = 6: sum = 20\n//   idx = 4: sum = 36\n//   idx = 0: return 36\n//\n// Output: Prefix sums [1, 4, 9, 16, 25, 36]",
    "keySteps": [
      "Initialize: Create tree array and set all values to 0",
      "Update: Add value to all affected nodes using LSB",
      "Query: Sum values from all relevant nodes using LSB"
    ]
  },
  "fast-fourier-transform": {
    "name": "Fast Fourier Transform",
    "type": "Number Theory",
    "description": "Fast Fourier Transform is an algorithm with time complexity O(n log n). It is primarily used for polynomial multiplication",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Polynomial multiplication\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Polynomial multiplication\n    ",
    "useCase": "Polynomial multiplication\n    ",
    "pseudocode": "# Fast Fourier Transform\n# Input: Array a of complex numbers, length n (power of 2)\n# Output: Array y of complex numbers (DFT of a)\n\nAlgorithm FFT(a, n)\n    if n = 1 then\n        return a\n\n    # Split into even and odd indices\n    a_even ← array of length n/2\n    a_odd ← array of length n/2\n    for i ← 0 to n/2 - 1 do\n        a_even[i] ← a[2i]\n        a_odd[i] ← a[2i + 1]\n    end for\n\n    # Recursive calls\n    y_even ← FFT(a_even, n/2)\n    y_odd ← FFT(a_odd, n/2)\n\n    # Combine results\n    y ← array of length n\n    ω ← e^(2πi/n)\n    for k ← 0 to n/2 - 1 do\n        y[k] ← y_even[k] + ω^k · y_odd[k]\n        y[k + n/2] ← y_even[k] - ω^k · y_odd[k]\n    end for\n\n    return y\n\n# Inverse FFT\nAlgorithm IFFT(y, n)\n    # Conjugate input\n    for i ← 0 to n-1 do\n        y[i] ← conjugate(y[i])\n    end for\n\n    # Apply FFT\n    a ← FFT(y, n)\n\n    # Conjugate and scale\n    for i ← 0 to n-1 do\n        a[i] ← conjugate(a[i]) / n\n    end for\n\n    return a\n\n# Example:\n# Input: a = [1, 2, 3, 4], n = 4\n#\n# Step 1: Split into even and odd\n#         a_even = [1, 3]\n#         a_odd = [2, 4]\n#\n# Step 2: Recursive calls\n#         y_even = FFT([1, 3], 2) = [4, -2]\n#         y_odd = FFT([2, 4], 2) = [6, -2]\n#\n# Step 3: Combine results\n#         ω = e^(2πi/4) = i\n#         y[0] = 4 + 6 = 10\n#         y[1] = -2 + i·(-2) = -2 - 2i\n#         y[2] = 4 - 6 = -2\n#         y[3] = -2 - i·(-2) = -2 + 2i\n#\n# Output: [10, -2-2i, -2, -2+2i]",
    "keySteps": [
      "Split input into even and odd indices",
      "Recursively compute FFT on halves",
      "Combine results using roots of unity",
      "Inverse FFT uses conjugation and scaling"
    ]
  },
  "fast-and-slow-pointers": {
    "name": "Fast and Slow Pointers",
    "type": "array",
    "description": "\n          A technique using two pointers moving at different speeds to detect cycles or find middle\n          elements\n        ",
    "timeComplexity": "O(n)",
    "spaceComplexity": "O(1)",
    "useCase": "Detecting cycles in linked lists, finding the middle node, or partitioning arrays\n        ",
    "pseudocode": "function hasCycle(head):\n    if not head or not head.next:\n        return False\n    \n    slow = head\n    fast = head\n    \n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n        \n        if slow == fast:\n            return True\n    \n    return False\n\nfunction findMiddle(head):\n    if not head:\n        return None\n    \n    slow = head\n    fast = head\n    \n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n    \n    return slow",
    "keySteps": [
      "Initialize two pointers, slow and fast, at the head of the list",
      "Move slow by one step and fast by two steps in each iteration",
      "Check for cycle: if slow and fast meet, a cycle exists",
      "For finding the middle: when fast reaches the end, slow is at the middle"
    ]
  },
  "extended-euclidean": {
    "name": "Extended Euclidean",
    "type": "number-theory",
    "description": "Extended Euclidean is an algorithm with time complexity O(log min(a,b). It is primarily used for find gcd and       bézout coefficients",
    "timeComplexity": "O(log min(a,b)) &nbsp;|&nbsp; Space: O(log min(a,b)) &nbsp;|&nbsp; Use: Find GCD and\n      Bézout coefficients\n    ",
    "spaceComplexity": "O(log min(a,b)) &nbsp;|&nbsp; Use: Find GCD and\n      Bézout coefficients\n    ",
    "useCase": "Find GCD and\n      Bézout coefficients\n    ",
    "pseudocode": "# Extended Euclidean Algorithm\n# Input: Integers a, b\n# Output: Tuple (d, x, y) where d = gcd(a,b) and ax + by = d\n\nAlgorithm EXTENDED-EUCLID(a, b)\n    if b = 0 then\n        return (a, 1, 0)\n    end if\n\n    (d', x', y') ← EXTENDED-EUCLID(b, a mod b)\n    d ← d'\n    x ← y'\n    y ← x' - ⌊a/b⌋ · y'\n    return (d, x, y)\n\n# Example:\n# Input: a = 30, b = 18\n#\n# Step 1: a = 30, b = 18\n#         a mod b = 12\n#         Recursive call: a = 18, b = 12\n#\n# Step 2: a = 18, b = 12\n#         a mod b = 6\n#         Recursive call: a = 12, b = 6\n#\n# Step 3: a = 12, b = 6\n#         a mod b = 0\n#         Base case: return (6, 1, 0)\n#\n# Step 4: Back to Step 2\n#         d = 6, x = 0, y = 1 - ⌊18/12⌋·0 = 1\n#         return (6, 0, 1)\n#\n# Step 5: Back to Step 1\n#         d = 6, x = 1, y = 0 - ⌊30/18⌋·1 = -1\n#         return (6, 1, -1)\n#\n# Output: (6, 1, -1)\n#\n# Verification:\n# 6 = 30·1 + 18·(-1)",
    "keySteps": [
      "Base case: Return GCD and coefficients when b = 0",
      "Recursively compute GCD and coefficients",
      "Update coefficients using floor division",
      "Return GCD and Bézout coefficients"
    ]
  },
  "exponential-search": {
    "name": "Exponential Search",
    "type": "searching",
    "description": "Exponential Search is an algorithm with time complexity O(log i). It is primarily used for find element in unbounded sorted       array",
    "timeComplexity": "O(log i) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find element in unbounded sorted\n      array\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find element in unbounded sorted\n      array\n    ",
    "useCase": "Find element in unbounded sorted\n      array\n    ",
    "pseudocode": "# Exponential Search: Find element in unbounded sorted array\n# Input: Sorted array A[1..n], target value x\n# Output: Index of x in A if found, -1 otherwise\n\nAlgorithm EXPONENTIAL-SEARCH(A, x)\n    n ← length[A]\n\n    # If x is at first position\n    if A[1] = x then\n        return 1\n    end if\n\n    # Find range for binary search\n    i ← 1\n    while i < n and A[i] ≤ x do\n        i ← i * 2\n    end while\n\n    # Binary search in found range\n    return BINARY-SEARCH(A, i/2, min(i, n), x)\n\nAlgorithm BINARY-SEARCH(A, low, high, x)\n    while low ≤ high do\n        mid ← ⌊(low + high)/2⌋\n        if A[mid] = x then\n            return mid\n        else if A[mid] < x then\n            low ← mid + 1\n        else\n            high ← mid - 1\n        end if\n    end while\n    return -1\n\n# Example:\n# Input: A = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100], x = 70\n#\n# Step 1: i = 1, A[1] = 10 ≠ 70\n# Step 2: i = 2, A[2] = 20 ≤ 70\n# Step 3: i = 4, A[4] = 40 ≤ 70\n# Step 4: i = 8, A[8] = 80 > 70\n# Step 5: Binary search in range [4,8]\n#         mid = 6, A[6] = 60 < 70\n#         mid = 7, A[7] = 70 = 70\n#\n# Output: 7",
    "keySteps": [
      "Check if element is at first position",
      "Find range by exponentially increasing index",
      "Perform binary search in found range",
      "Return index if found, -1 otherwise"
    ]
  },
  "edit-distance": {
    "name": "Edit Distance",
    "type": "dynamic-programming",
    "description": "Edit Distance is an algorithm with time complexity O(mn). It is primarily used for string similarity and transformation",
    "timeComplexity": "O(mn) &nbsp;|&nbsp; Space: O(mn) &nbsp;|&nbsp; Use: String similarity and transformation\n    ",
    "spaceComplexity": "O(mn) &nbsp;|&nbsp; Use: String similarity and transformation\n    ",
    "useCase": "String similarity and transformation\n    ",
    "pseudocode": "EDIT-DISTANCE(s, t):\n    // s and t are input strings\n    // Returns minimum number of operations to transform s to t\n    m ← length(s)\n    n ← length(t)\n    dp[0..m][0..n] ← 0\n    \n    // Initialize first row and column\n    for i ← 0 to m:\n        dp[i][0] ← i\n    for j ← 0 to n:\n        dp[0][j] ← j\n    \n    // Fill dp table\n    for i ← 1 to m:\n        for j ← 1 to n:\n            if s[i-1] = t[j-1]:\n                dp[i][j] ← dp[i-1][j-1]\n            else:\n                dp[i][j] ← 1 + min(\n                    dp[i-1][j],    // deletion\n                    dp[i][j-1],    // insertion\n                    dp[i-1][j-1]   // substitution\n                )\n    \n    return dp[m][n]\n\n// Example:\n// Input: s = \"kitten\", t = \"sitting\"\n//\n// dp table:\n//    s i t t i n g\n// k  1 2 3 4 5 6 7\n// i  2 1 2 3 4 5 6\n// t  3 2 1 2 3 4 5\n// t  4 3 2 1 2 3 4\n// e  5 4 3 2 2 3 4\n// n  6 5 4 3 3 2 3\n//\n// Operations:\n// 1. kitten → sitten (substitute 'k' with 's')\n// 2. sitten → sittin (substitute 'e' with 'i')\n// 3. sittin → sitting (insert 'g')\n//\n// Edit distance: 3",
    "keySteps": [
      "Dynamic programming solution for string transformation",
      "Handles three operations: insertion, deletion, substitution",
      "Can be extended to include transposition and other operations",
      "Can be optimized to O(min(m,n)) space"
    ]
  },
  "dynamic-programming": {
    "name": "Dynamic Programming",
    "type": "dynamic-programming",
    "description": "Dynamic Programming is an algorithm with time complexity O(n²). It is primarily used for optimization problems with         overlapping subproblems",
    "timeComplexity": "O(n²) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Optimization problems with\n        overlapping subproblems\n      ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Optimization problems with\n        overlapping subproblems\n      ",
    "useCase": "Optimization problems with\n        overlapping subproblems\n      ",
    "pseudocode": "// Fibonacci\nFIBONACCI(n):\n  if n ≤ 1:\n    return n\n  dp = [0] * (n + 1)\n  dp[1] = 1\n  for i from 2 to n:\n    dp[i] = dp[i-1] + dp[i-2]\n  return dp[n]\n\n// Longest Common Subsequence\nLCS(X, Y):\n  m = length(X)\n  n = length(Y)\n  dp = [0] * (n + 1)\n  for i from 1 to m:\n    prev = 0\n    for j from 1 to n:\n      temp = dp[j]\n      if X[i-1] == Y[j-1]:\n        dp[j] = prev + 1\n      else:\n        dp[j] = max(dp[j], dp[j-1])\n      prev = temp\n  return dp[n]\n\n// Knapsack\nKNAPSACK(W, V, C):\n  n = length(W)\n  dp = [0] * (C + 1)\n  for i from 1 to n:\n    for j from C downto W[i-1]:\n      dp[j] = max(dp[j], dp[j-W[i-1]] + V[i-1])\n  return dp[C]\n\n// Matrix Chain Multiplication\nMCM(P):\n  n = length(P) - 1\n  dp = [0] * n\n  for l from 2 to n:\n    for i from 0 to n-l:\n      j = i + l - 1\n      dp[i][j] = ∞\n      for k from i to j-1:\n        cost = dp[i][k] + dp[k+1][j] + P[i]*P[k+1]*P[j+1]\n        if cost < dp[i][j]:\n          dp[i][j] = cost\n  return dp[0][n-1]",
    "keySteps": []
  },
  "dynamic-programming-pattern": {
    "name": "Dynamic Programming Pattern",
    "type": "dynamic-programming",
    "description": "This Pattern is an algorithm with time complexity O(n). It is primarily used for solving problems with overlapping       subproblems",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Solving problems with overlapping\n      subproblems\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Solving problems with overlapping\n      subproblems\n    ",
    "useCase": "Solving problems with overlapping\n      subproblems\n    ",
    "pseudocode": "DP-PATTERN(n)\n    # Define state and dependencies\n    state ← array[n+1]\n\n    # Initialize base cases\n    state[0] ← base_case_0\n    state[1] ← base_case_1\n\n    # Fill DP table\n    for i ← 2 to n\n        # Compute state from previous states\n        state[i] ← compute_state(state[i-1], state[i-2])\n\n    return state[n]\n\n# Example:\n# Input: n = 5\n# State: dp[i] represents solution for subproblem of size i\n# Base cases: dp[0] = 0, dp[1] = 1\n# Recurrence: dp[i] = dp[i-1] + dp[i-2]\n# Output: dp[5] = 5",
    "keySteps": [
      "Define: State and dependencies",
      "Initialize: Base cases",
      "Compute: States in correct order"
    ]
  },
  "dynamic-programming-iterative": {
    "name": "Dynamic Programming Iterative",
    "type": "dynamic-programming",
    "description": "Iterative DP is an algorithm with time complexity O(n). It is primarily used for solving problems with bottom-up       approach",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Solving problems with bottom-up\n      approach\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Solving problems with bottom-up\n      approach\n    ",
    "useCase": "Solving problems with bottom-up\n      approach\n    ",
    "pseudocode": "ITERATIVE-DP(n)\n    # Initialize DP array with base cases\n    dp[0] ← base_case_0\n    dp[1] ← base_case_1\n\n    # Fill DP array\n    for i ← 2 to n\n        dp[i] ← compute_from_previous(dp[i-1], dp[i-2])\n\n    return dp[n]\n\n# Example:\n# Input: n = 5\n# Base cases: dp[0] = 0, dp[1] = 1\n# Compute: dp[i] = dp[i-1] + dp[i-2]\n# Output: dp[5] = 5",
    "keySteps": [
      "Initialize: DP array with base cases",
      "Fill: DP array from bottom up",
      "Return: Final state value"
    ]
  },
  "coin-change": {
    "name": "Coin Change",
    "type": "dynamic-programming",
    "description": "Coin Change (DP) is an algorithm with time complexity O(n*m). It is primarily used for finding minimum coins needed for       amount",
    "timeComplexity": "O(n*m) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Finding minimum coins needed for\n      amount\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Finding minimum coins needed for\n      amount\n    ",
    "useCase": "Finding minimum coins needed for\n      amount\n    ",
    "pseudocode": "COIN-CHANGE(coins, amount)\n    # Initialize DP array with infinity\n    dp[0..amount] ← ∞\n    dp[0] ← 0  # Base case: 0 coins needed for amount 0\n\n    # Fill DP array\n    for i ← 1 to amount\n        for each coin in coins\n            if coin ≤ i\n                dp[i] ← min(dp[i], dp[i - coin] + 1)\n\n    if dp[amount] = ∞\n        return -1\n    else\n        return dp[amount]\n\n# Example:\n# Input: coins = [1, 2, 5], amount = 11\n# dp array after filling:\n# [0, 1, 1, 2, 2, 1, 2, 2, 3, 3, 2, 3]\n# Output: 3  # 5 + 5 + 1",
    "keySteps": [
      "Initialize: DP array with infinity and base case",
      "Fill: DP array by trying each coin",
      "Return: Minimum coins or -1 if impossible"
    ]
  },
  "doubly-linked-list": {
    "name": "Doubly Linked List",
    "type": "data-structures",
    "description": "A linked list where each node has references to both the next and previous nodes",
    "timeComplexity": "O(n) for access/search, O(1) for insertion/deletion",
    "spaceComplexity": "O(n) for storing n nodes",
    "useCase": "When you need bidirectional traversal and O(1) insertion/deletion at both ends",
    "pseudocode": "class Node:\n    def __init__(self, data):\n        self.data = data\n        self.next = None\n        self.prev = None\n\nclass DoublyLinkedList:\n    def __init__(self):\n        self.head = None\n        self.tail = None\n    \n    def insert_at_beginning(self, data):\n        new_node = Node(data)\n        if self.head is None:\n            self.head = new_node\n            self.tail = new_node\n        else:\n            new_node.next = self.head\n            self.head.prev = new_node\n            self.head = new_node\n    \n    def insert_at_end(self, data):\n        new_node = Node(data)\n        if self.tail is None:\n            self.head = new_node\n            self.tail = new_node\n        else:\n            new_node.prev = self.tail\n            self.tail.next = new_node\n            self.tail = new_node",
    "keySteps": [
      "Each node contains data and pointers to both next and previous nodes",
      "Maintain head and tail pointers for O(1) access to both ends",
      "Update both next and prev pointers when inserting or deleting nodes",
      "Handle edge cases: empty list, single node, first/last node operations"
    ]
  },
  "divide-and-conquer": {
    "name": "Divide and Conquer",
    "type": "divide-and-conquer",
    "description": "Divide and Conquer is an algorithm with time complexity O(n log n). It is primarily used for break problems into smaller       subproblems",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Break problems into smaller\n      subproblems\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Break problems into smaller\n      subproblems\n    ",
    "useCase": "Break problems into smaller\n      subproblems\n    ",
    "pseudocode": "// Merge Sort\nMERGE-SORT(A, l, r):\n  if l ≥ r:\n    return\n  mid = floor((l + r) / 2)\n  MERGE-SORT(A, l, mid)\n  MERGE-SORT(A, mid+1, r)\n  MERGE(A, l, mid, r)\n\n// Quick Sort\nQUICK-SORT(A, l, r):\n  if l ≥ r:\n    return\n  p = PARTITION(A, l, r)\n  QUICK-SORT(A, l, p-1)\n  QUICK-SORT(A, p+1, r)\n\n// Binary Search\nBINARY-SEARCH(A, l, r, x):\n  if l > r:\n    return -1\n  mid = floor((l + r) / 2)\n  if A[mid] == x:\n    return mid\n  if A[mid] > x:\n    return BINARY-SEARCH(A, l, mid-1, x)\n  return BINARY-SEARCH(A, mid+1, r, x)\n\n// Strassen's Matrix Multiplication\nSTRASSEN(A, B):\n  if A is 1x1:\n    return A * B\n  split A and B into 4 submatrices\n  P1 = STRASSEN(A11, B12 - B22)\n  P2 = STRASSEN(A11 + A12, B22)\n  P3 = STRASSEN(A21 + A22, B11)\n  P4 = STRASSEN(A22, B21 - B11)\n  P5 = STRASSEN(A11 + A22, B11 + B22)\n  P6 = STRASSEN(A12 - A22, B21 + B22)\n  P7 = STRASSEN(A11 - A21, B11 + B12)\n  C11 = P5 + P4 - P2 + P6\n  C12 = P1 + P2\n  C21 = P3 + P4\n  C22 = P5 + P1 - P3 - P7\n  return combine C11, C12, C21, C22",
    "keySteps": []
  },
  "dijkstras-algorithm": {
    "name": "Dijkstra's Algorithm",
    "type": "graph",
    "description": "Dijkstra's Algorithm is an algorithm with time complexity O((V+E). It is primarily used for finding shortest paths from a       source",
    "timeComplexity": "O((V+E)logV) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding shortest paths from a\n      source\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding shortest paths from a\n      source\n    ",
    "useCase": "Finding shortest paths from a\n      source\n    ",
    "pseudocode": "// Standard Dijkstra (Greedy Approach)\nDIJKSTRA(G, w, s)\n1  INITIALIZE-SINGLE-SOURCE(G, s)\n2  S = ∅  // Set of processed vertices\n3  Q = G.V  // Priority queue of vertices\n4  while Q ≠ ∅\n5      u = EXTRACT-MIN(Q)  // Greedy choice: vertex with minimum distance\n6      S = S ∪ {u}\n7      for each vertex v ∈ G.Adj[u]\n8          RELAX(u, v, w)\n\nINITIALIZE-SINGLE-SOURCE(G, s)\n1  for each vertex v ∈ G.V\n2      v.d = ∞\n3      v.π = NIL\n4  s.d = 0\n\nRELAX(u, v, w)\n1  if v.d > u.d + w(u, v)\n2      v.d = u.d + w(u, v)\n3      v.π = u\n\n// Dijkstra with Path Reconstruction\nDIJKSTRA-WITH-PATH(G, w, s, t)\n1  INITIALIZE-SINGLE-SOURCE(G, s)\n2  S = ∅\n3  Q = G.V\n4  while Q ≠ ∅\n5      u = EXTRACT-MIN(Q)\n6      if u == t\n7          break\n8      S = S ∪ {u}\n9      for each vertex v ∈ G.Adj[u]\n10         RELAX(u, v, w)\n11  return CONSTRUCT-PATH(s, t)\n\nCONSTRUCT-PATH(s, t)\n1  path = []\n2  u = t\n3  while u ≠ NIL\n4      path.append(u)\n5      u = u.π\n6  return REVERSE(path)\n\n// Bidirectional Dijkstra (Optimization)\nBIDIRECTIONAL-DIJKSTRA(G, w, s, t)\n1  INITIALIZE-SINGLE-SOURCE(G, s)\n2  INITIALIZE-SINGLE-SOURCE(G, t)\n3  S_f = ∅  // Forward search set\n4  S_b = ∅  // Backward search set\n5  Q_f = G.V  // Forward priority queue\n6  Q_b = G.V  // Backward priority queue\n7  min_dist = ∞\n8  meeting_node = NIL\n9  while Q_f ≠ ∅ and Q_b ≠ ∅\n10     u = EXTRACT-MIN(Q_f)\n11     if u ∈ S_f\n12         continue\n13     S_f = S_f ∪ {u}\n14     if u ∈ S_b\n15         total_dist = u.d + u.d_b\n16         if total_dist < min_dist\n17             min_dist = total_dist\n18             meeting_node = u\n19     for each vertex v ∈ G.Adj[u]\n20         if v ∉ S_f\n21             RELAX(u, v, w)\n22     u = EXTRACT-MIN(Q_b)\n23     if u ∈ S_b\n24         continue\n25     S_b = S_b ∪ {u}\n26     if u ∈ S_f\n27         total_dist = u.d + u.d_b\n28         if total_dist < min_dist\n29             min_dist = total_dist\n30             meeting_node = u\n31     for each vertex v ∈ G.Adj[u]\n32         if v ∉ S_b\n33             RELAX(u, v, w)\n34 return min_dist, meeting_node",
    "keySteps": []
  },
  "digit-dp": {
    "name": "Digit DP",
    "type": "dynamic-programming",
    "description": "Digit Dynamic Programming is an algorithm with time complexity O(d * s * b). It is primarily used for number range problems",
    "timeComplexity": "O(d * s * b) &nbsp;|&nbsp; Space: O(d * s) &nbsp;|&nbsp; Use: Number range problems\n    ",
    "spaceComplexity": "O(d * s) &nbsp;|&nbsp; Use: Number range problems\n    ",
    "useCase": "Number range problems\n    ",
    "pseudocode": "DIGIT-DP(low, high, condition):\n    // low and high are the range boundaries\n    // condition is a function that checks digit constraints\n    // Returns count of numbers in range satisfying condition\n    \n    function COUNT(n):\n        digits ← convert n to array of digits\n        d ← length(digits)\n        dp[d][s][tight] ← -1  // Initialize memoization table\n        \n        function SOLVE(pos, sum, tight):\n            if pos = d:\n                return 1 if condition(sum) else 0\n            \n            if dp[pos][sum][tight] ≠ -1:\n                return dp[pos][sum][tight]\n            \n            limit ← digits[pos] if tight else 9\n            count ← 0\n            \n            for digit ← 0 to limit:\n                new_tight ← tight and (digit = limit)\n                new_sum ← sum + digit\n                if condition(new_sum):\n                    count ← count + SOLVE(pos + 1, new_sum, new_tight)\n            \n            dp[pos][sum][tight] ← count\n            return count\n        \n        return SOLVE(0, 0, true)\n    \n    return COUNT(high) - COUNT(low - 1)\n\n// Example: Count numbers with digit sum = target\n// Range: [1, 1000], target = 10\n//\n// For number 123:\n// pos=0: digit=1, sum=1, tight=true\n// pos=1: digit=2, sum=3, tight=true\n// pos=2: digit=3, sum=6, tight=true\n//\n// For number 910:\n// pos=0: digit=9, sum=9, tight=true\n// pos=1: digit=1, sum=10, tight=true\n// pos=2: digit=0, sum=10, tight=false",
    "keySteps": [
      "Efficiently solves number range problems",
      "Uses digit-by-digit processing with memoization",
      "Handles constraints on digits and their properties",
      "Efficient for large number ranges with digit constraints"
    ]
  },
  "dfs": {
    "name": "DFS",
    "type": "graph",
    "description": "DFS is an algorithm with time complexity O(V + E). It is primarily used for topological sort, cycle detection,       and strongly connected components",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Topological sort, cycle detection,\n      and strongly connected components\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Topological sort, cycle detection,\n      and strongly connected components\n    ",
    "useCase": "Topological sort, cycle detection,\n      and strongly connected components\n    ",
    "pseudocode": "// Standard DFS\nDFS(G):\n  for each vertex u in G.V:\n    u.color = WHITE\n    u.π = NIL\n  time = 0\n  for each vertex u in G.V:\n    if u.color == WHITE:\n      DFS-VISIT(G, u)\n\nDFS-VISIT(G, u):\n  time = time + 1\n  u.d = time\n  u.color = GRAY\n  for each v in G.adj[u]:\n    if v.color == WHITE:\n      v.π = u\n      DFS-VISIT(G, v)\n  u.color = BLACK\n  time = time + 1\n  u.f = time\n\n// Topological Sort\nTOPOLOGICAL-SORT(G):\n  DFS(G)\n  sort vertices by decreasing finish time\n  return sorted vertices\n\n// Cycle Detection\nHAS-CYCLE(G):\n  for each vertex u in G.V:\n    u.color = WHITE\n  for each vertex u in G.V:\n    if u.color == WHITE:\n      if DFS-CYCLE(G, u):\n        return true\n  return false\n\nDFS-CYCLE(G, u):\n  u.color = GRAY\n  for each v in G.adj[u]:\n    if v.color == WHITE:\n      if DFS-CYCLE(G, v):\n        return true\n    elif v.color == GRAY:\n      return true\n  u.color = BLACK\n  return false\n\n// Strongly Connected Components\nSCC(G):\n  DFS(G)\n  compute G^T\n  DFS(G^T) in order of decreasing finish time\n  return trees in depth-first forest",
    "keySteps": []
  },
  "dfs-linked-list": {
    "name": "DFS Linked List",
    "type": "graph",
    "description": "DFS (Linked List) is an algorithm with time complexity O(n). It is primarily used for traverse linked list depth-first",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Traverse linked list depth-first\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Traverse linked list depth-first\n    ",
    "useCase": "Traverse linked list depth-first\n    ",
    "pseudocode": "// Node structure for linked list\nNODE:\n    key\n    next\n    visited\n\n// DFS on linked list\nDFS-LINKED-LIST(head):\n    if head = NIL:\n        return\n\n    // Mark current node as visited\n    head.visited ← true\n    process head.key\n\n    // Recursively visit next node if not visited\n    if head.next ≠ NIL and not head.next.visited:\n        DFS-LINKED-LIST(head.next)\n\n// Example:\n// Input: 1 → 2 → 3 → 4 → 5\n//\n// Execution:\n// 1. Visit 1, visited = {1}\n// 2. Visit 2, visited = {1,2}\n// 3. Visit 3, visited = {1,2,3}\n// 4. Visit 4, visited = {1,2,3,4}\n// 5. Visit 5, visited = {1,2,3,4,5}\n//\n// Output: 1, 2, 3, 4, 5",
    "keySteps": [
      "Visit: Process current node",
      "Mark: Node as visited",
      "Recurse: Visit next unvisited node"
    ]
  },
  "dfs-graph": {
    "name": "DFS Graph",
    "type": "graph",
    "description": "Depth-First Search for Graph Traversal",
    "timeComplexity": "O(V + E) where V is vertices and E is edges",
    "spaceComplexity": "O(V) for visited set and recursion stack",
    "useCase": "Finding connected components, cycle detection, topological sorting",
    "pseudocode": "function DFS(graph, start):\n    visited = set()\n    stack = [start]\n    \n    while stack is not empty:\n        current = stack.pop()\n        \n        if current not in visited:\n            visited.add(current)\n            process(current)\n            \n            for neighbor in graph[current]:\n                if neighbor not in visited:\n                    stack.append(neighbor)",
    "keySteps": [
      "Initialize: Visited set and stack with start vertex",
      "Process: Pop vertex from stack and mark as visited",
      "Explore: Add unvisited neighbors to stack",
      "Repeat: Until stack is empty"
    ]
  },
  "dfs-binary-tree": {
    "name": "DFS (Binary Tree)",
    "type": "tree",
    "description": "DFS (Binary Tree) is an algorithm with time complexity O(n). It is primarily used for traverse binary tree in depth-first       order",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(h) &nbsp;|&nbsp; Use: Traverse binary tree in depth-first\n      order\n    ",
    "spaceComplexity": "O(h) &nbsp;|&nbsp; Use: Traverse binary tree in depth-first\n      order\n    ",
    "useCase": "Traverse binary tree in depth-first\n      order\n    ",
    "pseudocode": "# DFS (Binary Tree): Traverse binary tree in depth-first order\n# Input: Binary tree T with root node\n# Output: List of nodes in DFS order\n\nAlgorithm DFS-BINARY-TREE(T)\n    if T.root = NIL then\n        return empty list\n    end if\n\n    result ← empty list\n    stack ← empty stack\n    stack.push(T.root)\n\n    while stack is not empty do\n        node ← stack.pop()\n        result.append(node.value)\n\n        # Push right child first so left is processed first\n        if node.right ≠ NIL then\n            stack.push(node.right)\n        end if\n\n        if node.left ≠ NIL then\n            stack.push(node.left)\n        end if\n    end while\n\n    return result\n\n# Example:\n# Input: Binary tree\n#        1\n#       / \\\n#      2   3\n#     / \\   \\\n#    4   5   6\n#\n# Step 1: Push 1\n# Step 2: Pop 1, Push 3, Push 2\n# Step 3: Pop 2, Push 5, Push 4\n# Step 4: Pop 4\n# Step 5: Pop 5\n# Step 6: Pop 3, Push 6\n# Step 7: Pop 6\n#\n# Output: [1, 2, 4, 5, 3, 6]",
    "keySteps": [
      "Initialize stack and result list",
      "Push root node onto stack",
      "Process nodes in stack order, pushing right then left children",
      "Return list of processed nodes"
    ]
  },
  "counting-sort": {
    "name": "Counting Sort",
    "type": "sorting",
    "description": "Counting Sort is an algorithm with time complexity O(n+k). It is primarily used for sorting integers with small range",
    "timeComplexity": "O(n+k) &nbsp;|&nbsp; Space: O(n+k) &nbsp;|&nbsp; Use: Sorting integers with small range\n    ",
    "spaceComplexity": "O(n+k) &nbsp;|&nbsp; Use: Sorting integers with small range\n    ",
    "useCase": "Sorting integers with small range\n    ",
    "pseudocode": "// Standard Counting Sort\nCOUNTING-SORT(A):\n    # Find maximum value\n    max_val = max(A)\n    n = len(A)\n\n    # Initialize count array\n    count = [0] * (max_val + 1)\n    output = [0] * n\n\n    # Store count of each element\n    for x in A:\n        count[x] += 1\n\n    # Change count[i] to position of element\n    for i in range(1, max_val + 1):\n        count[i] += count[i-1]\n\n    # Build output array\n    for i in range(n-1, -1, -1):\n        output[count[A[i]]-1] = A[i]\n        count[A[i]] -= 1\n\n    return output\n\n// Counting Sort with Negative Numbers\nCOUNTING-SORT-NEGATIVE(A):\n    # Find min and max values\n    min_val = min(A)\n    max_val = max(A)\n    range_val = max_val - min_val + 1\n    n = len(A)\n\n    # Initialize count array\n    count = [0] * range_val\n    output = [0] * n\n\n    # Store count of each element\n    for x in A:\n        count[x - min_val] += 1\n\n    # Change count[i] to position of element\n    for i in range(1, range_val):\n        count[i] += count[i-1]\n\n    # Build output array\n    for i in range(n-1, -1, -1):\n        output[count[A[i] - min_val]-1] = A[i]\n        count[A[i] - min_val] -= 1\n\n    return output\n\n// Counting Sort with Objects\nCOUNTING-SORT-OBJECTS(A, key_func):\n    # Find maximum key value\n    max_key = max(key_func(x) for x in A)\n    n = len(A)\n\n    # Initialize count array\n    count = [0] * (max_key + 1)\n    output = [None] * n\n\n    # Store count of each key\n    for x in A:\n        count[key_func(x)] += 1\n\n    # Change count[i] to position of element\n    for i in range(1, max_key + 1):\n        count[i] += count[i-1]\n\n    # Build output array\n    for i in range(n-1, -1, -1):\n        key = key_func(A[i])\n        output[count[key]-1] = A[i]\n        count[key] -= 1\n\n    return output\n\n// Counting Sort with Radix\nCOUNTING-SORT-RADIX(A, exp):\n    n = len(A)\n    output = [0] * n\n    count = [0] * 10\n\n    # Store count of occurrences\n    for i in range(n):\n        index = (A[i] // exp) % 10\n        count[index] += 1\n\n    # Change count[i] to position of digit\n    for i in range(1, 10):\n        count[i] += count[i-1]\n\n    # Build output array\n    for i in range(n-1, -1, -1):\n        index = (A[i] // exp) % 10\n        output[count[index]-1] = A[i]\n        count[index] -= 1\n\n    # Copy output to A\n    for i in range(n):\n        A[i] = output[i]",
    "keySteps": []
  },
  "circular-linked-list": {
    "name": "Circular Linked List",
    "type": "data-structures",
    "description": "Circular Linked List is an algorithm with time complexity O(n). It is primarily used for circular data structure operations",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Circular data structure operations\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Circular data structure operations\n    ",
    "useCase": "Circular data structure operations\n    ",
    "pseudocode": "// Node structure\nNODE(key):\n    key ← key\n    next ← null\n\n// Insert at beginning\nCIRCULAR-INSERT-HEAD(L, x):\n    x.next ← x\n    if L.head = null:\n        L.head ← x\n    else:\n        x.next ← L.head\n        last ← L.head\n        while last.next ≠ L.head:\n            last ← last.next\n        last.next ← x\n        L.head ← x\n\n// Insert at end\nCIRCULAR-INSERT-TAIL(L, x):\n    x.next ← x\n    if L.head = null:\n        L.head ← x\n    else:\n        last ← L.head\n        while last.next ≠ L.head:\n            last ← last.next\n        last.next ← x\n        x.next ← L.head\n\n// Delete node\nCIRCULAR-DELETE(L, x):\n    if L.head = null:\n        return\n    if L.head = x and L.head.next = L.head:\n        L.head ← null\n        return\n    if L.head = x:\n        last ← L.head\n        while last.next ≠ L.head:\n            last ← last.next\n        L.head ← L.head.next\n        last.next ← L.head\n        return\n    prev ← L.head\n    while prev.next ≠ L.head and prev.next ≠ x:\n        prev ← prev.next\n    if prev.next = x:\n        prev.next ← prev.next.next\n\n// Traverse list\nCIRCULAR-TRAVERSE(L):\n    if L.head = null:\n        return\n    current ← L.head\n    repeat:\n        print(current.key)\n        current ← current.next\n    until current = L.head\n\n// Example:\n// Input: Operations [INSERT-HEAD(1), INSERT-TAIL(2), INSERT-HEAD(3), DELETE(1)]\n//\n// After INSERT-HEAD(1):\n//   1 -> 1\n//\n// After INSERT-TAIL(2):\n//   1 -> 2 -> 1\n//\n// After INSERT-HEAD(3):\n//   3 -> 1 -> 2 -> 3\n//\n// After DELETE(1):\n//   3 -> 2 -> 3",
    "keySteps": [
      "Insert: Add node while maintaining circular structure",
      "Delete: Remove node and update circular links",
      "Traverse: Visit all nodes in circular order"
    ]
  },
  "chinese-remainder-theorem": {
    "name": "Chinese Remainder Theorem",
    "type": "number-theory",
    "description": "Chinese Remainder Theorem is an algorithm with time complexity O(n²). It is primarily used for solve system of congruences",
    "timeComplexity": "O(n²) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Solve system of congruences\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Solve system of congruences\n    ",
    "useCase": "Solve system of congruences\n    ",
    "pseudocode": "CRT(a, m)\n    let n be the length of a\n    let M ← 1\n    for i ← 1 to n\n        do M ← M · m[i]\n\n    let x ← 0\n    for i ← 1 to n\n        do let Mi ← M / m[i]\n            let yi ← MODULAR-INVERSE(Mi, m[i])\n            x ← x + a[i] · Mi · yi\n\n    return x mod M\n\nMODULAR-INVERSE(a, m)\n    let g, x, y be the result of EXTENDED-EUCLID(a, m)\n    if g ≠ 1\n        then return NIL\n    return x mod m\n\nEXTENDED-EUCLID(a, b)\n    if b = 0\n        then return (a, 1, 0)\n    let (d', x', y') ← EXTENDED-EUCLID(b, a mod b)\n    let d ← d'\n    let x ← y'\n    let y ← x' - ⌊a/b⌋ · y'\n    return (d, x, y)\n\n// Example:\n// Input: a = [2, 3, 2], m = [3, 5, 7]\n//\n// M = 3·5·7 = 105\n//\n// For i = 1:\n//   M₁ = 105/3 = 35\n//   y₁ = 2 (inverse of 35 mod 3)\n//\n// For i = 2:\n//   M₂ = 105/5 = 21\n//   y₂ = 1 (inverse of 21 mod 5)\n//\n// For i = 3:\n//   M₃ = 105/7 = 15\n//   y₃ = 1 (inverse of 15 mod 7)\n//\n// x = 2·35·2 + 3·21·1 + 2·15·1 = 233\n//\n// Output: 233 mod 105 = 23",
    "keySteps": [
      "Compute: Product of all moduli",
      "Calculate: Modular inverses using extended Euclidean algorithm",
      "Combine: Solutions using CRT formula"
    ]
  },
  "bucket-sort": {
    "name": "Bucket Sort",
    "type": "array",
    "description": "Bucket Sort is an algorithm with time complexity O(n). It is primarily used for sorting uniformly distributed numbers",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Sorting uniformly distributed numbers\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Sorting uniformly distributed numbers\n    ",
    "useCase": "Sorting uniformly distributed numbers\n    ",
    "pseudocode": "// Standard Bucket Sort\nBUCKET-SORT(A):\n    # Initialize buckets\n    n = len(A)\n    buckets = [[] for _ in range(n)]\n\n    # Distribute elements into buckets\n    for x in A:\n        bucket_idx = int(x * n)\n        buckets[bucket_idx].append(x)\n\n    # Sort individual buckets\n    for bucket in buckets:\n        INSERTION-SORT(bucket)\n\n    # Concatenate buckets\n    result = []\n    for bucket in buckets:\n        result.extend(bucket)\n\n    return result\n\n// Bucket Sort with Custom Range\nBUCKET-SORT-RANGE(A, min_val, max_val):\n    # Initialize buckets\n    n = len(A)\n    buckets = [[] for _ in range(n)]\n\n    # Distribute elements into buckets\n    for x in A:\n        bucket_idx = int((x - min_val) / (max_val - min_val) * (n-1))\n        buckets[bucket_idx].append(x)\n\n    # Sort individual buckets\n    for bucket in buckets:\n        INSERTION-SORT(bucket)\n\n    # Concatenate buckets\n    result = []\n    for bucket in buckets:\n        result.extend(bucket)\n\n    return result\n\n// Bucket Sort with Linked Lists\nBUCKET-SORT-LIST(A):\n    # Initialize buckets\n    n = len(A)\n    buckets = [LinkedList() for _ in range(n)]\n\n    # Distribute elements into buckets\n    for x in A:\n        bucket_idx = int(x * n)\n        buckets[bucket_idx].append(x)\n\n    # Sort individual buckets\n    for bucket in buckets:\n        bucket.sort()\n\n    # Concatenate buckets\n    result = []\n    for bucket in buckets:\n        result.extend(bucket.to_list())\n\n    return result\n\n// Bucket Sort with Counting Sort\nBUCKET-SORT-COUNTING(A):\n    # Initialize buckets\n    n = len(A)\n    buckets = [[] for _ in range(n)]\n\n    # Distribute elements into buckets\n    for x in A:\n        bucket_idx = int(x * n)\n        buckets[bucket_idx].append(x)\n\n    # Sort individual buckets using counting sort\n    for bucket in buckets:\n        if bucket:\n            max_val = max(bucket)\n            count = [0] * (max_val + 1)\n            for x in bucket:\n                count[x] += 1\n            sorted_bucket = []\n            for i in range(max_val + 1):\n                sorted_bucket.extend([i] * count[i])\n            bucket[:] = sorted_bucket\n\n    # Concatenate buckets\n    result = []\n    for bucket in buckets:\n        result.extend(bucket)\n\n    return result",
    "keySteps": []
  },
  "bubble-sort": {
    "name": "Bubble Sort",
    "type": "sorting",
    "description": "Bubble Sort is an algorithm with time complexity O(n²). It is primarily used for sorting array in-place",
    "timeComplexity": "O(n²) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Sorting array in-place\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Sorting array in-place\n    ",
    "useCase": "Sorting array in-place\n    ",
    "pseudocode": "# Bubble Sort: Repeatedly swap adjacent elements if they are in wrong order\n# Input: Array A[1..n] of n elements\n# Output: Array A sorted in non-decreasing order\n\nBUBBLE-SORT(A)\n    n ← length[A]    # Number of elements in array\n\n    # Outer loop: n-1 passes needed\n    for i ← 1 to n-1 do\n        # Inner loop: compare adjacent elements\n        for j ← 1 to n-i do\n            # Swap if elements are in wrong order\n            if A[j] > A[j+1] then\n                # Exchange A[j] and A[j+1]\n                temp ← A[j]\n                A[j] ← A[j+1]\n                A[j+1] ← temp\n            end if\n        end for\n    end for\n\n# Example:\n# Input: A = [5, 2, 4, 6, 1, 3]\n# Pass 1: [2, 4, 5, 1, 3, 6]  # 6 bubbles to end\n# Pass 2: [2, 4, 1, 3, 5, 6]  # 5 bubbles to end\n# Pass 3: [2, 1, 3, 4, 5, 6]  # 4 bubbles to end\n# Pass 4: [1, 2, 3, 4, 5, 6]  # 3 bubbles to end\n# Pass 5: [1, 2, 3, 4, 5, 6]  # 2 bubbles to end\n# Output: [1, 2, 3, 4, 5, 6]",
    "keySteps": []
  },
  "bitwise-dp": {
    "name": "Bitwise DP",
    "type": "dynamic-programming",
    "description": "Bitwise Dynamic Programming is an algorithm with time complexity O(n2ⁿ). It is primarily used for subset problems and state       compression",
    "timeComplexity": "O(n2ⁿ) &nbsp;|&nbsp; Space: O(2ⁿ) &nbsp;|&nbsp; Use: Subset problems and state\n      compression\n    ",
    "spaceComplexity": "O(2ⁿ) &nbsp;|&nbsp; Use: Subset problems and state\n      compression\n    ",
    "useCase": "Subset problems and state\n      compression\n    ",
    "pseudocode": "BITWISE-DP(n, cost):\n    // n is number of elements\n    // cost[i][j] is cost of including element j in subset i\n    // Returns minimum cost of covering all elements\n    \n    // Initialize dp array\n    dp[0..2ⁿ-1] ← ∞\n    dp[0] ← 0\n    \n    // Iterate through all possible subsets\n    for mask ← 0 to 2ⁿ-1:\n        // Try adding each element to current subset\n        for j ← 0 to n-1:\n            if not (mask & (1 << j)):\n                new_mask ← mask | (1 << j)\n                dp[new_mask] ← min(dp[new_mask], dp[mask] + cost[mask][j])\n    \n    return dp[2ⁿ-1]\n\n// Example: Traveling Salesman Problem\n// n = 3 cities\n// cost matrix:\n// 0 10 15\n// 10 0 20\n// 15 20 0\n//\n// Binary representation of states:\n// 000: empty set\n// 001: {0}\n// 010: {1}\n// 011: {0,1}\n// 100: {2}\n// 101: {0,2}\n// 110: {1,2}\n// 111: {0,1,2}\n//\n// Final answer: minimum cost of visiting all cities",
    "keySteps": [
      "Uses bit manipulation for state representation",
      "Efficient for subset and permutation problems",
      "Common in competitive programming",
      "Practical for n ≤ 20 due to exponential complexity"
    ]
  },
  "bit-manipulation": {
    "name": "Bit Manipulation",
    "type": "data-structures",
    "description": "Bit Manipulation is an algorithm with time complexity O(1). It is primarily used for efficient bit-level operations",
    "timeComplexity": "O(1) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Efficient bit-level operations\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Efficient bit-level operations\n    ",
    "useCase": "Efficient bit-level operations\n    ",
    "pseudocode": "// Basic Operations\nAND(x, y):     return x & y\nOR(x, y):      return x | y\nXOR(x, y):     return x ^ y\nNOT(x):        return ~x\nLEFT-SHIFT(x, n):  return x << n\nRIGHT-SHIFT(x, n): return x >> n\n\n// Count Set Bits\nCOUNT-BITS(x):\n  count = 0\n  while x > 0:\n    count += x & 1\n    x = x >> 1\n  return count\n\n// Check Power of Two\nIS-POWER-OF-TWO(x):\n  return x > 0 and (x & (x - 1)) == 0\n\n// Find Single Number\nSINGLE-NUMBER(A):\n  result = 0\n  for num in A:\n    result ^= num\n  return result\n\n// Swap Without Temp\nSWAP(x, y):\n  x = x ^ y\n  y = x ^ y\n  x = x ^ y\n  return (x, y)\n\n// Add Without Plus\nADD(x, y):\n  while y != 0:\n    carry = x & y\n    x = x ^ y\n    y = carry << 1\n  return x",
    "keySteps": []
  },
  "binary-search": {
    "name": "Binary Search",
    "type": "searching",
    "description": "Binary Search is an algorithm with time complexity O(log n). It is primarily used for searching in sorted arrays",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Searching in sorted arrays\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Searching in sorted arrays\n    ",
    "useCase": "Searching in sorted arrays\n    ",
    "pseudocode": "// Standard Binary Search\nBINARY-SEARCH(A, x):\n  left = 0\n  right = n - 1\n  while left ≤ right:\n    mid = floor((left + right) / 2)\n    if A[mid] == x:\n      return mid\n    if A[mid] < x:\n      left = mid + 1\n    else:\n      right = mid - 1\n  return -1\n\n// First Occurrence\nFIRST-OCCURRENCE(A, x):\n  left = 0\n  right = n - 1\n  result = -1\n  while left ≤ right:\n    mid = floor((left + right) / 2)\n    if A[mid] == x:\n      result = mid\n      right = mid - 1\n    elif A[mid] < x:\n      left = mid + 1\n    else:\n      right = mid - 1\n  return result\n\n// Last Occurrence\nLAST-OCCURRENCE(A, x):\n  left = 0\n  right = n - 1\n  result = -1\n  while left ≤ right:\n    mid = floor((left + right) / 2)\n    if A[mid] == x:\n      result = mid\n      left = mid + 1\n    elif A[mid] < x:\n      left = mid + 1\n    else:\n      right = mid - 1\n  return result\n\n// Rotated Array Search\nROTATED-SEARCH(A, x):\n  left = 0\n  right = n - 1\n  while left ≤ right:\n    mid = floor((left + right) / 2)\n    if A[mid] == x:\n      return mid\n    if A[left] ≤ A[mid]:\n      if A[left] ≤ x < A[mid]:\n        right = mid - 1\n      else:\n        left = mid + 1\n    else:\n      if A[mid] < x ≤ A[right]:\n        left = mid + 1\n      else:\n        right = mid - 1\n  return -1",
    "keySteps": []
  },
  "binary-search-tree": {
    "name": "Binary Search Tree",
    "type": "tree",
    "description": "Binary Search Tree is an algorithm with time complexity O(h). It is primarily used for efficient search and insertion",
    "timeComplexity": "O(h) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Efficient search and insertion\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Efficient search and insertion\n    ",
    "useCase": "Efficient search and insertion\n    ",
    "pseudocode": "// Binary search tree node structure\nBST-NODE:\n    key\n    left\n    right\n    parent\n\n// Tree operations\nTREE-INSERT(T, z):\n    y ← NIL\n    x ← T.root\n    while x ≠ NIL:\n        y ← x\n        if z.key < x.key:\n            x ← x.left\n        else:\n            x ← x.right\n    z.parent ← y\n    if y = NIL:\n        T.root ← z\n    else if z.key < y.key:\n        y.left ← z\n    else:\n        y.right ← z\n\nTREE-SEARCH(x, k):\n    if x = NIL or k = x.key:\n        return x\n    if k < x.key:\n        return TREE-SEARCH(x.left, k)\n    else:\n        return TREE-SEARCH(x.right, k)\n\nTREE-DELETE(T, z):\n    if z.left = NIL:\n        TRANSPLANT(T, z, z.right)\n    else if z.right = NIL:\n        TRANSPLANT(T, z, z.left)\n    else:\n        y ← TREE-MINIMUM(z.right)\n        if y.parent ≠ z:\n            TRANSPLANT(T, y, y.right)\n            y.right ← z.right\n            y.right.parent ← y\n        TRANSPLANT(T, z, y)\n        y.left ← z.left\n        y.left.parent ← y\n\nTRANSPLANT(T, u, v):\n    if u.parent = NIL:\n        T.root ← v\n    else if u = u.parent.left:\n        u.parent.left ← v\n    else:\n        u.parent.right ← v\n    if v ≠ NIL:\n        v.parent ← u.parent\n\n// Example:\n// Input: T = empty tree\n// Operations:\n// 1. Insert 5\n// 2. Insert 3\n// 3. Insert 7\n// 4. Insert 2\n// 5. Insert 4\n// 6. Insert 6\n// 7. Insert 8\n//\n// Resulting tree:\n//        5\n//      /   \\\\\n//     3     7\n//    / \\\\   / \\\\\n//   2   4 6   8",
    "keySteps": [
      "Insert: Maintain BST property",
      "Search: Binary search in tree",
      "Delete: Handle three cases"
    ]
  },
  "binary-search-on-answer": {
    "name": "Binary Search on Answer",
    "type": "searching",
    "description": "Binary Search on Answer is an algorithm with time complexity O(n log m). It is primarily used for find optimal value in search       space",
    "timeComplexity": "O(n log m) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find optimal value in search\n      space\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find optimal value in search\n      space\n    ",
    "useCase": "Find optimal value in search\n      space\n    ",
    "pseudocode": "// Binary search on answer with predicate function\nBINARY-SEARCH-ANSWER(low, high, predicate):\n    while low < high:\n        mid ← ⌊(low + high) / 2⌋\n        if predicate(mid):\n            high ← mid\n        else:\n            low ← mid + 1\n    return low\n\n// Example: Find minimum capacity to ship packages within D days\nSHIP-PACKAGES(weights, D):\n    n ← length[weights]\n    low ← max(weights)\n    high ← sum(weights)\n    predicate ← λ(capacity):\n        days ← 1\n        current ← 0\n        for i ← 1 to n:\n            if current + weights[i] > capacity:\n                days ← days + 1\n                current ← weights[i]\n            else:\n                current ← current + weights[i]\n        return days ≤ D\n    return BINARY-SEARCH-ANSWER(low, high, predicate)\n\n// Example:\n// Input: weights = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], D = 5\n//\n// Execution:\n// 1. low = 10, high = 55\n// 2. mid = 32: days = 3 ≤ 5\n// 3. mid = 21: days = 4 ≤ 5\n// 4. mid = 15: days = 5 ≤ 5\n// 5. mid = 12: days = 6 > 5\n// 6. mid = 13: days = 6 > 5\n// 7. mid = 14: days = 5 ≤ 5\n//\n// Output: 15",
    "keySteps": [
      "Initialize: Set search space boundaries",
      "Search: Binary search with predicate function",
      "Verify: Check if solution meets requirements"
    ]
  },
  "binary-indexed-tree": {
    "name": "Binary Indexed Tree",
    "type": "data-structures",
    "description": "Binary Indexed Tree is an algorithm with time complexity O(log n). It is primarily used for efficient range queries and point       updates",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Efficient range queries and point\n      updates\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Efficient range queries and point\n      updates\n    ",
    "useCase": "Efficient range queries and point\n      updates\n    ",
    "pseudocode": "BINARY-INDEXED-TREE(A)\n    let n be the length of A\n    let tree[1‥n] be a new array\n\n    for i ← 1 to n\n        do tree[i] ← 0\n\n    for i ← 1 to n\n        do UPDATE(tree, i, A[i])\n\n    return tree\n\nUPDATE(tree, idx, delta)\n    while idx ≤ n\n        do tree[idx] ← tree[idx] + delta\n            idx ← idx + (idx & -idx)\n\nQUERY(tree, idx)\n    let sum ← 0\n    while idx > 0\n        do sum ← sum + tree[idx]\n            idx ← idx - (idx & -idx)\n    return sum\n\nRANGE-QUERY(tree, l, r)\n    return QUERY(tree, r) - QUERY(tree, l-1)\n\n// Example:\n// Input: A = [1, 3, 5, 7, 9, 11]\n//\n// Initial tree:\n//   tree = [0, 0, 0, 0, 0, 0]\n//\n// After updates:\n//   tree = [1, 4, 5, 16, 9, 20]\n//\n// Query(4):\n//   idx = 4: sum = 16\n//   idx = 0: return 16\n//\n// Range Query(2,5):\n//   QUERY(5) = 25\n//   QUERY(1) = 1\n//   return 24\n//\n// Output: Range sum from index 2 to 5 is 24",
    "keySteps": [
      "Initialize: Create tree array and set all values to 0",
      "Update: Add value to all affected nodes using LSB",
      "Query: Compute prefix sums and range queries efficiently"
    ]
  },
  "bfs": {
    "name": "BFS",
    "type": "graph",
    "description": "BFS is an algorithm with time complexity O(V + E). It is primarily used for level-order traversal and shortest       path in unweighted graphs",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Level-order traversal and shortest\n      path in unweighted graphs\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Level-order traversal and shortest\n      path in unweighted graphs\n    ",
    "useCase": "Level-order traversal and shortest\n      path in unweighted graphs\n    ",
    "pseudocode": "// Standard BFS\nBFS(G, s):\n  for each vertex u in G.V - {s}:\n    u.color = WHITE\n    u.d = ∞\n    u.π = NIL\n  s.color = GRAY\n  s.d = 0\n  s.π = NIL\n  Q = ∅\n  ENQUEUE(Q, s)\n  while Q ≠ ∅:\n    u = DEQUEUE(Q)\n    for each v in G.adj[u]:\n      if v.color == WHITE:\n        v.color = GRAY\n        v.d = u.d + 1\n        v.π = u\n        ENQUEUE(Q, v)\n    u.color = BLACK\n\n// Shortest Path\nSHORTEST-PATH(G, s, t):\n  BFS(G, s)\n  if t.d == ∞:\n    return NIL\n  path = []\n  u = t\n  while u ≠ NIL:\n    path.append(u)\n    u = u.π\n  return reverse(path)\n\n// Connected Components\nCONNECTED-COMPONENTS(G):\n  for each vertex u in G.V:\n    u.color = WHITE\n    u.π = NIL\n  cc = 0\n  for each vertex u in G.V:\n    if u.color == WHITE:\n      cc += 1\n      BFS-VISIT(G, u, cc)\n  return cc\n\n// Level Order Traversal\nLEVEL-ORDER(T):\n  if T.root == NIL:\n    return []\n  Q = ∅\n  ENQUEUE(Q, T.root)\n  result = []\n  while Q ≠ ∅:\n    level_size = Q.size\n    level = []\n    for i from 1 to level_size:\n      u = DEQUEUE(Q)\n      level.append(u.key)\n      if u.left ≠ NIL:\n        ENQUEUE(Q, u.left)\n      if u.right ≠ NIL:\n        ENQUEUE(Q, u.right)\n    result.append(level)\n  return result",
    "keySteps": []
  },
  "bfs-linked-list": {
    "name": "BFS Linked List",
    "type": "data-structures",
    "description": "BFS Linked List is an algorithm with time complexity O(n). It is primarily used for traverse linked list level by level",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Traverse linked list level by level\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Traverse linked list level by level\n    ",
    "useCase": "Traverse linked list level by level\n    ",
    "pseudocode": "// Node structure for linked list\nNODE:\n    key\n    next\n    visited\n\n// BFS on linked list\nBFS-LINKED-LIST(head):\n    if head = NIL:\n        return\n\n    // Initialize queue and mark head as visited\n    Q ← ∅\n    ENQUEUE(Q, head)\n    head.visited ← true\n\n    while Q ≠ ∅:\n        u ← DEQUEUE(Q)\n        process u.key\n\n        // Process next node if not visited\n        if u.next ≠ NIL and not u.next.visited:\n            u.next.visited ← true\n            ENQUEUE(Q, u.next)\n\n// Example:\n// Input: 1 → 2 → 3 → 4 → 5\n//\n// Execution:\n// 1. Q = [1], visited = {1}\n// 2. Q = [2], visited = {1,2}\n// 3. Q = [3], visited = {1,2,3}\n// 4. Q = [4], visited = {1,2,3,4}\n// 5. Q = [5], visited = {1,2,3,4,5}\n//\n// Output: 1, 2, 3, 4, 5",
    "keySteps": [
      "Initialize: Queue and visited set",
      "Process: Nodes level by level",
      "Mark: Visited nodes to prevent cycles"
    ]
  },
  "bellman-ford": {
    "name": "Bellman Ford",
    "type": "graph",
    "description": "Bellman Ford is an algorithm with time complexity O(VE). It is primarily used for find shortest paths with negative       weights",
    "timeComplexity": "O(VE) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find shortest paths with negative\n      weights\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find shortest paths with negative\n      weights\n    ",
    "useCase": "Find shortest paths with negative\n      weights\n    ",
    "pseudocode": "# Bellman-Ford: Find shortest paths with negative weights\n# Input: Weighted directed graph G = (V, E) with weight function w, source vertex s\n# Output: Shortest paths from s to all vertices, or indication of negative cycle\n\nAlgorithm BELLMAN-FORD(G, w, s)\n    # Initialize distances\n    for each vertex v in V do\n        d[v] ← ∞\n        π[v] ← NIL\n    end for\n    d[s] ← 0\n\n    # Relax edges |V| - 1 times\n    for i ← 1 to |V| - 1 do\n        for each edge (u, v) in E do\n            if d[v] > d[u] + w(u, v) then\n                d[v] ← d[u] + w(u, v)\n                π[v] ← u\n            end if\n        end for\n    end for\n\n    # Check for negative cycles\n    for each edge (u, v) in E do\n        if d[v] > d[u] + w(u, v) then\n            return \"Graph contains negative cycle\"\n        end if\n    end for\n\n    return d, π\n\n# Example:\n# Input: G with V = {s,a,b,c} and edges:\n# (s,a,4), (s,b,5), (a,b,-1), (a,c,2), (b,c,1)\n#\n# Step 1: Initial distances\n#         d = [0, ∞, ∞, ∞]\n# Step 2: After first relaxation\n#         d = [0, 4, 5, ∞]\n# Step 3: After second relaxation\n#         d = [0, 4, 3, 4]\n# Step 4: After third relaxation\n#         d = [0, 4, 3, 4]\n# Step 5: No negative cycle found\n#\n# Output: d = [0, 4, 3, 4]",
    "keySteps": [
      "Initialize distances and predecessors",
      "Relax edges |V| - 1 times",
      "Check for negative cycles",
      "Return distances and predecessors"
    ]
  },
  "backtracking": {
    "name": "Backtracking",
    "type": "backtracking",
    "description": "Backtracking is an algorithm with time complexity O(n!). It is primarily used for exhaustive search with pruning",
    "timeComplexity": "O(n!) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Exhaustive search with pruning\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Exhaustive search with pruning\n    ",
    "useCase": "Exhaustive search with pruning\n    ",
    "pseudocode": "// N-Queens\nN-QUEENS(n):\n  board = [0] * n\n  return SOLVE-N-QUEENS(board, 0)\n\nSOLVE-N-QUEENS(board, row):\n  if row == n:\n    return true\n  for col from 0 to n-1:\n    if IS-SAFE(board, row, col):\n      board[row] = col\n      if SOLVE-N-QUEENS(board, row+1):\n        return true\n      board[row] = 0\n  return false\n\n// Sudoku\nSUDOKU(board):\n  return SOLVE-SUDOKU(board)\n\nSOLVE-SUDOKU(board):\n  find empty cell (i, j)\n  if no empty cell:\n    return true\n  for num from 1 to 9:\n    if IS-VALID(board, i, j, num):\n      board[i][j] = num\n      if SOLVE-SUDOKU(board):\n        return true\n      board[i][j] = 0\n  return false\n\n// Subset Sum\nSUBSET-SUM(S, target):\n  return SOLVE-SUBSET-SUM(S, 0, target)\n\nSOLVE-SUBSET-SUM(S, i, target):\n  if target == 0:\n    return true\n  if i == length(S) or target < 0:\n    return false\n  if SOLVE-SUBSET-SUM(S, i+1, target-S[i]):\n    return true\n  return SOLVE-SUBSET-SUM(S, i+1, target)",
    "keySteps": []
  },
  "b-tree": {
    "name": "B Tree",
    "type": "tree",
    "description": "B-Tree is an algorithm with time complexity O(log n). It is primarily used for disk-based balanced search tree",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Disk-based balanced search tree\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Disk-based balanced search tree\n    ",
    "useCase": "Disk-based balanced search tree\n    ",
    "pseudocode": "B-TREE-INSERT(T, k)\n    let r ← T.root\n    if r.n = 2t - 1\n        then s ← ALLOCATE-NODE()\n             T.root ← s\n             s.leaf ← false\n             s.n ← 0\n             s.c₁ ← r\n             B-TREE-SPLIT-CHILD(s, 1)\n             B-TREE-INSERT-NONFULL(s, k)\n        else B-TREE-INSERT-NONFULL(r, k)\n\nB-TREE-INSERT-NONFULL(x, k)\n    let i ← x.n\n    if x.leaf\n        then while i ≥ 1 and k < x.keyᵢ\n                do x.keyᵢ₊₁ ← x.keyᵢ\n                   i ← i - 1\n             x.keyᵢ₊₁ ← k\n             x.n ← x.n + 1\n        else while i ≥ 1 and k < x.keyᵢ\n                do i ← i - 1\n             i ← i + 1\n             if x.cᵢ.n = 2t - 1\n                then B-TREE-SPLIT-CHILD(x, i)\n                     if k > x.keyᵢ\n                        then i ← i + 1\n             B-TREE-INSERT-NONFULL(x.cᵢ, k)\n\nB-TREE-SPLIT-CHILD(x, i)\n    let z ← ALLOCATE-NODE()\n    let y ← x.cᵢ\n    z.leaf ← y.leaf\n    z.n ← t - 1\n    for j ← 1 to t - 1\n        do z.keyⱼ ← y.keyⱼ₊ₜ\n    if not y.leaf\n        then for j ← 1 to t\n                do z.cⱼ ← y.cⱼ₊ₜ\n    y.n ← t - 1\n    for j ← x.n + 1 downto i + 1\n        do x.cⱼ₊₁ ← x.cⱼ\n    x.cᵢ₊₁ ← z\n    for j ← x.n downto i\n        do x.keyⱼ₊₁ ← x.keyⱼ\n    x.keyᵢ ← y.keyₜ\n    x.n ← x.n + 1\n\n// Example:\n// Input: Insert keys [10, 20, 30, 40, 50, 60, 70, 80, 90] with t = 2\n//\n// Insert 10, 20:\n//   [10, 20]\n//\n// Insert 30:\n//   [20]\n//  /    \\\n// [10]  [30]\n//\n// Insert 40, 50:\n//   [20, 40]\n//  /   |   \\\n// [10] [30] [50]\n//\n// Insert 60:\n//      [40]\n//    /     \\\n// [20]     [60]\n// /  \\     /  \\\n// [10][30][50][70]\n//\n// Insert 70, 80, 90:\n//      [40, 70]\n//    /    |    \\\n// [20]  [60]  [80,90]\n// /  \\  /  \\\n// [10][30][50]",
    "keySteps": [
      "Insert: Find appropriate leaf node for insertion",
      "Split: Handle node overflow by splitting nodes",
      "Maintain: Keep tree balanced through proper splitting"
    ]
  },
  "avl-tree": {
    "name": "AVL Tree",
    "type": "tree",
    "description": "AVL Tree is an algorithm with time complexity O(log n). It is primarily used for self-balancing binary search tree",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Self-balancing binary search tree\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Self-balancing binary search tree\n    ",
    "useCase": "Self-balancing binary search tree\n    ",
    "pseudocode": "AVL-INSERT(T, z)\n    let y ← null\n    let x ← T.root\n\n    while x ≠ null\n        do y ← x\n           if z.key < x.key\n               then x ← x.left\n               else x ← x.right\n\n    z.p ← y\n    if y = null\n        then T.root ← z\n        else if z.key < y.key\n            then y.left ← z\n            else y.right ← z\n\n    z.left ← null\n    z.right ← null\n    z.height ← 1\n\n    AVL-BALANCE(T, z)\n\nAVL-BALANCE(T, z)\n    while z ≠ null\n        do z.height ← 1 + max(HEIGHT(z.left), HEIGHT(z.right))\n           if HEIGHT(z.left) - HEIGHT(z.right) > 1\n               then if HEIGHT(z.left.left) ≥ HEIGHT(z.left.right)\n                       then RIGHT-ROTATE(T, z)\n                       else LEFT-ROTATE(T, z.left)\n                           RIGHT-ROTATE(T, z)\n           else if HEIGHT(z.right) - HEIGHT(z.left) > 1\n               then if HEIGHT(z.right.right) ≥ HEIGHT(z.right.left)\n                       then LEFT-ROTATE(T, z)\n                       else RIGHT-ROTATE(T, z.right)\n                           LEFT-ROTATE(T, z)\n           z ← z.p\n\nRIGHT-ROTATE(T, y)\n    let x ← y.left\n    y.left ← x.right\n    if x.right ≠ null\n        then x.right.p ← y\n    x.p ← y.p\n    if y.p = null\n        then T.root ← x\n        else if y = y.p.right\n            then y.p.right ← x\n            else y.p.left ← x\n    x.right ← y\n    y.p ← x\n    y.height ← 1 + max(HEIGHT(y.left), HEIGHT(y.right))\n    x.height ← 1 + max(HEIGHT(x.left), HEIGHT(x.right))\n\nLEFT-ROTATE(T, x)\n    let y ← x.right\n    x.right ← y.left\n    if y.left ≠ null\n        then y.left.p ← x\n    y.p ← x.p\n    if x.p = null\n        then T.root ← y\n        else if x = x.p.left\n            then x.p.left ← y\n            else x.p.right ← y\n    y.left ← x\n    x.p ← y\n    x.height ← 1 + max(HEIGHT(x.left), HEIGHT(x.right))\n    y.height ← 1 + max(HEIGHT(y.left), HEIGHT(y.right))\n\n// Example:\n// Input: Insert keys [10, 20, 30, 40, 50, 25]\n//\n// Insert 10:\n//   Tree: 10\n//\n// Insert 20:\n//   Tree: 10\n//         \\\n//         20\n//\n// Insert 30:\n//   Tree: 20\n//        /  \\\n//      10    30\n//\n// Insert 40:\n//   Tree: 20\n//        /  \\\n//      10    30\n//             \\\n//             40\n//\n// Insert 50:\n//   Tree: 20\n//        /  \\\n//      10    40\n//           /  \\\n//         30    50\n//\n// Insert 25:\n//   Tree: 30\n//        /  \\\n//      20    40\n//     /  \\    \\\n//   10   25   50",
    "keySteps": [
      "Insert: Standard BST insertion with height tracking",
      "Balance: Check and fix height imbalances using rotations",
      "Rotate: Perform left/right rotations to maintain balance"
    ]
  },
  "articulation-points": {
    "name": "Articulation Points",
    "type": "graph",
    "description": "Articulation Points is an algorithm with time complexity O(V + E). It is primarily used for find vertices whose removal       increases connected components",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find vertices whose removal\n      increases connected components\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find vertices whose removal\n      increases connected components\n    ",
    "useCase": "Find vertices whose removal\n      increases connected components\n    ",
    "pseudocode": "# Articulation Points: Find vertices whose removal increases connected components\n# Input: Undirected graph G = (V, E)\n# Output: Set of articulation points\n\nAlgorithm ARTICULATION-POINTS(G)\n    time ← 0\n    for each vertex v in V do\n        visited[v] ← false\n        disc[v] ← ∞\n        low[v] ← ∞\n        parent[v] ← NIL\n    end for\n\n    for each vertex v in V do\n        if not visited[v] then\n            DFS-AP(v)\n        end if\n    end for\n\n    return articulation_points\n\nAlgorithm DFS-AP(u)\n    visited[u] ← true\n    disc[u] ← low[u] ← time + 1\n    time ← time + 1\n    children ← 0\n\n    for each vertex v in Adj[u] do\n        if not visited[v] then\n            children ← children + 1\n            parent[v] ← u\n            DFS-AP(v)\n\n            # Check if subtree rooted with v has connection to ancestors of u\n            low[u] ← min(low[u], low[v])\n\n            # u is articulation point if:\n            # 1. u is root and has two or more children\n            # 2. u is not root and low[v] ≥ disc[u]\n            if parent[u] = NIL and children > 1 then\n                articulation_points ← articulation_points ∪ {u}\n            else if parent[u] ≠ NIL and low[v] ≥ disc[u] then\n                articulation_points ← articulation_points ∪ {u}\n            end if\n        else if v ≠ parent[u] then\n            low[u] ← min(low[u], disc[v])\n        end if\n    end for\n\n# Example:\n# Input: G with V = {0,1,2,3,4} and edges:\n# (0,1), (1,2), (2,0), (1,3), (1,4), (3,4)\n#\n# Step 1: Start DFS from 0\n# Step 2: Visit 0, 1, 2\n# Step 3: Backtrack to 1, visit 3, 4\n# Step 4: Check articulation points\n#         - 1 is root with 2 children\n#         - No other vertices satisfy conditions\n#\n# Output: {1}",
    "keySteps": [
      "Initialize visited, discovery, and low values",
      "Perform DFS from each unvisited vertex",
      "Update low values and check articulation conditions",
      "Return set of articulation points"
    ]
  },
  "activity-selection": {
    "name": "Activity Selection",
    "type": "greedy",
    "description": "Activity Selection is an algorithm with time complexity O(n log n). It is primarily used for selecting maximum number of       non-overlapping activities",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Selecting maximum number of\n      non-overlapping activities\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Selecting maximum number of\n      non-overlapping activities\n    ",
    "useCase": "Selecting maximum number of\n      non-overlapping activities\n    ",
    "pseudocode": "// Standard Activity Selection\ndef activity_selection(activities):\n    # Sort activities by finish time\n    activities.sort(key=lambda x: x[1])\n\n    selected = []\n    last_finish = 0\n\n    for activity in activities:\n        start, finish = activity\n        if start >= last_finish:\n            selected.append(activity)\n            last_finish = finish\n\n    return selected\n\n// Activity Selection with Weights\ndef activity_selection_weights(activities):\n    # Sort activities by finish time\n    activities.sort(key=lambda x: x[1])\n\n    n = len(activities)\n    dp = [0] * n\n    dp[0] = activities[0][2]  # weight\n\n    for i in range(1, n):\n        # Find last non-conflicting activity\n        last_non_conflict = -1\n        for j in range(i-1, -1, -1):\n            if activities[j][1] <= activities[i][0]:\n                last_non_conflict = j\n                break\n\n        # Include current activity\n        include = activities[i][2]\n        if last_non_conflict != -1:\n            include += dp[last_non_conflict]\n\n        # Store maximum of including or excluding\n        dp[i] = max(include, dp[i-1])\n\n    return dp[n-1]\n\n// Activity Selection with Resource Constraints\ndef activity_selection_resources(activities, resources):\n    # Sort activities by finish time\n    activities.sort(key=lambda x: x[1])\n\n    selected = []\n    resource_available = [0] * resources\n\n    for activity in activities:\n        start, finish, resource = activity\n        if start >= resource_available[resource]:\n            selected.append(activity)\n            resource_available[resource] = finish\n\n    return selected\n\n# Examples:\n\n# Standard Activity Selection\n# Input:\n# activities = [\n#     (1, 4),  # (start, finish)\n#     (3, 5),\n#     (0, 6),\n#     (5, 7),\n#     (3, 8),\n#     (5, 9),\n#     (6, 10),\n#     (8, 11),\n#     (8, 12),\n#     (2, 13),\n#     (12, 14)\n# ]\n# Output:\n# selected = [(1, 4), (5, 7), (8, 11), (12, 14)]\n# Total activities: 4\n\n# Activity Selection with Weights\n# Input:\n# activities = [\n#     (1, 4, 2),  # (start, finish, weight)\n#     (3, 5, 4),\n#     (0, 6, 4),\n#     (5, 7, 7),\n#     (3, 8, 2),\n#     (5, 9, 1)\n# ]\n# Output:\n# max_weight = 8  # (1,4,2) + (5,7,7)\n\n# Activity Selection with Resource Constraints\n# Input:\n# activities = [\n#     (1, 4, 0),  # (start, finish, resource)\n#     (3, 5, 1),\n#     (0, 6, 0),\n#     (5, 7, 1),\n#     (3, 8, 0),\n#     (5, 9, 1)\n# ]\n# Output:\n# selected = [(1, 4, 0), (3, 5, 1), (5, 7, 1)]\n# Total activities: 3",
    "keySteps": [
      "Sort: Activities by finish time",
      "Select: First activity and subsequent non-overlapping activities",
      "Update: Track last finish time or resource availability"
    ]
  },
  "a-star-search": {
    "name": "A* Search",
    "type": "searching",
    "description": "A* Search is an algorithm with time complexity O(b^d). It is primarily used for optimal path finding with       heuristics",
    "timeComplexity": "O(b^d) &nbsp;|&nbsp; Space: O(b^d) &nbsp;|&nbsp; Use: Optimal path finding with\n      heuristics\n    ",
    "spaceComplexity": "O(b^d) &nbsp;|&nbsp; Use: Optimal path finding with\n      heuristics\n    ",
    "useCase": "Optimal path finding with\n      heuristics\n    ",
    "pseudocode": "A-STAR-SEARCH(G, start, goal)\n    let openSet be a new priority queue\n    let gScore[1‥n] be a new array\n    let fScore[1‥n] be a new array\n    let cameFrom[1‥n] be a new array\n\n    for each vertex v in G.V\n        do gScore[v] ← ∞\n           fScore[v] ← ∞\n           cameFrom[v] ← null\n\n    gScore[start] ← 0\n    fScore[start] ← h(start, goal)\n    openSet.insert(start, fScore[start])\n\n    while openSet is not empty\n        do current ← openSet.extract_min()\n           if current = goal\n               then return RECONSTRUCT-PATH(cameFrom, current)\n\n           for each neighbor in G.adj[current]\n               do tentative_gScore ← gScore[current] + d(current, neighbor)\n                  if tentative_gScore < gScore[neighbor]\n                      then cameFrom[neighbor] ← current\n                           gScore[neighbor] ← tentative_gScore\n                           fScore[neighbor] ← gScore[neighbor] + h(neighbor, goal)\n                           if neighbor not in openSet\n                               then openSet.insert(neighbor, fScore[neighbor])\n\n    return null\n\nRECONSTRUCT-PATH(cameFrom, current)\n    let path be a new array\n    while current ≠ null\n        do path.append(current)\n           current ← cameFrom[current]\n    return reverse(path)\n\n// Example:\n// Input: G = {\n//   V = {A, B, C, D, E},\n//   E = {(A,B,4), (A,C,2), (B,D,5), (C,D,1), (C,E,3), (D,E,1)}\n// }\n// start = A, goal = E\n//\n// Initial state:\n//   openSet = {(A,6)}\n//   gScore = {A:0, B:∞, C:∞, D:∞, E:∞}\n//   fScore = {A:6, B:∞, C:∞, D:∞, E:∞}\n//\n// First iteration:\n//   current = A\n//   openSet = {(B,9), (C,5)}\n//   gScore = {A:0, B:4, C:2, D:∞, E:∞}\n//   fScore = {A:6, B:9, C:5, D:∞, E:∞}\n//\n// Second iteration:\n//   current = C\n//   openSet = {(B,9), (D,4), (E,5)}\n//   gScore = {A:0, B:4, C:2, D:3, E:5}\n//   fScore = {A:6, B:9, C:5, D:4, E:5}\n//\n// Final path: A → C → D → E",
    "keySteps": [
      "Initialize: Set up priority queue and score arrays",
      "Process: Expand nodes with lowest f-score",
      "Update: Maintain g-scores and reconstruct path"
    ]
  }
}
