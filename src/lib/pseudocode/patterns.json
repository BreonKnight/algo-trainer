{
  "zigzag-traversal": {
    "name": "Zigzag Traversal",
    "type": "tree",
    "description": "Zigzag Traversal is an algorithm with time complexity O(n). It is primarily used for level-order traversal with alternating       directions",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Level-order traversal with alternating\n      directions\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Level-order traversal with alternating\n      directions\n    ",
    "useCase": "Level-order traversal with alternating\n      directions\n    ",
    "pseudocode": "// Zigzag level order traversal\nZIGZAG-TRAVERSAL(root):\n  if root == null:\n    return []\n  \n  result = []\n  queue = [root]\n  level = 0\n  \n  while queue is not empty:\n    level_size = len(queue)\n    current_level = []\n    \n    for i = 0 to level_size-1:\n      node = queue.dequeue()\n      if level % 2 == 0:\n        current_level.append(node.val)\n      else:\n        current_level.insert(0, node.val)\n      \n      if node.left:\n        queue.enqueue(node.left)\n      if node.right:\n        queue.enqueue(node.right)\n    \n    result.append(current_level)\n    level += 1\n  \n  return result\n\n// Example usage\ntree = [3,9,20,null,null,15,7]\nresult = ZIGZAG-TRAVERSAL(tree)\n// Returns: [[3],[20,9],[15,7]]",
    "keySteps": [
      "Modified level-order traversal",
      "Uses queue for efficient level processing",
      "Can be implemented with two stacks"
    ]
  },
  "z-algorithm": {
    "name": "Z-Algorithm",
    "type": "string",
    "description": "Z-Algorithm is an algorithm with time complexity O(n). It is primarily used for pattern matching in string",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Pattern matching in string\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Pattern matching in string\n    ",
    "useCase": "Pattern matching in string\n    ",
    "pseudocode": "# Z Algorithm: Pattern matching in string\n# Input: String S[1..n]\n# Output: Array Z[1..n] where Z[i] is length of longest substring starting at i that is also a prefix\n\nAlgorithm Z-ALGORITHM(S)\n    n \u2190 length[S]\n    Z[1..n] \u2190 [0, 0, ..., 0]\n    Z[1] \u2190 n\n    L \u2190 1\n    R \u2190 1\n\n    for i \u2190 2 to n do\n        if i > R then\n            # Case 1: i outside current Z-box\n            L \u2190 i\n            R \u2190 i\n            while R \u2264 n and S[R-L+1] = S[R] do\n                R \u2190 R + 1\n            Z[i] \u2190 R - L\n            R \u2190 R - 1\n        else\n            # Case 2: i inside current Z-box\n            k \u2190 i - L + 1\n            if Z[k] < R - i + 1 then\n                # Case 2a: Z[k] < remaining\n                Z[i] \u2190 Z[k]\n            else\n                # Case 2b: Z[k] \u2265 remaining\n                L \u2190 i\n                while R \u2264 n and S[R-L+1] = S[R] do\n                    R \u2190 R + 1\n                Z[i] \u2190 R - L\n                R \u2190 R - 1\n    return Z\n\n# Example:\n# Input: S = \"aabxaabxcaabxaabxay\"\n#\n# Step 1: Initialize Z[1] = 19 (length of S)\n# Step 2: i=2, outside Z-box, find Z[2] = 1\n# Step 3: i=3, outside Z-box, find Z[3] = 0\n# Step 4: i=4, outside Z-box, find Z[4] = 0\n# Step 5: i=5, outside Z-box, find Z[5] = 4\n# ... continue until i=19\n#\n# Output: Z = [19, 1, 0, 0, 4, 1, 0, 0, 0, 8, 1, 0, 0, 5, 1, 0, 0, 1, 0]",
    "keySteps": [
      "Initialize Z array and first element",
      "Maintain Z-box boundaries (L, R)",
      "Handle two cases: outside and inside Z-box",
      "Compute Z[i] based on position and previous values"
    ]
  },
  "union-find": {
    "name": "Union Find",
    "type": "Algorithm",
    "description": "Union Find is an algorithm with time complexity O(\u03b1(n). It is primarily used for managing disjoint sets",
    "timeComplexity": "O(\u03b1(n)) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Managing disjoint sets\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Managing disjoint sets\n    ",
    "useCase": "Managing disjoint sets\n    ",
    "pseudocode": "// Create new set\nMAKE-SET(x):\n    x.parent = x\n    x.rank = 0\n\n// Find set representative\nFIND-SET(x):\n    if x \u2260 x.parent:\n        x.parent = FIND-SET(x.parent)  // Path compression\n    return x.parent\n\n// Union two sets\nUNION(x, y):\n    x_root = FIND-SET(x)\n    y_root = FIND-SET(y)\n    if x_root = y_root:\n        return\n    if x_root.rank < y_root.rank:\n        x_root.parent = y_root\n    else if x_root.rank > y_root.rank:\n        y_root.parent = x_root\n    else:\n        y_root.parent = x_root\n        x_root.rank = x_root.rank + 1\n\n// Check if elements are in same set\nCONNECTED(x, y):\n    return FIND-SET(x) = FIND-SET(y)",
    "keySteps": []
  },
  "two-sum": {
    "name": "Two Sum",
    "type": "n\u00b2",
    "description": "Two Sum is an algorithm with time complexity O(n\u00b2). It is primarily used for find indices of two numbers that sum       to target",
    "timeComplexity": "O(n\u00b2) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find indices of two numbers that sum\n      to target\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find indices of two numbers that sum\n      to target\n    ",
    "useCase": "Find indices of two numbers that sum\n      to target\n    ",
    "pseudocode": "TWO-SUM(A, target)\n    let n be the length of A\n    for i \u2190 1 to n - 1\n        do for j \u2190 i + 1 to n\n            do if A[i] + A[j] = target\n                then return [i, j]\n    return NIL\n\n// Example:\n// Input: A = [2, 7, 11, 15], target = 9\n//\n// i = 1, j = 2: A[1] + A[2] = 2 + 7 = 9\n//\n// Output: [1, 2]",
    "keySteps": [
      "Initialize: Set up nested loops for array traversal",
      "Compare: Check if current pair sums to target",
      "Return: Indices of elements that sum to target"
    ]
  },
  "two-sum-two-pointers": {
    "name": "Two Sum (Two Pointers)",
    "type": "n log n",
    "description": "Two Sum (Two Pointers) is an algorithm with time complexity O(n log n). It is primarily used for find pairs that sum to target",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find pairs that sum to target\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find pairs that sum to target\n    ",
    "useCase": "Find pairs that sum to target\n    ",
    "pseudocode": "# Two Sum (Two Pointers): Find pairs that sum to target\n# Input: Array A[1..n], target value t\n# Output: Indices (i, j) where A[i] + A[j] = t, or (-1, -1) if not found\n\nAlgorithm TWO-SUM-TWO-POINTERS(A, t)\n    # Sort array for two pointers approach\n    A \u2190 SORT(A)\n    left \u2190 1\n    right \u2190 length[A]\n\n    while left < right do\n        sum \u2190 A[left] + A[right]\n        if sum = t then\n            return (left, right)\n        else if sum < t then\n            left \u2190 left + 1\n        else\n            right \u2190 right - 1\n        end if\n    end while\n\n    return (-1, -1)\n\n# Example:\n# Input: A = [2, 7, 11, 15], t = 9\n#\n# Step 1: A = [2, 7, 11, 15], left = 1, right = 4\n# Step 2: sum = 2 + 15 = 17 > 9, right = 3\n# Step 3: sum = 2 + 11 = 13 > 9, right = 2\n# Step 4: sum = 2 + 7 = 9 = t, return (1, 2)\n#\n# Output: (1, 2)",
    "keySteps": [
      "Sort the input array",
      "Initialize left and right pointers",
      "Move pointers based on sum comparison with target",
      "Return indices when sum equals target"
    ]
  },
  "two-sum-dict": {
    "name": "Two Sum (Dictionary)",
    "type": "Algorithm",
    "description": "Two Sum (Dictionary) is an algorithm with time complexity O(n). It is primarily used for find pairs that sum to target",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Find pairs that sum to target\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Find pairs that sum to target\n    ",
    "useCase": "Find pairs that sum to target\n    ",
    "pseudocode": "# Two Sum (Dictionary): Find pairs that sum to target\n# Input: Array A[1..n], target value t\n# Output: Indices (i, j) where A[i] + A[j] = t, or (-1, -1) if not found\n\nAlgorithm TWO-SUM-DICTIONARY(A, t)\n    # Initialize dictionary to store value-index pairs\n    D \u2190 empty dictionary\n\n    for i \u2190 1 to length[A] do\n        complement \u2190 t - A[i]\n        if complement \u2208 D then\n            return (D[complement], i)\n        end if\n        D[A[i]] \u2190 i\n    end for\n\n    return (-1, -1)\n\n# Example:\n# Input: A = [2, 7, 11, 15], t = 9\n#\n# Step 1: i = 1, A[1] = 2, complement = 7, D = {2: 1}\n# Step 2: i = 2, A[2] = 7, complement = 2 \u2208 D, return (1, 2)\n#\n# Output: (1, 2)",
    "keySteps": [
      "Initialize empty dictionary",
      "For each element, calculate complement",
      "Check if complement exists in dictionary",
      "Store current element and index in dictionary"
    ]
  },
  "two-pointers": {
    "name": "Two Pointers",
    "type": "array",
    "description": "Two Pointers is an algorithm with time complexity O(n). It is primarily used for finding pairs or subarrays that       satisfy certain conditions",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Finding pairs or subarrays that\n      satisfy certain conditions\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Finding pairs or subarrays that\n      satisfy certain conditions\n    ",
    "useCase": "Finding pairs or subarrays that\n      satisfy certain conditions\n    ",
    "pseudocode": "// Two sum\nTWO-SUM(A, target):\n  left = 0\n  right = A.length - 1\n  while left < right:\n    sum = A[left] + A[right]\n    if sum == target:\n      return [left, right]\n    else if sum < target:\n      left += 1\n    else:\n      right -= 1\n  return NIL\n\n// Remove duplicates\nREMOVE-DUPLICATES(A):\n  if A.length == 0:\n    return 0\n  slow = 0\n  for fast = 1 to A.length-1:\n    if A[fast] != A[slow]:\n      slow += 1\n      A[slow] = A[fast]\n  return slow + 1\n\n// Container with most water\nMAX-AREA(height):\n  left = 0\n  right = height.length - 1\n  max_area = 0\n  while left < right:\n    area = min(height[left], height[right]) * (right - left)\n    max_area = max(max_area, area)\n    if height[left] < height[right]:\n      left += 1\n    else:\n      right -= 1\n  return max_area\n\n// Three sum\nTHREE-SUM(A, target):\n  sort(A)\n  result = []\n  for i = 0 to A.length-2:\n    if i > 0 and A[i] == A[i-1]:\n      continue\n    left = i + 1\n    right = A.length - 1\n    while left < right:\n      sum = A[i] + A[left] + A[right]\n      if sum == target:\n        result.append([A[i], A[left], A[right]])\n        while left < right and A[left] == A[left+1]:\n          left += 1\n        while left < right and A[right] == A[right-1]:\n          right -= 1\n        left += 1\n        right -= 1\n      else if sum < target:\n        left += 1\n      else:\n        right -= 1\n  return result",
    "keySteps": []
  },
  "two-pointer": {
    "name": "Two Pointer",
    "type": "string",
    "description": "Two Pointer is an algorithm with time complexity O(n). It is primarily used for array/string manipulation with two       indices",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Array/string manipulation with two\n      indices\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Array/string manipulation with two\n      indices\n    ",
    "useCase": "Array/string manipulation with two\n      indices\n    ",
    "pseudocode": "// Two pointer technique\nTWO-POINTER-SUM(A, target):\n  left = 0\n  right = len(A) - 1\n  \n  while left < right:\n    sum = A[left] + A[right]\n    if sum == target:\n      return [left, right]\n    elif sum < target:\n      left += 1\n    else:\n      right -= 1\n  return [-1, -1]\n\n// Example usage\nA = [1, 2, 3, 4, 5, 6]\ntarget = 9\nresult = TWO-POINTER-SUM(A, target)\n// Returns: [3, 4] (indices of 4 and 5)",
    "keySteps": [
      "Finding pairs that sum to a target value",
      "Reversing arrays or strings",
      "Finding palindromes",
      "Merging sorted arrays"
    ]
  },
  "trie": {
    "name": "Trie",
    "type": "L",
    "description": "Trie is an algorithm with time complexity O(L). It is primarily used for efficient string storage and search",
    "timeComplexity": "O(L) &nbsp;|&nbsp; Space: O(AL) &nbsp;|&nbsp; Use: Efficient string storage and search\n    ",
    "spaceComplexity": "O(AL) &nbsp;|&nbsp; Use: Efficient string storage and search\n    ",
    "useCase": "Efficient string storage and search\n    ",
    "pseudocode": "// Trie node structure\nTRIE-NODE:\n    children[1..26]  // Array of child nodes\n    is_end          // Marks end of word\n    count           // Number of words with this prefix\n\n// Initialize trie\nTRIE-INIT():\n    root \u2190 new TRIE-NODE\n    root.is_end \u2190 false\n    root.count \u2190 0\n    return root\n\n// Insert word into trie\nTRIE-INSERT(root, word):\n    current \u2190 root\n    for i \u2190 1 to length[word]:\n        index \u2190 word[i] - 'a'\n        if current.children[index] = NIL:\n            current.children[index] \u2190 new TRIE-NODE\n        current \u2190 current.children[index]\n        current.count \u2190 current.count + 1\n    current.is_end \u2190 true\n\n// Search word in trie\nTRIE-SEARCH(root, word):\n    current \u2190 root\n    for i \u2190 1 to length[word]:\n        index \u2190 word[i] - 'a'\n        if current.children[index] = NIL:\n            return false\n        current \u2190 current.children[index]\n    return current.is_end\n\n// Count words with prefix\nTRIE-COUNT-PREFIX(root, prefix):\n    current \u2190 root\n    for i \u2190 1 to length[prefix]:\n        index \u2190 prefix[i] - 'a'\n        if current.children[index] = NIL:\n            return 0\n        current \u2190 current.children[index]\n    return current.count\n\n// Example:\n// Input: words = [\"apple\", \"app\", \"banana\", \"ball\"]\n//\n// Trie Structure:\n//         (root)\n//        /      \\\\\n//       a        b\n//      /         \\\\\n//     p           a\n//    / \\\\         \\\\\n//   p   p         l\n//  /     \\\\        \\\\\n// l       l        l\n// |       |        |\n// e       e        e\n//\n// Operations:\n// 1. Search \"app\" \u2192 true\n// 2. Search \"ban\" \u2192 false\n// 3. Count prefix \"ap\" \u2192 2\n// 4. Count prefix \"ba\" \u2192 2",
    "keySteps": [
      "Initialize: Create root node",
      "Insert: Add words character by character",
      "Search: Traverse trie for word existence"
    ]
  },
  "trie-operations": {
    "name": "Trie Operations",
    "type": "m",
    "description": "Trie Operations is an algorithm with time complexity O(m). It is primarily used for string prefix       operations",
    "timeComplexity": "O(m) &nbsp;|&nbsp; Space: O(ALPHABET_SIZE * m * n) &nbsp;|&nbsp; Use: String prefix\n      operations\n    ",
    "spaceComplexity": "O(ALPHABET_SIZE * m * n) &nbsp;|&nbsp; Use: String prefix\n      operations\n    ",
    "useCase": "String prefix\n      operations\n    ",
    "pseudocode": "// Node structure\nNODE:\n    children[ALPHABET_SIZE]\n    isEndOfWord\n\n// Initialize trie\nTRIE-INIT():\n    root \u2190 new NODE\n    root.isEndOfWord \u2190 false\n    for i \u2190 1 to ALPHABET_SIZE:\n        root.children[i] \u2190 null\n    return root\n\n// Insert word\nTRIE-INSERT(root, word):\n    node \u2190 root\n    for i \u2190 1 to length[word]:\n        index \u2190 word[i] - 'a'\n        if node.children[index] = null:\n            node.children[index] \u2190 new NODE\n        node \u2190 node.children[index]\n    node.isEndOfWord \u2190 true\n\n// Search word\nTRIE-SEARCH(root, word):\n    node \u2190 root\n    for i \u2190 1 to length[word]:\n        index \u2190 word[i] - 'a'\n        if node.children[index] = null:\n            return false\n        node \u2190 node.children[index]\n    return node.isEndOfWord\n\n// Check prefix\nTRIE-STARTS-WITH(root, prefix):\n    node \u2190 root\n    for i \u2190 1 to length[prefix]:\n        index \u2190 prefix[i] - 'a'\n        if node.children[index] = null:\n            return false\n        node \u2190 node.children[index]\n    return true\n\n// Delete word\nTRIE-DELETE(root, word):\n    return TRIE-DELETE-HELPER(root, word, 0)\n\nTRIE-DELETE-HELPER(node, word, depth):\n    if node = null:\n        return false\n    if depth = length[word]:\n        if node.isEndOfWord:\n            node.isEndOfWord \u2190 false\n            return is-empty(node)\n        return false\n    index \u2190 word[depth] - 'a'\n    if TRIE-DELETE-HELPER(node.children[index], word, depth + 1):\n        node.children[index] \u2190 null\n        return is-empty(node) and not node.isEndOfWord\n    return false\n\n// Example:\n// Input: Operations [INSERT(\"apple\"), INSERT(\"app\"), SEARCH(\"apple\"), DELETE(\"app\")]\n//\n// After INSERT(\"apple\"):\n//    root\n//     |\n//     a\n//     |\n//     p\n//     |\n//     p\n//     |\n//     l\n//     |\n//     e (end)\n//\n// After INSERT(\"app\"):\n//    root\n//     |\n//     a\n//     |\n//     p\n//     |\n//     p (end)\n//     |\n//     l\n//     |\n//     e (end)\n//\n// SEARCH(\"apple\") \u2192 true\n// SEARCH(\"app\") \u2192 true\n//\n// After DELETE(\"app\"):\n//    root\n//     |\n//     a\n//     |\n//     p\n//     |\n//     p\n//     |\n//     l\n//     |\n//     e (end)",
    "keySteps": [
      "Insert: Add word character by character, marking end",
      "Search: Traverse trie following word characters",
      "Delete: Remove word and clean up unused nodes"
    ]
  },
  "tree-implementation": {
    "name": "Tree Implementation",
    "type": "tree",
    "description": "Tree Implementation is an algorithm with time complexity O(n). It is primarily used for tree representation and traversal",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Tree representation and traversal\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Tree representation and traversal\n    ",
    "useCase": "Tree representation and traversal\n    ",
    "pseudocode": "// Binary tree node structure\nTREE-NODE(key):\n    node \u2190 new object\n    node.key \u2190 key\n    node.left \u2190 NIL\n    node.right \u2190 NIL\n    node.parent \u2190 NIL\n    return node\n\n// Tree traversal algorithms\nINORDER-TREE-WALK(x):\n    if x \u2260 NIL:\n        INORDER-TREE-WALK(x.left)\n        print x.key\n        INORDER-TREE-WALK(x.right)\n\nPREORDER-TREE-WALK(x):\n    if x \u2260 NIL:\n        print x.key\n        PREORDER-TREE-WALK(x.left)\n        PREORDER-TREE-WALK(x.right)\n\nPOSTORDER-TREE-WALK(x):\n    if x \u2260 NIL:\n        POSTORDER-TREE-WALK(x.left)\n        POSTORDER-TREE-WALK(x.right)\n        print x.key\n\n// Tree search operations\nTREE-SEARCH(x, k):\n    if x = NIL or k = x.key:\n        return x\n    if k < x.key:\n        return TREE-SEARCH(x.left, k)\n    else:\n        return TREE-SEARCH(x.right, k)\n\nITERATIVE-TREE-SEARCH(x, k):\n    while x \u2260 NIL and k \u2260 x.key:\n        if k < x.key:\n            x \u2190 x.left\n        else:\n            x \u2190 x.right\n    return x\n\nTREE-MINIMUM(x):\n    while x.left \u2260 NIL:\n        x \u2190 x.left\n    return x\n\nTREE-MAXIMUM(x):\n    while x.right \u2260 NIL:\n        x \u2190 x.right\n    return x\n\nTREE-SUCCESSOR(x):\n    if x.right \u2260 NIL:\n        return TREE-MINIMUM(x.right)\n    y \u2190 x.parent\n    while y \u2260 NIL and x = y.right:\n        x \u2190 y\n        y \u2190 y.parent\n    return y\n\n// Example:\n// Input: Binary tree with keys [4, 2, 6, 1, 3, 5, 7]\n//\n// Tree structure:\n//       4\n//     /   \\\\\n//    2     6\n//   / \\\\   / \\\\\n//  1   3 5   7\n//\n// Inorder traversal: 1 2 3 4 5 6 7\n// Preorder traversal: 4 2 1 3 6 5 7\n// Postorder traversal: 1 3 2 5 7 6 4",
    "keySteps": [
      "Structure: Define node with key, left, right, and parent pointers",
      "Traversal: Implement inorder, preorder, and postorder walks",
      "Operations: Search, minimum, maximum, and successor functions"
    ]
  },
  "tree-dp": {
    "name": "Tree Dynamic Programming",
    "type": "tree",
    "description": "Tree Dynamic Programming is an algorithm with time complexity O(n). It is primarily used for solve tree problems with overlapping       subproblems",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Solve tree problems with overlapping\n      subproblems\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Solve tree problems with overlapping\n      subproblems\n    ",
    "useCase": "Solve tree problems with overlapping\n      subproblems\n    ",
    "pseudocode": "# Tree Dynamic Programming: Solve tree problems with overlapping subproblems\n# Input: Root node r of a tree\n# Output: Optimal solution value for the tree\n\nAlgorithm TREE-DP(r)\n    # Base case: empty tree\n    if r = NIL then\n        return 0\n    end if\n\n    # Initialize memoization table\n    memo \u2190 empty dictionary\n\n    # Helper function for post-order traversal\n    function DFS(u)\n        if u = NIL then\n            return 0\n        end if\n\n        # Check if already computed\n        if u \u2208 memo then\n            return memo[u]\n        end if\n\n        # Case 1: Include current node\n        include \u2190 u.value\n        for each child v of u do\n            for each grandchild w of v do\n                include \u2190 include + DFS(w)\n            end for\n        end for\n\n        # Case 2: Exclude current node\n        exclude \u2190 0\n        for each child v of u do\n            exclude \u2190 exclude + DFS(v)\n        end for\n\n        # Store and return optimal solution\n        memo[u] \u2190 max(include, exclude)\n        return memo[u]\n    end function\n\n    return DFS(r)\n\n# Example:\n# Input: Tree with nodes [3, 4, 5, 1, 3, 1]\n#\n# Step 1: DFS(3)\n#   include = 3 + DFS(1) + DFS(3) = 3 + 1 + 3 = 7\n#   exclude = DFS(4) + DFS(5) = 4 + 5 = 9\n#   memo[3] = max(7, 9) = 9\n#\n# Output: 9",
    "keySteps": []
  },
  "topological-sort": {
    "name": "Topological Sort",
    "type": "Algorithm",
    "description": "Topological Sort is an algorithm with time complexity O(V + E). It is primarily used for linear ordering of vertices in a       dag",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Linear ordering of vertices in a\n      DAG\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Linear ordering of vertices in a\n      DAG\n    ",
    "useCase": "Linear ordering of vertices in a\n      DAG\n    ",
    "pseudocode": "# Topological Sort: Linear ordering of vertices in a DAG\n# Input: Directed Acyclic Graph G = (V, E)\n# Output: Topological ordering of vertices\n\nAlgorithm TOPOLOGICAL-SORT(G)\n    # Initialize visited and result arrays\n    visited \u2190 empty array of size |V|\n    result \u2190 empty array\n    time \u2190 0\n\n    # Helper function for DFS\n    function DFS(u)\n        visited[u] \u2190 true\n        time \u2190 time + 1\n        u.discovery \u2190 time\n\n        for each vertex v in G.Adj[u] do\n            if not visited[v] then\n                DFS(v)\n            end if\n        end for\n\n        time \u2190 time + 1\n        u.finish \u2190 time\n        result.append(u)\n    end function\n\n    # Perform DFS on all vertices\n    for each vertex u in G.V do\n        if not visited[u] then\n            DFS(u)\n        end if\n    end for\n\n    # Reverse to get topological order\n    return reverse(result)\n\n# Example:\n# Input: G = (V, E) where V = {1, 2, 3, 4, 5}\n#        E = {(1,2), (1,3), (2,4), (3,4), (4,5)}\n#\n# Step 1: DFS(1)\n#   discovery[1] = 1, finish[1] = 10\n#   discovery[2] = 2, finish[2] = 7\n#   discovery[4] = 3, finish[4] = 6\n#   discovery[5] = 4, finish[5] = 5\n#   discovery[3] = 8, finish[3] = 9\n#\n# Output: [1, 3, 2, 4, 5]",
    "keySteps": [
      "Initialize visited and result arrays",
      "Perform DFS on all unvisited vertices",
      "Track discovery and finish times",
      "Reverse result to get topological order"
    ]
  },
  "test-data": {
    "name": "Test Data",
    "type": "bit manipulation",
    "description": "Test Data is an algorithm with time complexity O(n). It is primarily used for verify algorithm correctness",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Verify algorithm correctness\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Verify algorithm correctness\n    ",
    "useCase": "Verify algorithm correctness\n    ",
    "pseudocode": "// Test Data Structure\nTEST-CASE:\n    input: any\n    expected: any\n    description: string\n\n// Test Suite\nTEST-SUITE:\n    test_cases: array of TEST-CASE\n    edge_cases: array of TEST-CASE\n    boundary_cases: array of TEST-CASE\n\n// Example Test Suite\ntest_suite = {\n    test_cases: [\n        {\n            input: [1, 2, 3, 4, 5],\n            expected: 15,\n            description: \"Sum of array elements\"\n        },\n        {\n            input: [-1, -2, -3],\n            expected: -6,\n            description: \"Sum of negative numbers\"\n        }\n    ],\n    edge_cases: [\n        {\n            input: [],\n            expected: 0,\n            description: \"Empty array\"\n        },\n        {\n            input: [1],\n            expected: 1,\n            description: \"Single element\"\n        }\n    ],\n    boundary_cases: [\n        {\n            input: [Number.MAX_SAFE_INTEGER, 1],\n            expected: Number.MAX_SAFE_INTEGER + 1,\n            description: \"Integer overflow\"\n        }\n    ]\n}",
    "keySteps": [
      "Define: Input and expected output",
      "Include: Edge cases and boundary conditions",
      "Verify: Algorithm correctness"
    ]
  },
  "ternary-search-algorithm": {
    "name": "Ternary Search",
    "type": "log\u2083 n",
    "description": "Ternary Search is an algorithm with time complexity O(log\u2083 n). It is primarily used for find maximum/minimum in unimodal       function",
    "timeComplexity": "O(log\u2083 n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find maximum/minimum in unimodal\n      function\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find maximum/minimum in unimodal\n      function\n    ",
    "useCase": "Find maximum/minimum in unimodal\n      function\n    ",
    "pseudocode": "# Ternary Search: Find maximum/minimum in unimodal function\n# Input: Array A[1..n], target value t\n# Output: Index of target value, or -1 if not found\n\nAlgorithm TERNARY-SEARCH(A, t)\n    left \u2190 1\n    right \u2190 length[A]\n\n    while left \u2264 right do\n        # Divide range into three parts\n        mid1 \u2190 left + (right - left) / 3\n        mid2 \u2190 right - (right - left) / 3\n\n        if A[mid1] = t then\n            return mid1\n        else if A[mid2] = t then\n            return mid2\n        else if t < A[mid1] then\n            right \u2190 mid1 - 1\n        else if t > A[mid2] then\n            left \u2190 mid2 + 1\n        else\n            left \u2190 mid1 + 1\n            right \u2190 mid2 - 1\n        end if\n    end while\n\n    return -1\n\n# Example:\n# Input: A = [1, 2, 3, 4, 5, 6, 7, 8, 9], t = 5\n#\n# Step 1: left = 1, right = 9, mid1 = 4, mid2 = 6\n#         A[4] = 4 < 5, A[6] = 6 > 5\n# Step 2: left = 5, right = 5, mid1 = 5, mid2 = 5\n#         A[5] = 5 = t\n#\n# Output: 5",
    "keySteps": []
  },
  "suffix-tree": {
    "name": "Suffix Tree",
    "type": "Algorithm",
    "description": "Suffix Tree is an algorithm with time complexity O(n). It is primarily used for efficient string operations",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Efficient string operations\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Efficient string operations\n    ",
    "useCase": "Efficient string operations\n    ",
    "pseudocode": "// Suffix tree node structure\nSUFFIX-NODE:\n    start\n    end\n    children\n    suffix_link\n    parent\n\n// Build suffix tree using Ukkonen's algorithm\nBUILD-SUFFIX-TREE(S):\n    n \u2190 length[S]\n    root \u2190 new SUFFIX-NODE\n    active_node \u2190 root\n    active_edge \u2190 0\n    active_length \u2190 0\n    remaining \u2190 0\n\n    for i \u2190 1 to n:\n        remaining \u2190 remaining + 1\n        last_new_node \u2190 NIL\n\n        while remaining > 0:\n            if active_length = 0:\n                active_edge \u2190 i\n\n            if active_node.children[S[active_edge]] = NIL:\n                active_node.children[S[active_edge]] \u2190 new SUFFIX-NODE\n                if last_new_node \u2260 NIL:\n                    last_new_node.suffix_link \u2190 active_node\n                    last_new_node \u2190 NIL\n            else:\n                next_node \u2190 active_node.children[S[active_edge]]\n                if active_length \u2265 next_node.end - next_node.start + 1:\n                    active_length \u2190 active_length - (next_node.end - next_node.start + 1)\n                    active_edge \u2190 active_edge + (next_node.end - next_node.start + 1)\n                    active_node \u2190 next_node\n                    continue\n\n            if S[i] = S[next_node.start + active_length]:\n                active_length \u2190 active_length + 1\n                if last_new_node \u2260 NIL and active_node \u2260 root:\n                    last_new_node.suffix_link \u2190 active_node\n                    last_new_node \u2190 NIL\n                break\n\n            split_node \u2190 new SUFFIX-NODE\n            active_node.children[S[active_edge]] \u2190 split_node\n            split_node.children[S[next_node.start + active_length]] \u2190 next_node\n            next_node.start \u2190 next_node.start + active_length\n            split_node.children[S[i]] \u2190 new SUFFIX-NODE\n\n            if last_new_node \u2260 NIL:\n                last_new_node.suffix_link \u2190 split_node\n\n            last_new_node \u2190 split_node\n            remaining \u2190 remaining - 1\n\n            if active_node = root and active_length > 0:\n                active_length \u2190 active_length - 1\n                active_edge \u2190 i - remaining + 1\n            else if active_node \u2260 root:\n                active_node \u2190 active_node.suffix_link\n\n    return root\n\n// Example:\n// Input: S = \"banana\"\n//\n// Suffix Tree:\n//         (root)\n//        /   |   \\\\\n//       b    a    n\n//      /     |     \\\\\n//     a      n      a\n//    /       |       \\\\\n//   n        a        n\n//  /         |         \\\\\n// a          n          a\n// |          |          |\n// $          a          $\n//            |\n//            n\n//            |\n//            a\n//            |\n//            $",
    "keySteps": [
      "Initialize: Create root node and active point",
      "Process: Add characters one by one",
      "Update: Maintain suffix links and active point"
    ]
  },
  "suffix-array": {
    "name": "Suffix Array",
    "type": "Algorithm",
    "description": "Suffix Array is an algorithm with time complexity O(n log n). It is primarily used for efficient string operations",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Efficient string operations\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Efficient string operations\n    ",
    "useCase": "Efficient string operations\n    ",
    "pseudocode": "# Suffix Array: Efficient string operations\n# Input: String S[1..n]\n# Output: Suffix array SA[1..n] where SA[i] is starting index of i-th smallest suffix\n\nAlgorithm SUFFIX-ARRAY(S)\n    n \u2190 length[S]\n    # Initialize suffix array with indices\n    SA \u2190 array of size n\n    for i \u2190 1 to n do\n        SA[i] \u2190 i\n    end for\n\n    # Sort suffixes based on first character\n    sort SA using S[SA[i]] as key\n\n    # Sort suffixes based on increasing length\n    for k \u2190 1 to n do\n        # Create equivalence classes\n        rank \u2190 array of size n\n        rank[SA[1]] \u2190 0\n        for i \u2190 2 to n do\n            if S[SA[i]] = S[SA[i-1]] then\n                rank[SA[i]] \u2190 rank[SA[i-1]]\n            else\n                rank[SA[i]] \u2190 rank[SA[i-1]] + 1\n            end if\n        end for\n\n        # Sort suffixes based on first 2^k characters\n        temp \u2190 array of size n\n        for i \u2190 1 to n do\n            temp[i] \u2190 SA[i]\n        end for\n\n        for i \u2190 1 to n do\n            SA[i] \u2190 temp[i]\n            if SA[i] > k then\n                SA[i] \u2190 SA[i] - k\n            else\n                SA[i] \u2190 SA[i] + n - k\n            end if\n        end for\n\n        # Update equivalence classes\n        new_rank \u2190 array of size n\n        new_rank[SA[1]] \u2190 0\n        for i \u2190 2 to n do\n            if rank[SA[i]] = rank[SA[i-1]] and\n               rank[SA[i]+k] = rank[SA[i-1]+k] then\n                new_rank[SA[i]] \u2190 new_rank[SA[i-1]]\n            else\n                new_rank[SA[i]] \u2190 new_rank[SA[i-1]] + 1\n            end if\n        end for\n        rank \u2190 new_rank\n    end for\n\n    return SA\n\n# Example:\n# Input: S = \"banana\"\n#\n# Step 1: SA = [1, 2, 3, 4, 5, 6]\n# Step 2: Sort by first character\n#         SA = [2, 1, 3, 5, 4, 6]\n# Step 3: Sort by first 2 characters\n#         SA = [2, 1, 3, 5, 4, 6]\n# Step 4: Sort by first 4 characters\n#         SA = [6, 4, 2, 1, 3, 5]\n#\n# Output: [6, 4, 2, 1, 3, 5]",
    "keySteps": [
      "Initialize suffix array with indices",
      "Sort suffixes based on first character",
      "Create and update equivalence classes",
      "Sort suffixes based on increasing length"
    ]
  },
  "strongly-connected-components": {
    "name": "Monster Territory Clusters",
    "type": "Graph",
    "description": "Monster Territory Clusters is an algorithm with time complexity O(V + E). It is primarily used for find groups of territories where       monsters can freely move between any two areas",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find groups of territories where\n      monsters can freely move between any two areas\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find groups of territories where\n      monsters can freely move between any two areas\n    ",
    "useCase": "Find groups of territories where\n      monsters can freely move between any two areas\n    ",
    "pseudocode": "# Monster Territory Clusters: Find groups of interconnected monster territories\n# Input: G = (V, E) - directed graph of monster territories and migration paths\n# Output: List of territory clusters where monsters can freely move between any two areas\n\nAlgorithm FIND-TERRITORY-CLUSTERS(territory_graph)\n    # First DFS pass to get exploration times\n    for each territory t \u2208 territory_graph\n        t.explored \u2190 false\n        t.parent \u2190 NIL\n    time \u2190 0\n    exploration_stack \u2190 []\n    for each territory t \u2208 territory_graph\n        if not t.explored\n            EXPLORE-TERRITORY(territory_graph, t, exploration_stack)\n\n    # Compute reverse migration paths\n    reverse_graph \u2190 REVERSE-MIGRATION-PATHS(territory_graph)\n\n    # Second DFS pass in reverse order of exploration\n    for each territory t \u2208 territory_graph\n        t.explored \u2190 false\n        t.parent \u2190 NIL\n    territory_clusters \u2190 []\n    while exploration_stack is not empty\n        t \u2190 exploration_stack.pop()\n        if not t.explored\n            cluster \u2190 []\n            EXPLORE-TERRITORY(reverse_graph, t, cluster)\n            territory_clusters.append(cluster)\n\n    return territory_clusters\n\nAlgorithm EXPLORE-TERRITORY(graph, territory, result)\n    territory.explored \u2190 true\n    for each connected_territory \u2208 graph[territory]\n        if not connected_territory.explored\n            connected_territory.parent \u2190 territory\n            EXPLORE-TERRITORY(graph, connected_territory, result)\n    result.append(territory)\n\nAlgorithm REVERSE-MIGRATION-PATHS(graph)\n    reverse_graph \u2190 new Graph\n    for each territory t \u2208 graph\n        reverse_graph[t] \u2190 []\n    for each territory t \u2208 graph\n        for each connected_territory \u2208 graph[t]\n            reverse_graph[connected_territory].append(t)\n    return reverse_graph\n\n# Example:\n# Input: Territory Graph where\n# V = {Ancient Forest, Wildspire Waste, Coral Highlands, Elder's Recess, Rotten Vale}\n# E = {\n#   Ancient Forest \u2192 Wildspire Waste,\n#   Wildspire Waste \u2192 Coral Highlands,\n#   Coral Highlands \u2192 Ancient Forest,\n#   Coral Highlands \u2192 Elder's Recess,\n#   Elder's Recess \u2192 Rotten Vale,\n#   Rotten Vale \u2192 Wildspire Waste\n# }\n#\n# First DFS pass:\n# Ancient Forest: explored first\n# Wildspire Waste: explored second\n# Coral Highlands: explored third\n# Elder's Recess: explored fourth\n# Rotten Vale: explored last\n#\n# Second DFS pass on reverse graph:\n# Cluster 1: {Ancient Forest, Wildspire Waste, Coral Highlands}\n# Cluster 2: {Elder's Recess}\n# Cluster 3: {Rotten Vale}\n#\n# Output: [\n#   [\"Ancient Forest\", \"Wildspire Waste\", \"Coral Highlands\"],\n#   [\"Elder's Recess\"],\n#   [\"Rotten Vale\"]\n# ]",
    "keySteps": [
      "Explore territories to understand migration patterns",
      "Map reverse migration paths between territories",
      "Identify clusters where monsters can freely move between territories",
      "Use clusters to plan efficient hunting routes and predict monster movements"
    ]
  },
  "string-operations": {
    "name": "String Operations",
    "type": "Basic String Manipulation",
    "description": "String Operations is an algorithm with time complexity O(n). It is primarily used for string manipulation",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: String manipulation\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: String manipulation\n    ",
    "useCase": "String manipulation\n    ",
    "pseudocode": "// Common String Operations\nCONCATENATE(s1, s2):\n  return s1 + s2\n\nSUBSTRING(s, start, end):\n  return s[start..end]\n\nCHAR_AT(s, index):\n  return s[index]\n\nLENGTH(s):\n  return s.length\n\nCOMPARE(s1, s2):\n  return s1 == s2\n\nFIND(s, pattern):\n  return s.indexOf(pattern)\n\nREPLACE(s, old, new):\n  return s.replace(old, new)\n\nSPLIT(s, delimiter):\n  return s.split(delimiter)\n\nJOIN(arr, delimiter):\n  return arr.join(delimiter)\n\nTRIM(s):\n  return s.trim()\n\nTO_UPPER(s):\n  return s.toUpperCase()\n\nTO_LOWER(s):\n  return s.toLowerCase()",
    "keySteps": []
  },
  "string-hashing": {
    "name": "String Hashing",
    "type": "string",
    "description": "String Hashing is an algorithm with time complexity O(n). It is primarily used for fast string comparison and pattern       matching",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Fast string comparison and pattern\n      matching\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Fast string comparison and pattern\n      matching\n    ",
    "useCase": "Fast string comparison and pattern\n      matching\n    ",
    "pseudocode": "// Rolling hash function\nROLLING-HASH(s, base, mod):\n  hash = 0\n  power = 1\n  for i = 0 to len(s)-1:\n    hash = (hash + (s[i] - 'a' + 1) * power) % mod\n    power = (power * base) % mod\n  return hash\n\n// Substring hash\nSUBSTRING-HASH(s, start, length, base, mod):\n  hash = 0\n  power = 1\n  for i = start to start+length-1:\n    hash = (hash + (s[i] - 'a' + 1) * power) % mod\n    power = (power * base) % mod\n  return hash\n\n// Example usage\ns = \"hello\"\nbase = 31\nmod = 10^9 + 7\nhash = ROLLING-HASH(s, base, mod)\nsub_hash = SUBSTRING-HASH(s, 1, 3, base, mod)  // Hash of \"ell\"",
    "keySteps": [
      "O(1) comparison of strings",
      "Low collision probability with good parameters",
      "Useful for Rabin-Karp and other string algorithms"
    ]
  },
  "state-compression-dp": {
    "name": "State Compression DP",
    "type": "Dynamic Programming",
    "description": "State Compression DP is an algorithm with time complexity O(n * 2^m). It is primarily used for solve problems with state       represented as bits",
    "timeComplexity": "O(n * 2^m) &nbsp;|&nbsp; Space: O(2^m) &nbsp;|&nbsp; Use: Solve problems with state\n      represented as bits\n    ",
    "spaceComplexity": "O(2^m) &nbsp;|&nbsp; Use: Solve problems with state\n      represented as bits\n    ",
    "useCase": "Solve problems with state\n      represented as bits\n    ",
    "pseudocode": "# State Compression DP: Solve problems with state represented as bits\n# Input: Grid G[1..n][1..m]\n# Output: Maximum value achievable\n\nAlgorithm STATE-COMPRESSION-DP(G)\n    n \u2190 rows[G]\n    m \u2190 cols[G]\n    # Initialize DP table\n    dp \u2190 array of size 2^m\n    for i \u2190 0 to 2^m - 1 do\n        dp[i] \u2190 -\u221e\n    end for\n    dp[0] \u2190 0\n\n    # Process each row\n    for i \u2190 1 to n do\n        # Initialize current row's DP\n        curr \u2190 array of size 2^m\n        for j \u2190 0 to 2^m - 1 do\n            curr[j] \u2190 -\u221e\n        end for\n\n        # Try all possible states\n        for prev \u2190 0 to 2^m - 1 do\n            if dp[prev] = -\u221e then\n                continue\n            end if\n\n            # Try all possible current states\n            for curr_state \u2190 0 to 2^m - 1 do\n                # Check if current state is valid\n                valid \u2190 true\n                for j \u2190 0 to m - 1 do\n                    if (curr_state & (1 << j)) \u2260 0 then\n                        if G[i][j+1] = 0 then\n                            valid \u2190 false\n                            break\n                        end if\n                        if j > 0 and (curr_state & (1 << (j-1))) \u2260 0 then\n                            valid \u2190 false\n                            break\n                        end if\n                    end if\n                end for\n\n                if valid then\n                    # Calculate value for current state\n                    value \u2190 0\n                    for j \u2190 0 to m - 1 do\n                        if (curr_state & (1 << j)) \u2260 0 then\n                            value \u2190 value + G[i][j+1]\n                        end if\n                    end for\n\n                    # Update DP\n                    curr[curr_state] \u2190 max(curr[curr_state], dp[prev] + value)\n                end if\n            end for\n        end for\n\n        dp \u2190 curr\n    end for\n\n    return max(dp)\n\n# Example:\n# Input: G = [[1, 2, 3],\n#             [4, 5, 6],\n#             [7, 8, 9]]\n#\n# Step 1: dp = [0, -\u221e, -\u221e, -\u221e, -\u221e, -\u221e, -\u221e, -\u221e]\n# Step 2: Process first row\n#         curr = [0, 1, 2, 3, -\u221e, -\u221e, -\u221e, -\u221e]\n# Step 3: Process second row\n#         curr = [0, 4, 5, 9, -\u221e, -\u221e, -\u221e, -\u221e]\n# Step 4: Process third row\n#         curr = [0, 7, 8, 15, -\u221e, -\u221e, -\u221e, -\u221e]\n#\n# Output: 15",
    "keySteps": [
      "Initialize DP table with bit states",
      "Process each row of the grid",
      "Check validity of current state",
      "Update DP with maximum value"
    ]
  },
  "stack": {
    "name": "Stack",
    "type": "Data Structure",
    "description": "A linear data structure that follows Last-In-First-Out (LIFO) principle",
    "timeComplexity": "O(1) for push, pop, and peek operations",
    "spaceComplexity": "O(n) for storing n elements",
    "useCase": "Function call stack, expression evaluation, backtracking algorithms",
    "pseudocode": "# Stack: LIFO (Last-In-First-Out) data structure\n# Input: Elements to be pushed onto stack\n# Output: Elements popped from stack in reverse order\n\nAlgorithm STACK-OPERATIONS\n    # Initialize empty stack\n    S \u2190 empty array\n    top \u2190 0\n\n    # Push element x onto stack\n    Algorithm PUSH(S, x)\n        top \u2190 top + 1\n        S[top] \u2190 x\n\n    # Pop element from stack\n    Algorithm POP(S)\n        if top = 0 then\n            return \"underflow\"\n        end if\n        x \u2190 S[top]\n        top \u2190 top - 1\n        return x\n\n    # Check if stack is empty\n    Algorithm STACK-EMPTY(S)\n        if top = 0 then\n            return true\n        else\n            return false\n        end if\n\n    # Peek at top element\n    Algorithm PEEK(S)\n        if top = 0 then\n            return \"empty\"\n        end if\n        return S[top]\n\n# Example:\n# Input: Push sequence [1, 2, 3]\n#\n# Step 1: PUSH(S, 1)\n#         S = [1], top = 1\n# Step 2: PUSH(S, 2)\n#         S = [1, 2], top = 2\n# Step 3: PUSH(S, 3)\n#         S = [1, 2, 3], top = 3\n# Step 4: POP(S)\n#         Returns 3, S = [1, 2], top = 2\n# Step 5: PEEK(S)\n#         Returns 2\n#\n# Output: Elements popped in order [3, 2, 1]",
    "keySteps": [
      "PUSH: Add element to top of stack in O(1) time",
      "POP: Remove and return top element in O(1) time",
      "STACK-EMPTY: Check if stack is empty in O(1) time",
      "PEEK: View top element without removal in O(1) time"
    ]
  },
  "stack-sort": {
    "name": "Stack Sort",
    "type": "Algorithm",
    "description": "Stack Sort is an algorithm with time complexity O(n\u00b2). It is primarily used for sort using stack operations",
    "timeComplexity": "O(n\u00b2) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Sort using stack operations\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Sort using stack operations\n    ",
    "useCase": "Sort using stack operations\n    ",
    "pseudocode": "// Sort array using stack operations\nSTACK-SORT(A):\n    n \u2190 length[A]\n    S \u2190 empty stack\n    T \u2190 empty stack\n    // Push all elements to first stack\n    for i \u2190 1 to n:\n        PUSH(S, A[i])\n    // Sort elements using two stacks\n    while S not empty:\n        temp \u2190 POP(S)\n        while T not empty and TOP(T) > temp:\n            PUSH(S, POP(T))\n        PUSH(T, temp)\n    // Transfer sorted elements back to array\n    for i \u2190 n downto 1:\n        A[i] \u2190 POP(T)\n    return A\n\n// Example:\n// Input: A = [5, 2, 4, 6, 1, 3]\n//\n// Execution:\n// 1. Initial push: S = [5, 2, 4, 6, 1, 3], T = []\n// 2. After first iteration: S = [5, 2, 4, 6], T = [1, 3]\n// 3. After second iteration: S = [5, 2, 4], T = [1, 3, 6]\n// 4. After third iteration: S = [5, 2], T = [1, 3, 4, 6]\n// 5. After fourth iteration: S = [5], T = [1, 2, 3, 4, 6]\n// 6. After fifth iteration: S = [], T = [1, 2, 3, 4, 5, 6]\n//\n// Output: [1, 2, 3, 4, 5, 6]",
    "keySteps": [
      "Initialize: Create two empty stacks",
      "Sort: Use second stack to maintain sorted order",
      "Transfer: Move sorted elements back to array"
    ]
  },
  "stack-implementation": {
    "name": "Stack Implementation",
    "type": "Algorithm",
    "description": "Stack Implementation is an algorithm with time complexity O(1). It is primarily used for lifo data structure",
    "timeComplexity": "O(1) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: LIFO data structure\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: LIFO data structure\n    ",
    "useCase": "LIFO data structure\n    ",
    "pseudocode": "STACK-EMPTY(S)\n    if S.top = 0\n        then return true\n        else return false\n\nPUSH(S, x)\n    if S.top = S.size\n        then error \"stack overflow\"\n    S.top \u2190 S.top + 1\n    S[S.top] \u2190 x\n\nPOP(S)\n    if STACK-EMPTY(S)\n        then error \"stack underflow\"\n    S.top \u2190 S.top - 1\n    return S[S.top + 1]\n\n// Example:\n// Input: Operations [PUSH(10), PUSH(20), POP(), PUSH(30), PUSH(40)]\n//\n// Initial state:\n//   S = []\n//   S.top = 0\n//\n// After PUSH(10):\n//   S = [10]\n//   S.top = 1\n//\n// After PUSH(20):\n//   S = [10, 20]\n//   S.top = 2\n//\n// After POP():\n//   S = [10]\n//   S.top = 1\n//   Returns: 20\n//\n// After PUSH(30):\n//   S = [10, 30]\n//   S.top = 2\n//\n// After PUSH(40):\n//   S = [10, 30, 40]\n//   S.top = 3\n//\n// Final state:\n//   S = [10, 30, 40]\n//   S.top = 3",
    "keySteps": [
      "Initialize: Create array and top pointer",
      "Push: Add element and increment top pointer",
      "Pop: Remove element and decrement top pointer"
    ]
  },
  "sparse-table": {
    "name": "Sparse Table",
    "type": "1",
    "description": "Sparse Table is an algorithm with time complexity O(1). It is primarily used for range       minimum/maximum queries",
    "timeComplexity": "O(1) query, O(n log n) build &nbsp;|&nbsp; Space: O(n log n) &nbsp;|&nbsp; Use: Range\n      minimum/maximum queries\n    ",
    "spaceComplexity": "O(n log n) &nbsp;|&nbsp; Use: Range\n      minimum/maximum queries\n    ",
    "useCase": "Range\n      minimum/maximum queries\n    ",
    "pseudocode": "// Build sparse table\nBUILD-SPARSE-TABLE(A, n):\n  k = floor(log\u2082(n))\n  st = new array[n][k+1]\n  \n  // Initialize first column\n  for i = 0 to n-1:\n    st[i][0] = A[i]\n  \n  // Fill remaining columns\n  for j = 1 to k:\n    for i = 0 to n-2^j:\n      st[i][j] = min(st[i][j-1], st[i+2^(j-1)][j-1])\n  return st\n\n// Query minimum in range [L, R]\nQUERY-MIN(st, L, R):\n  j = floor(log\u2082(R-L+1))\n  return min(st[L][j], st[R-2^j+1][j])\n\n// Example usage\nA = [4, 2, 3, 7, 1, 5, 3, 3, 9, 6, 7, 1, 2, 4, 5]\nst = BUILD-SPARSE-TABLE(A, 15)\nmin_val = QUERY-MIN(st, 2, 7)  // Returns minimum in range [2,7]",
    "keySteps": [
      "O(1) query time for range minimum/maximum",
      "Static data structure (no updates)",
      "Can be extended for other range queries"
    ]
  },
  "spanning-tree": {
    "name": "Spanning Tree",
    "type": "E log V",
    "description": "Spanning Tree is an algorithm with time complexity O(E log V). It is primarily used for finding minimum spanning       trees",
    "timeComplexity": "O(E log V) &nbsp;|&nbsp; Space: O(V + E) &nbsp;|&nbsp; Use: Finding minimum spanning\n      trees\n    ",
    "spaceComplexity": "O(V + E) &nbsp;|&nbsp; Use: Finding minimum spanning\n      trees\n    ",
    "useCase": "Finding minimum spanning\n      trees\n    ",
    "pseudocode": "// Kruskal's Algorithm\nKRUSKAL(G):\n  A = \u2205\n  for each vertex v in G.V:\n    MAKE-SET(v)\n  sort G.E by weight\n  for each edge (u,v) in G.E (in sorted order):\n    if FIND-SET(u) \u2260 FIND-SET(v):\n      A = A \u222a {(u,v)}\n      UNION(u,v)\n  return A\n\n// Prim's Algorithm\nPRIM(G, w, r):\n  for each u in G.V:\n    key[u] = \u221e\n    \u03c0[u] = NIL\n  key[r] = 0\n  Q = G.V\n  while Q \u2260 \u2205:\n    u = EXTRACT-MIN(Q)\n    for each v in G.Adj[u]:\n      if v \u2208 Q and w(u,v) < key[v]:\n        \u03c0[v] = u\n        key[v] = w(u,v)",
    "keySteps": [
      "Both algorithms find minimum spanning tree",
      "Kruskal's better for sparse graphs",
      "Prim's better for dense graphs"
    ]
  },
  "sorting-quicksort": {
    "name": "Quick Sort",
    "type": "n log n",
    "description": "Quick Sort is an algorithm with time complexity O(n log n). It is primarily used for efficient       general-purpose sorting",
    "timeComplexity": "O(n log n) avg, O(n\u00b2) worst &nbsp;|&nbsp; Space: O(log n) &nbsp;|&nbsp; Use: Efficient\n      general-purpose sorting\n    ",
    "spaceComplexity": "O(log n) &nbsp;|&nbsp; Use: Efficient\n      general-purpose sorting\n    ",
    "useCase": "Efficient\n      general-purpose sorting\n    ",
    "pseudocode": "QUICKSORT(A, p, r):\n    if p < r:\n        q \u2190 PARTITION(A, p, r)\n        QUICKSORT(A, p, q-1)\n        QUICKSORT(A, q+1, r)\n\nPARTITION(A, p, r):\n    x \u2190 A[r]    // pivot\n    i \u2190 p - 1\n    for j \u2190 p to r-1:\n        if A[j] \u2264 x:\n            i \u2190 i + 1\n            exchange A[i] with A[j]\n    exchange A[i+1] with A[r]\n    return i + 1\n\n// Example:\n// Input: A = [3, 7, 8, 5, 2, 1, 9, 5, 4]\n//\n// First partition (pivot = 4):\n// [3, 2, 1, 4, 7, 8, 9, 5, 5]\n//\n// Recursive calls:\n// Left: [3, 2, 1]\n// Right: [7, 8, 9, 5, 5]\n//\n// Final result: [1, 2, 3, 4, 5, 5, 7, 8, 9]",
    "keySteps": [
      "Choose pivot element (usually last element)",
      "Partition array around pivot",
      "Recursively sort subarrays",
      "Use median-of-three for pivot selection"
    ]
  },
  "sorting-mergesort": {
    "name": "Merge Sort",
    "type": "n log n",
    "description": "Merge Sort is an algorithm with time complexity O(n log n). It is primarily used for stable sorting with guaranteed       performance",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Stable sorting with guaranteed\n      performance\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Stable sorting with guaranteed\n      performance\n    ",
    "useCase": "Stable sorting with guaranteed\n      performance\n    ",
    "pseudocode": "MERGESORT(A, p, r):\n    if p < r:\n        q \u2190 \u230a(p + r) / 2\u230b\n        MERGESORT(A, p, q)\n        MERGESORT(A, q + 1, r)\n        MERGE(A, p, q, r)\n\nMERGE(A, p, q, r):\n    n\u2081 \u2190 q - p + 1\n    n\u2082 \u2190 r - q\n    let L[1..n\u2081 + 1] and R[1..n\u2082 + 1] be new arrays\n    for i \u2190 1 to n\u2081:\n        L[i] \u2190 A[p + i - 1]\n    for j \u2190 1 to n\u2082:\n        R[j] \u2190 A[q + j]\n    L[n\u2081 + 1] \u2190 \u221e\n    R[n\u2082 + 1] \u2190 \u221e\n    i \u2190 1\n    j \u2190 1\n    for k \u2190 p to r:\n        if L[i] \u2264 R[j]:\n            A[k] \u2190 L[i]\n            i \u2190 i + 1\n        else:\n            A[k] \u2190 R[j]\n            j \u2190 j + 1\n\n// Example:\n// Input: A = [3, 7, 8, 5, 2, 1, 9, 5, 4]\n//\n// First split:\n// Left: [3, 7, 8, 5]\n// Right: [2, 1, 9, 5, 4]\n//\n// Recursive splits:\n// [3, 7] [8, 5] [2, 1] [9, 5, 4]\n//\n// Merge steps:\n// [3, 7] [5, 8] [1, 2] [4, 5, 9]\n// [3, 5, 7, 8] [1, 2, 4, 5, 9]\n// [1, 2, 3, 4, 5, 5, 7, 8, 9]",
    "keySteps": [
      "Divide array into two halves",
      "Recursively sort each half",
      "Merge sorted halves",
      "Stable sorting algorithm"
    ]
  },
  "sorting-heapsort": {
    "name": "Heap Sort",
    "type": "n log n",
    "description": "Heap Sort is an algorithm with time complexity O(n log n). It is primarily used for in-place sorting with guaranteed       performance",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: In-place sorting with guaranteed\n      performance\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: In-place sorting with guaranteed\n      performance\n    ",
    "useCase": "In-place sorting with guaranteed\n      performance\n    ",
    "pseudocode": "HEAPSORT(A):\n    BUILD-MAX-HEAP(A)\n    for i \u2190 length[A] downto 2:\n        exchange A[1] with A[i]\n        heap-size[A] \u2190 heap-size[A] - 1\n        MAX-HEAPIFY(A, 1)\n\nBUILD-MAX-HEAP(A):\n    heap-size[A] \u2190 length[A]\n    for i \u2190 \u230alength[A]/2\u230b downto 1:\n        MAX-HEAPIFY(A, i)\n\nMAX-HEAPIFY(A, i):\n    l \u2190 LEFT(i)\n    r \u2190 RIGHT(i)\n    if l \u2264 heap-size[A] and A[l] > A[i]:\n        largest \u2190 l\n    else:\n        largest \u2190 i\n    if r \u2264 heap-size[A] and A[r] > A[largest]:\n        largest \u2190 r\n    if largest \u2260 i:\n        exchange A[i] with A[largest]\n        MAX-HEAPIFY(A, largest)\n\nLEFT(i):\n    return 2i\n\nRIGHT(i):\n    return 2i + 1\n\n// Example:\n// Input: A = [3, 7, 8, 5, 2, 1, 9, 5, 4]\n//\n// Build max heap:\n//        9\n//      /   \\\\\n//     7     8\n//    / \\\\   / \\\\\n//   5   2 1   5\n//  / \\\\\n// 3   4\n//\n// Extract max and heapify:\n// [9, 8, 7, 5, 5, 4, 3, 2, 1]",
    "keySteps": [
      "Build max heap from array",
      "Extract maximum element",
      "Maintain heap property",
      "In-place sorting algorithm"
    ]
  },
  "sorting-comparisons": {
    "name": "Sorting Comparisons",
    "type": "n log n",
    "description": "Sorting Comparisons is an algorithm with time complexity O(n log n). It is primarily used for comparing and analyzing sorting       algorithms",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Comparing and analyzing sorting\n      algorithms\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Comparing and analyzing sorting\n      algorithms\n    ",
    "useCase": "Comparing and analyzing sorting\n      algorithms\n    ",
    "pseudocode": "// Comparison-based sorting algorithms\nQUICK-SORT(A, p, r):\n  if p < r:\n    q = PARTITION(A, p, r)\n    QUICK-SORT(A, p, q-1)\n    QUICK-SORT(A, q+1, r)\n\nMERGE-SORT(A, p, r):\n  if p < r:\n    q = floor((p + r) / 2)\n    MERGE-SORT(A, p, q)\n    MERGE-SORT(A, q+1, r)\n    MERGE(A, p, q, r)\n\nHEAP-SORT(A):\n  BUILD-MAX-HEAP(A)\n  for i = length[A] downto 2:\n    exchange A[1] with A[i]\n    heap-size[A] = heap-size[A] - 1\n    MAX-HEAPIFY(A, 1)",
    "keySteps": [
      "All comparison-based sorts have \u03a9(n log n) lower bound",
      "Choose based on data characteristics and requirements",
      "Hybrid approaches (e.g., Timsort) combine strengths"
    ]
  },
  "sliding-window": {
    "name": "Sliding Window",
    "type": "Algorithm",
    "description": "A technique for efficiently processing arrays by maintaining a window of elements",
    "timeComplexity": "O(n) where n is the array length",
    "spaceComplexity": "O(1) for fixed-size window problems",
    "useCase": "Finding subarrays with specific properties, string pattern matching, array optimization\n      ",
    "pseudocode": "# Sliding Window: Find subarrays with specific properties\n# Input: Array A[1..n], window size k\n# Output: Maximum sum of any subarray of size k\n\nAlgorithm SLIDING-WINDOW(A, k)\n    n \u2190 length[A]\n    if n < k then\n        return -1\n    end if\n\n    # Compute sum of first window\n    window_sum \u2190 0\n    for i \u2190 1 to k do\n        window_sum \u2190 window_sum + A[i]\n    end for\n    max_sum \u2190 window_sum\n\n    # Slide window and update sum\n    for i \u2190 k + 1 to n do\n        window_sum \u2190 window_sum + A[i] - A[i - k]\n        max_sum \u2190 max(max_sum, window_sum)\n    end for\n\n    return max_sum\n\n# Example:\n# Input: A = [1, 4, 2, 10, 2, 3, 1, 0, 20], k = 4\n#\n# Step 1: window_sum = 1 + 4 + 2 + 10 = 17\n#         max_sum = 17\n# Step 2: window_sum = 17 + 2 - 1 = 18\n#         max_sum = 18\n# Step 3: window_sum = 18 + 3 - 4 = 17\n#         max_sum = 18\n# Step 4: window_sum = 17 + 1 - 2 = 16\n#         max_sum = 18\n# Step 5: window_sum = 16 + 0 - 10 = 6\n#         max_sum = 18\n# Step 6: window_sum = 6 + 20 - 2 = 24\n#         max_sum = 24\n#\n# Output: 24",
    "keySteps": [
      "Initialize window sum and maximum sum variables",
      "Compute sum of the first window of size k",
      "Slide window by adding new element and removing oldest",
      "Update maximum sum when a larger sum is found"
    ]
  },
  "sieve-of-sundaram": {
    "name": "Sieve of Sundaram",
    "type": "Algorithm",
    "description": "An alternative to the Sieve of Eratosthenes that generates odd composite numbers",
    "timeComplexity": "O(n log n) where n is the upper limit",
    "spaceComplexity": "O(n/2) for storing odd numbers up to n",
    "useCase": "Finding prime numbers, especially when memory is limited",
    "pseudocode": "# Sieve of Sundaram\n# Input: Integer n > 1\n# Output: Array of primes \u2264 n\n\nAlgorithm SIEVE-OF-SUNDARAM(n)\n    # Initialize array\n    k \u2190 (n - 1) // 2\n    is_prime \u2190 array of size k + 1\n    for i \u2190 1 to k do\n        is_prime[i] \u2190 true\n    end for\n\n    # Mark numbers of form i + j + 2ij\n    for i \u2190 1 to k do\n        j \u2190 i\n        while i + j + 2*i*j \u2264 k do\n            is_prime[i + j + 2*i*j] \u2190 false\n            j \u2190 j + 1\n        end while\n    end for\n\n    # Collect primes\n    primes \u2190 [2]  # 2 is the only even prime\n    for i \u2190 1 to k do\n        if is_prime[i] then\n            primes.append(2*i + 1)\n        end if\n    end for\n\n    return primes\n\n# Example:\n# Input: n = 30\n#\n# Step 1: k = (30 - 1) // 2 = 14\n#         is_prime = [T, T, T, T, T, T, T, T, T, T, T, T, T, T, T]\n#\n# Step 2: Mark numbers\n#         i = 1: mark 4, 7, 10, 13\n#         i = 2: mark 7, 12\n#         i = 3: mark 10\n#         i = 4: mark 13\n#\n# Step 3: Collect primes\n#         primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\n#\n# Output: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]",
    "keySteps": [
      "Initialize array for odd numbers up to n/2",
      "Mark numbers of form i + j + 2ij as composite",
      "Collect remaining unmarked numbers as potential primes",
      "Transform indices to get actual prime numbers"
    ]
  },
  "sieve-of-eratosthenes": {
    "name": "Sieve of Eratosthenes",
    "type": "Algorithm",
    "description": "An efficient algorithm to find all prime numbers up to a given limit",
    "timeComplexity": "O(n log log n) where n is the upper limit",
    "spaceComplexity": "O(n) for storing the boolean array",
    "useCase": "Finding prime numbers, prime factorization, number theory problems",
    "pseudocode": "# Sieve of Eratosthenes: Find all primes up to n\n# Input: Integer n > 1\n# Output: Array of primes \u2264 n\n\nAlgorithm SIEVE-OF-ERATOSTHENES(n)\n    # Initialize array of booleans\n    is_prime \u2190 array of size n + 1\n    for i \u2190 2 to n do\n        is_prime[i] \u2190 true\n    end for\n\n    # Mark multiples of primes\n    for i \u2190 2 to \u221an do\n        if is_prime[i] then\n            for j \u2190 i\u00b2 to n step i do\n                is_prime[j] \u2190 false\n            end for\n        end if\n    end for\n\n    # Collect primes\n    primes \u2190 empty array\n    for i \u2190 2 to n do\n        if is_prime[i] then\n            primes.append(i)\n        end if\n    end for\n\n    return primes\n\n# Example:\n# Input: n = 30\n#\n# Step 1: is_prime = [F, F, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T]\n# Step 2: i = 2, mark multiples of 2\n#         is_prime = [F, F, T, T, F, T, F, T, F, T, F, T, F, T, F, T, F, T, F, T, F, T, F, T, F, T, F, T, F, T, F]\n# Step 3: i = 3, mark multiples of 3\n#         is_prime = [F, F, T, T, F, T, F, T, F, F, F, T, F, T, F, F, F, T, F, T, F, F, F, T, F, T, F, F, F, T, F]\n# Step 4: i = 5, mark multiples of 5\n#         is_prime = [F, F, T, T, F, T, F, T, F, F, F, T, F, T, F, F, F, T, F, T, F, F, F, T, F, T, F, F, F, T, F]\n#\n# Output: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]",
    "keySteps": [
      "Initialize array of booleans for all numbers up to n",
      "Mark multiples of each prime number as non-prime",
      "Collect remaining unmarked numbers as primes",
      "Return the array of prime numbers"
    ]
  },
  "sieve-of-atkin": {
    "name": "Sieve of Atkin",
    "type": "n/log log n",
    "description": "Sieve of Atkin is an algorithm with time complexity O(n/log log n). It is primarily used for find all primes up to n",
    "timeComplexity": "O(n/log log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Find all primes up to n\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Find all primes up to n\n    ",
    "useCase": "Find all primes up to n\n    ",
    "pseudocode": "# Sieve of Atkin\n# Input: Integer n > 1\n# Output: Array of primes \u2264 n\n\nAlgorithm SIEVE-OF-ATKIN(n)\n    # Initialize array\n    is_prime \u2190 array of size n + 1\n    for i \u2190 0 to n do\n        is_prime[i] \u2190 false\n    end for\n\n    # Mark potential primes\n    for x \u2190 1 to \u221an do\n        for y \u2190 1 to \u221an do\n            # Case 1: 4x\u00b2 + y\u00b2\n            k \u2190 4*x*x + y*y\n            if k \u2264 n and (k mod 12 = 1 or k mod 12 = 5) then\n                is_prime[k] \u2190 not is_prime[k]\n            end if\n\n            # Case 2: 3x\u00b2 + y\u00b2\n            k \u2190 3*x*x + y*y\n            if k \u2264 n and k mod 12 = 7 then\n                is_prime[k] \u2190 not is_prime[k]\n            end if\n\n            # Case 3: 3x\u00b2 - y\u00b2\n            k \u2190 3*x*x - y*y\n            if x > y and k \u2264 n and k mod 12 = 11 then\n                is_prime[k] \u2190 not is_prime[k]\n            end if\n        end for\n    end for\n\n    # Mark squares of primes as non-prime\n    for i \u2190 5 to \u221an do\n        if is_prime[i] then\n            for j \u2190 i*i to n step i*i do\n                is_prime[j] \u2190 false\n            end for\n        end if\n    end for\n\n    # Collect primes\n    primes \u2190 [2, 3]\n    for i \u2190 5 to n do\n        if is_prime[i] then\n            primes.append(i)\n        end if\n    end for\n\n    return primes\n\n# Example:\n# Input: n = 30\n#\n# Step 1: Initialize array\n#         is_prime = [F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F]\n#\n# Step 2: Mark potential primes\n#         x = 1, y = 1: k = 5, 4, 2\n#         x = 2, y = 1: k = 17, 13, 11\n#         x = 2, y = 2: k = 20, 16, 8\n#         ...\n#\n# Step 3: Mark squares\n#         i = 5: mark 25\n#\n# Step 4: Collect primes\n#         primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\n#\n# Output: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]",
    "keySteps": [
      "Initialize array for potential primes",
      "Mark numbers using quadratic forms",
      "Mark squares of primes as non-prime",
      "Collect remaining primes"
    ]
  },
  "shell-sort": {
    "name": "Shell Sort",
    "type": "Algorithm",
    "description": "An optimization of insertion sort that allows the exchange of items that are far apart",
    "timeComplexity": "O(n log\u00b2 n) average case, depends on gap sequence",
    "spaceComplexity": "O(1) in-place sorting algorithm",
    "useCase": "Optimized insertion sort with gap sequence, good for medium-sized arrays",
    "pseudocode": "# Shell Sort: An optimization of insertion sort using gap sequence\n# Input: Array A[1..n]\n# Output: Sorted array A\n\nAlgorithm SHELL-SORT(A)\n    n \u2190 length[A]\n    \n    # Start with a large gap, then reduce it\n    gap \u2190 \u230an/2\u230b\n    \n    while gap > 0 do\n        # Do insertion sort for elements at positions i, i+gap, i+2*gap, ...\n        for i \u2190 gap + 1 to n do\n            temp \u2190 A[i]\n            j \u2190 i\n            \n            # Shift earlier gap-sorted elements up until correct location\n            while j \u2265 gap and A[j - gap] > temp do\n                A[j] \u2190 A[j - gap]\n                j \u2190 j - gap\n            end while\n            \n            # Put temp in its correct location\n            A[j] \u2190 temp\n        end for\n        \n        # Reduce the gap\n        gap \u2190 \u230agap/2\u230b\n    end while\n\n# Example:\n# Input: A = [12, 34, 54, 2, 3]\n#\n# Step 1: gap = 2\n# [12, 34, 54, 2, 3] \u2192 [12, 2, 54, 34, 3]\n#\n# Step 2: gap = 1\n# [12, 2, 54, 34, 3] \u2192 [2, 3, 12, 34, 54]",
    "keySteps": [
      "Initialize gap sequence starting with n/2",
      "Perform insertion sort on elements separated by gap",
      "Reduce gap size and repeat until gap is 1",
      "Final pass with gap=1 is a standard insertion sort"
    ]
  },
  "selection-sort": {
    "name": "Selection Sort",
    "type": "n\u00b2",
    "description": "Selection Sort is an algorithm with time complexity O(n\u00b2). It is primarily used for sorting array in-place",
    "timeComplexity": "O(n\u00b2) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Sorting array in-place\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Sorting array in-place\n    ",
    "useCase": "Sorting array in-place\n    ",
    "pseudocode": "SELECTION-SORT(A)\n    n \u2190 length[A]\n\n    for i \u2190 1 to n-1\n        # Find minimum in unsorted part\n        min_idx \u2190 i\n        for j \u2190 i+1 to n\n            if A[j] < A[min_idx]\n                min_idx \u2190 j\n\n        # Swap with first unsorted element\n        swap A[i] and A[min_idx]\n\n# Example:\n# Input: A = [5, 2, 4, 6, 1, 3]\n# After each iteration:\n# [1, 2, 4, 6, 5, 3]  # 1 is selected\n# [1, 2, 4, 6, 5, 3]  # 2 is selected\n# [1, 2, 3, 6, 5, 4]  # 3 is selected\n# [1, 2, 3, 4, 5, 6]  # 4 is selected\n# [1, 2, 3, 4, 5, 6]  # 5 is selected\n# Output: [1, 2, 3, 4, 5, 6]",
    "keySteps": [
      "Find: Minimum element in unsorted part",
      "Swap: With first unsorted element",
      "Repeat: Until array is sorted"
    ]
  },
  "segment-tree": {
    "name": "Segment Tree",
    "type": "log n",
    "description": "Segment Tree is an algorithm with time complexity O(log n). It is primarily used for range queries and updates",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Range queries and updates\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Range queries and updates\n    ",
    "useCase": "Range queries and updates\n    ",
    "pseudocode": "// Standard Segment Tree\nclass SegmentTree:\n    def __init__(self, data):\n        self.n = len(data)\n        self.size = 1\n        while self.size < self.n:\n            self.size *= 2\n        self.tree = [0] * (2 * self.size)\n        self.build(data)\n\n    def build(self, data):\n        # Fill leaves\n        for i in range(self.n):\n            self.tree[self.size + i] = data[i]\n        # Build internal nodes\n        for i in range(self.size - 1, 0, -1):\n            self.tree[i] = self.tree[2*i] + self.tree[2*i+1]\n\n    def update(self, pos, value):\n        pos += self.size\n        self.tree[pos] = value\n        while pos > 1:\n            pos //= 2\n            self.tree[pos] = self.tree[2*pos] + self.tree[2*pos+1]\n\n    def query(self, l, r):\n        res = 0\n        l += self.size\n        r += self.size\n        while l <= r:\n            if l % 2 == 1:\n                res += self.tree[l]\n                l += 1\n            if r % 2 == 0:\n                res += self.tree[r]\n                r -= 1\n            l //= 2\n            r //= 2\n        return res\n\n// Lazy Propagation Segment Tree\nclass LazySegmentTree:\n    def __init__(self, data):\n        self.n = len(data)\n        self.size = 1\n        while self.size < self.n:\n            self.size *= 2\n        self.tree = [0] * (2 * self.size)\n        self.lazy = [0] * (2 * self.size)\n        self.build(data)\n\n    def push(self, node, node_l, node_r):\n        if self.lazy[node] != 0:\n            self.tree[node] += self.lazy[node] * (node_r - node_l + 1)\n            if node_l != node_r:\n                self.lazy[2*node] += self.lazy[node]\n                self.lazy[2*node+1] += self.lazy[node]\n            self.lazy[node] = 0\n\n    def range_update(self, l, r, val):\n        self._range_update(1, 0, self.size-1, l, r, val)\n\n    def _range_update(self, node, node_l, node_r, l, r, val):\n        self.push(node, node_l, node_r)\n        if r < node_l or l > node_r:\n            return\n        if l <= node_l and node_r <= r:\n            self.lazy[node] += val\n            self.push(node, node_l, node_r)\n            return\n        mid = (node_l + node_r) // 2\n        self._range_update(2*node, node_l, mid, l, r, val)\n        self._range_update(2*node+1, mid+1, node_r, l, r, val)\n        self.tree[node] = self.tree[2*node] + self.tree[2*node+1]\n\n// Persistent Segment Tree\nclass PersistentSegmentTree:\n    def __init__(self, data):\n        self.n = len(data)\n        self.size = 1\n        while self.size < self.n:\n            self.size *= 2\n        self.versions = []\n        self.build(data)\n\n    def build(self, data):\n        root = [0] * (2 * self.size)\n        for i in range(self.n):\n            root[self.size + i] = data[i]\n        for i in range(self.size - 1, 0, -1):\n            root[i] = root[2*i] + root[2*i+1]\n        self.versions.append(root)\n\n    def update(self, version, pos, value):\n        new_root = self.versions[version].copy()\n        pos += self.size\n        new_root[pos] = value\n        while pos > 1:\n            pos //= 2\n            new_root[pos] = new_root[2*pos] + new_root[2*pos+1]\n        self.versions.append(new_root)\n        return len(self.versions) - 1",
    "keySteps": []
  },
  "rotate-matrix": {
    "name": "Matrix Operations",
    "type": "n\u00b2",
    "description": "Matrix Operations is an algorithm with time complexity O(n\u00b2). It is primarily used for matrix transformations and operations",
    "timeComplexity": "O(n\u00b2) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Matrix transformations and operations\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Matrix transformations and operations\n    ",
    "useCase": "Matrix transformations and operations\n    ",
    "pseudocode": "ROTATE-CLOCKWISE(A)\n1  n = A.rows\n2  // Transpose the matrix\n3  for i = 1 to n\n4      for j = i to n\n5          exchange A[i][j] with A[j][i]\n6  // Reverse each row\n7  for i = 1 to n\n8      for j = 1 to n/2\n9          exchange A[i][j] with A[i][n-j+1]\n10 return A\n\nROTATE-COUNTERCLOCKWISE(A)\n1  n = A.rows\n2  // Transpose the matrix\n3  for i = 1 to n\n4      for j = i to n\n5          exchange A[i][j] with A[j][i]\n6  // Reverse each column\n7  for j = 1 to n\n8      for i = 1 to n/2\n9          exchange A[i][j] with A[n-i+1][j]\n10 return A\n\n// Example:\n// Input: A = [[1, 2, 3],\n//             [4, 5, 6],\n//             [7, 8, 9]]\n//\n// Clockwise rotation:\n// Step 1: Transpose\n//         [[1, 4, 7],\n//          [2, 5, 8],\n//          [3, 6, 9]]\n// Step 2: Reverse rows\n//         [[7, 4, 1],\n//          [8, 5, 2],\n//          [9, 6, 3]]\n//\n// Counterclockwise rotation:\n// Step 1: Transpose\n//         [[1, 4, 7],\n//          [2, 5, 8],\n//          [3, 6, 9]]\n// Step 2: Reverse columns\n//         [[3, 6, 9],\n//          [2, 5, 8],\n//          [1, 4, 7]]",
    "keySteps": []
  },
  "red-black-tree": {
    "name": "Red-Black Tree",
    "type": "log n",
    "description": "Red-Black Tree is an algorithm with time complexity O(log n). It is primarily used for self-balancing binary search tree",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Self-balancing binary search tree\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Self-balancing binary search tree\n    ",
    "useCase": "Self-balancing binary search tree\n    ",
    "pseudocode": "RB-INSERT(T, z)\n    let y \u2190 null\n    let x \u2190 T.root\n\n    while x \u2260 null\n        do y \u2190 x\n           if z.key < x.key\n               then x \u2190 x.left\n               else x \u2190 x.right\n\n    z.p \u2190 y\n    if y = null\n        then T.root \u2190 z\n        else if z.key < y.key\n            then y.left \u2190 z\n            else y.right \u2190 z\n\n    z.left \u2190 null\n    z.right \u2190 null\n    z.color \u2190 RED\n    RB-INSERT-FIXUP(T, z)\n\nRB-INSERT-FIXUP(T, z)\n    while z.p.color = RED\n        do if z.p = z.p.p.left\n               then y \u2190 z.p.p.right\n                    if y.color = RED\n                        then z.p.color \u2190 BLACK\n                             y.color \u2190 BLACK\n                             z.p.p.color \u2190 RED\n                             z \u2190 z.p.p\n                        else if z = z.p.right\n                            then z \u2190 z.p\n                                 LEFT-ROTATE(T, z)\n                            z.p.color \u2190 BLACK\n                            z.p.p.color \u2190 RED\n                            RIGHT-ROTATE(T, z.p.p)\n               else (same as then clause with \"right\" and \"left\" exchanged)\n    T.root.color \u2190 BLACK\n\nLEFT-ROTATE(T, x)\n    let y \u2190 x.right\n    x.right \u2190 y.left\n    if y.left \u2260 null\n        then y.left.p \u2190 x\n    y.p \u2190 x.p\n    if x.p = null\n        then T.root \u2190 y\n        else if x = x.p.left\n            then x.p.left \u2190 y\n            else x.p.right \u2190 y\n    y.left \u2190 x\n    x.p \u2190 y\n\n// Example:\n// Input: Insert keys [10, 20, 30, 40, 50, 25]\n//\n// Insert 10:\n//   Tree: 10(B)\n//\n// Insert 20:\n//   Tree: 10(B)\n//         \\\n//         20(R)\n//\n// Insert 30:\n//   Tree: 20(B)\n//        /  \\\n//     10(R) 30(R)\n//\n// Insert 40:\n//   Tree: 20(B)\n//        /  \\\n//     10(B) 30(B)\n//             \\\n//            40(R)\n//\n// Insert 50:\n//   Tree: 20(B)\n//        /  \\\n//     10(B) 40(B)\n//           /  \\\n//        30(R) 50(R)\n//\n// Insert 25:\n//   Tree: 20(B)\n//        /  \\\n//     10(B) 40(R)\n//           /  \\\n//        30(B) 50(B)\n//       /\n//    25(R)",
    "keySteps": [
      "Step 1: [Description]",
      "Step 2: [Description]",
      "Step 3: [Description]"
    ]
  },
  "recursion": {
    "name": "Recursion",
    "type": "Algorithm",
    "description": "Recursion is an algorithm with time complexity O(n). It is primarily used for break problems into smaller       subproblems",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Break problems into smaller\n      subproblems\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Break problems into smaller\n      subproblems\n    ",
    "useCase": "Break problems into smaller\n      subproblems\n    ",
    "pseudocode": "// Factorial\nFACTORIAL(n):\n  if n \u2264 1:\n    return 1\n  return n * FACTORIAL(n-1)\n\n// Fibonacci\nFIBONACCI(n):\n  if n \u2264 1:\n    return n\n  return FIBONACCI(n-1) + FIBONACCI(n-2)\n\n// Tower of Hanoi\nHANOI(n, source, target, auxiliary):\n  if n == 1:\n    move disk from source to target\n    return\n  HANOI(n-1, source, auxiliary, target)\n  move disk from source to target\n  HANOI(n-1, auxiliary, target, source)\n\n// Binary Search\nBINARY-SEARCH(A, l, r, x):\n  if l > r:\n    return -1\n  mid = floor((l + r) / 2)\n  if A[mid] == x:\n    return mid\n  if A[mid] > x:\n    return BINARY-SEARCH(A, l, mid-1, x)\n  return BINARY-SEARCH(A, mid+1, r, x)\n\n// Merge Sort\nMERGE-SORT(A, l, r):\n  if l \u2265 r:\n    return\n  mid = floor((l + r) / 2)\n  MERGE-SORT(A, l, mid)\n  MERGE-SORT(A, mid+1, r)\n  MERGE(A, l, mid, r)\n\n// Quick Sort\nQUICK-SORT(A, l, r):\n  if l \u2265 r:\n    return\n  p = PARTITION(A, l, r)\n  QUICK-SORT(A, l, p-1)\n  QUICK-SORT(A, p+1, r)",
    "keySteps": []
  },
  "radix-sort": {
    "name": "Radix Sort",
    "type": "d(n+k",
    "description": "Radix Sort is an algorithm with time complexity O(d(n+k). It is primarily used for sort numbers by processing       individual digits",
    "timeComplexity": "O(d(n+k)) &nbsp;|&nbsp; Space: O(n+k) &nbsp;|&nbsp; Use: Sort numbers by processing\n      individual digits\n    ",
    "spaceComplexity": "O(n+k) &nbsp;|&nbsp; Use: Sort numbers by processing\n      individual digits\n    ",
    "useCase": "Sort numbers by processing\n      individual digits\n    ",
    "pseudocode": "RADIX-SORT(A)\n1  // Find maximum number to know number of digits\n2  max_num = max(A)\n3  exp = 1\n4  while max_num/exp > 0\n5      COUNTING-SORT(A, exp)\n6      exp *= 10\n\nCOUNTING-SORT(A, exp)\n1  n = A.length\n2  output = [0] * n\n3  count = [0] * 10\n4\n5  // Store count of occurrences\n6  for i = 0 to n-1\n7      index = (A[i]/exp) % 10\n8      count[index] += 1\n9\n10 // Change count[i] to position of digit i in output\n11 for i = 1 to 9\n12     count[i] += count[i-1]\n13\n14 // Build output array\n15 for i = n-1 downto 0\n16     index = (A[i]/exp) % 10\n17     output[count[index]-1] = A[i]\n18     count[index] -= 1\n19\n20 // Copy output to A\n21 for i = 0 to n-1\n22     A[i] = output[i]\n\n// Example:\n// Input: A = [170, 45, 75, 90, 802, 24, 2, 66]\n//\n// Step 1 (exp=1):\n// Count: [2, 0, 2, 0, 1, 2, 2, 0, 0, 1]\n// Output: [170, 90, 802, 2, 24, 45, 75, 66]\n//\n// Step 2 (exp=10):\n// Count: [2, 2, 2, 0, 1, 1, 0, 0, 0, 0]\n// Output: [802, 2, 24, 45, 66, 170, 75, 90]\n//\n// Step 3 (exp=100):\n// Count: [6, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n// Output: [2, 24, 45, 66, 75, 90, 170, 802]",
    "keySteps": [
      "Find: Maximum number to determine digit count",
      "Process: Each digit position from least to most significant",
      "Sort: Using counting sort for each digit position"
    ]
  },
  "rabin-karp": {
    "name": "Rabin-Karp",
    "type": "n + m",
    "description": "Rabin-Karp is an algorithm with time complexity O(n + m). It is primarily used for pattern matching with rolling hash",
    "timeComplexity": "O(n + m) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Pattern matching with rolling hash\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Pattern matching with rolling hash\n    ",
    "useCase": "Pattern matching with rolling hash\n    ",
    "pseudocode": "# Rabin-Karp: Pattern matching with rolling hash\n# Input: Text T[1..n], pattern P[1..m]\n# Output: Starting indices where P occurs in T\n\nAlgorithm RABIN-KARP(T, P)\n    n \u2190 length[T]\n    m \u2190 length[P]\n    d \u2190 256  # Number of characters in alphabet\n    q \u2190 101  # Prime number for hash\n    h \u2190 d^(m-1) mod q\n\n    # Compute hash of pattern and first window\n    p \u2190 0\n    t \u2190 0\n    for i \u2190 1 to m do\n        p \u2190 (d * p + P[i]) mod q\n        t \u2190 (d * t + T[i]) mod q\n    end for\n\n    # Slide pattern over text\n    for s \u2190 0 to n - m do\n        if p = t then\n            # Check for exact match\n            match \u2190 true\n            for i \u2190 1 to m do\n                if P[i] \u2260 T[s + i] then\n                    match \u2190 false\n                    break\n                end if\n            end for\n            if match then\n                print \"Pattern found at index\" s\n            end if\n        end if\n\n        # Compute hash for next window\n        if s < n - m then\n            t \u2190 (d * (t - T[s + 1] * h) + T[s + m + 1]) mod q\n            if t < 0 then\n                t \u2190 t + q\n            end if\n        end if\n    end for\n\n# Example:\n# Input: T = \"GEEKS FOR GEEKS\", P = \"GEEK\"\n#\n# Step 1: p = hash(\"GEEK\") = 71\n#         t = hash(\"GEEK\") = 71\n#         Match found at index 0\n# Step 2: t = hash(\"EEKS\") = 69\n# Step 3: t = hash(\"EKS \") = 75\n# Step 4: t = hash(\"KS F\") = 83\n# Step 5: t = hash(\"S FO\") = 95\n# Step 6: t = hash(\" FOR\") = 70\n# Step 7: t = hash(\"FOR \") = 82\n# Step 8: t = hash(\"OR G\") = 79\n# Step 9: t = hash(\"R GE\") = 71\n#         Match found at index 10\n#\n# Output: Pattern found at indices 0 and 10",
    "keySteps": [
      "Compute hash of pattern and first window",
      "Slide pattern over text",
      "Check for exact match when hashes match",
      "Update rolling hash for next window"
    ]
  },
  "quickselect": {
    "name": "Quickselect",
    "type": "divide and conquer",
    "description": "Quickselect is an algorithm with time complexity O(n). It is primarily used for find k-th       smallest element",
    "timeComplexity": "O(n) average, O(n\u00b2) worst &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find k-th\n      smallest element\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find k-th\n      smallest element\n    ",
    "useCase": "Find k-th\n      smallest element\n    ",
    "pseudocode": "QUICKSELECT(A, k)\n    return SELECT(A, 1, A.length, k)\n\nSELECT(A, p, r, k)\n    if p = r\n        then return A[p]\n    let q \u2190 PARTITION(A, p, r)\n    let i \u2190 q - p + 1\n    if k = i\n        then return A[q]\n    else if k < i\n        then return SELECT(A, p, q-1, k)\n    else return SELECT(A, q+1, r, k-i)\n\nPARTITION(A, p, r)\n    let x \u2190 A[r]\n    let i \u2190 p - 1\n    for j \u2190 p to r - 1\n        do if A[j] \u2264 x\n            then i \u2190 i + 1\n                exchange A[i] with A[j]\n    exchange A[i+1] with A[r]\n    return i + 1\n\n// Example:\n// Input: A = [3, 2, 1, 5, 4], k = 3\n//\n// First call: p = 1, r = 5, k = 3\n//   q = 3 (after PARTITION)\n//   i = 3 - 1 + 1 = 3\n//   k = i, return A[3] = 3\n//\n// Output: 3",
    "keySteps": [
      "Partition: Divide array using pivot element",
      "Compare: Check if k-th element is found",
      "Recurse: Search in appropriate subarray"
    ]
  },
  "quick-sort": {
    "name": "Quick Sort",
    "type": "n\u00b2",
    "description": "Quick Sort is an algorithm with time complexity O(n\u00b2). It is primarily used for efficient in-place sorting",
    "timeComplexity": "O(n\u00b2) &nbsp;|&nbsp; Space: O(log n) &nbsp;|&nbsp; Use: Efficient in-place sorting\n    ",
    "spaceComplexity": "O(log n) &nbsp;|&nbsp; Use: Efficient in-place sorting\n    ",
    "useCase": "Efficient in-place sorting\n    ",
    "pseudocode": "// Main quick sort function\nQUICK-SORT(array, start, end):\n    # If array has more than one element\n    if start < end:\n        # Partition the array and get pivot position\n        pivot_position = PARTITION(array, start, end)\n        # Sort left side of pivot\n        QUICK-SORT(array, start, pivot_position - 1)\n        # Sort right side of pivot\n        QUICK-SORT(array, pivot_position + 1, end)\n\n// Partition the array around a pivot\nPARTITION(array, start, end):\n    # Choose last element as pivot\n    pivot = array[end]\n    # Initialize pointer for elements less than pivot\n    smaller_element_pointer = start - 1\n\n    # Move through the array\n    for current_element from start to end - 1:\n        # If current element is less than pivot\n        if array[current_element] \u2264 pivot:\n            # Move smaller element pointer\n            smaller_element_pointer = smaller_element_pointer + 1\n            # Swap current element with element at pointer\n            swap array[smaller_element_pointer] with array[current_element]\n\n    # Place pivot in correct position\n    swap array[smaller_element_pointer + 1] with array[end]\n    # Return pivot position\n    return smaller_element_pointer + 1",
    "keySteps": []
  },
  "queue": {
    "name": "Queue",
    "type": "Data Structure",
    "description": "Queue is an algorithm with time complexity O(1). It is primarily used for fifo (first-in-first-out) operations",
    "timeComplexity": "O(1) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: FIFO (First-In-First-Out) operations\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: FIFO (First-In-First-Out) operations\n    ",
    "useCase": "FIFO (First-In-First-Out) operations\n    ",
    "pseudocode": "// Standard Queue\nclass Queue:\n    def __init__(self):\n        self.items = []\n\n    # Enqueue (add to rear)\n    def enqueue(self, item):\n        self.items.append(item)\n\n    # Dequeue (remove from front)\n    def dequeue(self):\n        if self.is_empty():\n            return None\n        return self.items.pop(0)\n\n    # Check if empty\n    def is_empty(self):\n        return len(self.items) == 0\n\n    # Get size\n    def size(self):\n        return len(self.items)\n\n    # Peek front\n    def peek(self):\n        if self.is_empty():\n            return None\n        return self.items[0]\n\n// Circular Queue\nclass CircularQueue:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.items = [None] * capacity\n        self.front = 0\n        self.rear = -1\n        self.size = 0\n\n    # Enqueue\n    def enqueue(self, item):\n        if self.is_full():\n            return False\n        self.rear = (self.rear + 1) % self.capacity\n        self.items[self.rear] = item\n        self.size += 1\n        return True\n\n    # Dequeue\n    def dequeue(self):\n        if self.is_empty():\n            return None\n        item = self.items[self.front]\n        self.front = (self.front + 1) % self.capacity\n        self.size -= 1\n        return item\n\n    # Check if empty\n    def is_empty(self):\n        return self.size == 0\n\n    # Check if full\n    def is_full(self):\n        return self.size == self.capacity\n\n    # Peek front\n    def peek(self):\n        if self.is_empty():\n            return None\n        return self.items[self.front]\n\n// Priority Queue\nclass PriorityQueue:\n    def __init__(self):\n        self.items = []\n\n    # Enqueue with priority\n    def enqueue(self, item, priority):\n        self.items.append((item, priority))\n        self.items.sort(key=lambda x: x[1])\n\n    # Dequeue highest priority\n    def dequeue(self):\n        if self.is_empty():\n            return None\n        return self.items.pop(0)[0]\n\n    # Check if empty\n    def is_empty(self):\n        return len(self.items) == 0\n\n    # Get size\n    def size(self):\n        return len(self.items)\n\n    # Peek highest priority\n    def peek(self):\n        if self.is_empty():\n            return None\n        return self.items[0][0]\n\n// Double-Ended Queue (Deque)\nclass Deque:\n    def __init__(self):\n        self.items = []\n\n    # Add to front\n    def add_front(self, item):\n        self.items.insert(0, item)\n\n    # Add to rear\n    def add_rear(self, item):\n        self.items.append(item)\n\n    # Remove from front\n    def remove_front(self):\n        if self.is_empty():\n            return None\n        return self.items.pop(0)\n\n    # Remove from rear\n    def remove_rear(self):\n        if self.is_empty():\n            return None\n        return self.items.pop()\n\n    # Check if empty\n    def is_empty(self):\n        return len(self.items) == 0\n\n    # Get size\n    def size(self):\n        return len(self.items)\n\n    # Peek front\n    def peek_front(self):\n        if self.is_empty():\n            return None\n        return self.items[0]\n\n    # Peek rear\n    def peek_rear(self):\n        if self.is_empty():\n            return None\n        return self.items[-1]",
    "keySteps": []
  },
  "queue-implementation": {
    "name": "Queue Implementation",
    "type": "1",
    "description": "Queue Implementation is an algorithm with time complexity O(1). It is primarily used for fifo data structure",
    "timeComplexity": "O(1) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: FIFO data structure\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: FIFO data structure\n    ",
    "useCase": "FIFO data structure\n    ",
    "pseudocode": "QUEUE-EMPTY(Q)\n    if Q.head = Q.tail\n        then return true\n        else return false\n\nQUEUE-FULL(Q)\n    if Q.head = Q.tail + 1 or (Q.head = 1 and Q.tail = Q.size)\n        then return true\n        else return false\n\nENQUEUE(Q, x)\n    if QUEUE-FULL(Q)\n        then error \"queue overflow\"\n    Q[Q.tail] \u2190 x\n    if Q.tail = Q.size\n        then Q.tail \u2190 1\n        else Q.tail \u2190 Q.tail + 1\n\nDEQUEUE(Q)\n    if QUEUE-EMPTY(Q)\n        then error \"queue underflow\"\n    x \u2190 Q[Q.head]\n    if Q.head = Q.size\n        then Q.head \u2190 1\n        else Q.head \u2190 Q.head + 1\n    return x\n\n// Example:\n// Input: Operations [ENQUEUE(10), ENQUEUE(20), DEQUEUE(), ENQUEUE(30), ENQUEUE(40)]\n//\n// Initial state:\n//   Q = []\n//   Q.head = 1\n//   Q.tail = 1\n//\n// After ENQUEUE(10):\n//   Q = [10]\n//   Q.head = 1\n//   Q.tail = 2\n//\n// After ENQUEUE(20):\n//   Q = [10, 20]\n//   Q.head = 1\n//   Q.tail = 3\n//\n// After DEQUEUE():\n//   Q = [20]\n//   Q.head = 2\n//   Q.tail = 3\n//   Returns: 10\n//\n// After ENQUEUE(30):\n//   Q = [20, 30]\n//   Q.head = 2\n//   Q.tail = 4\n//\n// After ENQUEUE(40):\n//   Q = [20, 30, 40]\n//   Q.head = 2\n//   Q.tail = 5\n//\n// Final state:\n//   Q = [20, 30, 40]\n//   Q.head = 2\n//   Q.tail = 5",
    "keySteps": [
      "Initialize: Create array and head/tail pointers",
      "Enqueue: Add element at tail and update pointer",
      "Dequeue: Remove element from head and update pointer"
    ]
  },
  "probability-dp": {
    "name": "Probability DP",
    "type": "n\u00b7k",
    "description": "Probability DP is an algorithm with time complexity O(n\u00b7k). It is primarily used for calculate probability of events",
    "timeComplexity": "O(n\u00b7k) &nbsp;|&nbsp; Space: O(n\u00b7k) &nbsp;|&nbsp; Use: Calculate probability of events\n    ",
    "spaceComplexity": "O(n\u00b7k) &nbsp;|&nbsp; Use: Calculate probability of events\n    ",
    "useCase": "Calculate probability of events\n    ",
    "pseudocode": "PROBABILITY-DP(n, k, p)\n    let dp[0\u2025n][0\u2025k] be a new array\n    for i \u2190 0 to n\n        do for j \u2190 0 to k\n            do dp[i][j] \u2190 -1\n    return CALC-PROB(n, k, p, dp)\n\nCALC-PROB(n, k, p, dp)\n    if n = 0\n        then if k = 0\n                then return 1\n                else return 0\n    if k < 0\n        then return 0\n    if dp[n][k] \u2260 -1\n        then return dp[n][k]\n\n    let prob \u2190 p \u00b7 CALC-PROB(n-1, k-1, p, dp) + (1-p) \u00b7 CALC-PROB(n-1, k, p, dp)\n    dp[n][k] \u2190 prob\n    return prob\n\n// Example:\n// Input: n = 3, k = 2, p = 0.5\n//\n// Initial call: n = 3, k = 2\n//\n// For n = 3:\n//   prob = 0.5\u00b7CALC-PROB(2,1) + 0.5\u00b7CALC-PROB(2,2)\n//\n// For n = 2:\n//   prob = 0.5\u00b7CALC-PROB(1,0) + 0.5\u00b7CALC-PROB(1,1)\n//\n// For n = 1:\n//   prob = 0.5\u00b7CALC-PROB(0,-1) + 0.5\u00b7CALC-PROB(0,0)\n//\n// Base cases:\n//   CALC-PROB(0,0) = 1\n//   CALC-PROB(0,-1) = 0\n//\n// Output: Probability of exactly 2 successes in 3 trials",
    "keySteps": [
      "Initialize: Create DP table for memoization",
      "Base Cases: Handle terminal conditions",
      "Recurse: Calculate probability using previous states"
    ]
  },
  "prims-algorithm": {
    "name": "Prim's Algorithm",
    "type": "--gradient-from",
    "description": "Prim's Algorithm is an algorithm with time complexity O(E log V). It is primarily used for finding minimum spanning tree",
    "timeComplexity": "O(E log V) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree\n    ",
    "useCase": "Finding minimum spanning tree\n    ",
    "pseudocode": "// Standard Prim's Algorithm\ndef prim(graph):\n    # Initialize MST and priority queue\n    mst = []\n    visited = set()\n    heap = [(0, None, next(iter(graph)))]  # (weight, parent, vertex)\n\n    while heap:\n        weight, parent, u = heapq.heappop(heap)\n        if u in visited:\n            continue\n\n        visited.add(u)\n        if parent is not None:\n            mst.append((parent, u, weight))\n\n        # Add adjacent vertices to heap\n        for v, w in graph[u].items():\n            if v not in visited:\n                heapq.heappush(heap, (w, u, v))\n\n    return mst\n\n// Prim's with Priority Queue\ndef prim_pq(graph):\n    mst = []\n    visited = set()\n    heap = [(0, None, next(iter(graph)))]\n\n    while heap:\n        weight, parent, u = heapq.heappop(heap)\n        if u in visited:\n            continue\n\n        visited.add(u)\n        if parent is not None:\n            mst.append((parent, u, weight))\n\n        for v, w in graph[u].items():\n            if v not in visited:\n                heapq.heappush(heap, (w, u, v))\n\n    return mst\n\n// Prim's with Fibonacci Heap\ndef prim_fh(graph):\n    mst = []\n    visited = set()\n    heap = FibonacciHeap()\n    heap.insert(next(iter(graph)), 0)\n\n    while not heap.is_empty():\n        u = heap.extract_min()\n        visited.add(u)\n\n        for v, w in graph[u].items():\n            if v not in visited:\n                if v not in heap:\n                    heap.insert(v, w)\n                elif w < heap.get_key(v):\n                    heap.decrease_key(v, w)\n\n    return mst",
    "keySteps": []
  },
  "prime-factorization": {
    "name": "Prime Factorization",
    "type": "Algorithm",
    "description": "Prime Factorization is an algorithm with time complexity O(\u221an). It is primarily used for decompose number into prime       factors",
    "timeComplexity": "O(\u221an) &nbsp;|&nbsp; Space: O(log n) &nbsp;|&nbsp; Use: Decompose number into prime\n      factors\n    ",
    "spaceComplexity": "O(log n) &nbsp;|&nbsp; Use: Decompose number into prime\n      factors\n    ",
    "useCase": "Decompose number into prime\n      factors\n    ",
    "pseudocode": "PRIME-FACTORS(n)\n  factors = []\n  // Handle even numbers\n  while n mod 2 == 0\n    factors.append(2)\n    n = n / 2\n  // Check odd numbers up to sqrt(n)\n  i = 3\n  while i * i <= n\n    while n mod i == 0\n      factors.append(i)\n      n = n / i\n    i = i + 2\n  // If n is a prime number > 2\n  if n > 2\n    factors.append(n)\n  return factors\n\n// Example:\n// Input: n = 60\n// Step 1: 60 \u00f7 2 = 30, factors = [2]\n// Step 2: 30 \u00f7 2 = 15, factors = [2, 2]\n// Step 3: 15 \u00f7 3 = 5, factors = [2, 2, 3]\n// Step 4: 5 \u00f7 5 = 1, factors = [2, 2, 3, 5]\n// Output: [2, 2, 3, 5]",
    "keySteps": [
      "Handle: Even numbers (factor of 2)",
      "Check: Odd numbers up to \u221an",
      "Add: Remaining prime factor if &gt; 2"
    ]
  },
  "prefix-sums": {
    "name": "Prefix Sums",
    "type": "Algorithm",
    "description": "Prefix Sums is an algorithm with time complexity O(n). It is primarily used for range sum queries",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Range sum queries\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Range sum queries\n    ",
    "useCase": "Range sum queries\n    ",
    "pseudocode": "PREFIX-SUMS(A)\n    let n be the length of A\n    let prefix[0\u2025n] be a new array\n    prefix[0] \u2190 0\n\n    for i \u2190 1 to n\n        do prefix[i] \u2190 prefix[i-1] + A[i]\n\n    return prefix\n\nRANGE-SUM(prefix, l, r)\n    return prefix[r] - prefix[l-1]\n\n// Example:\n// Input: A = [1, 2, 3, 4, 5]\n//\n// prefix[0] = 0\n// prefix[1] = 0 + 1 = 1\n// prefix[2] = 1 + 2 = 3\n// prefix[3] = 3 + 3 = 6\n// prefix[4] = 6 + 4 = 10\n// prefix[5] = 10 + 5 = 15\n//\n// Range sum from index 2 to 4:\n// RANGE-SUM(prefix, 2, 4) = prefix[4] - prefix[1] = 10 - 1 = 9\n//\n// Output: prefix = [0, 1, 3, 6, 10, 15]",
    "keySteps": [
      "Initialize: Create prefix array with size n+1",
      "Compute: Cumulative sums in prefix array",
      "Query: Calculate range sums using prefix differences"
    ]
  },
  "palindrome-partitioning": {
    "name": "Palindrome Partitioning",
    "type": "n * 2^n",
    "description": "Palindrome Partitioning is an algorithm with time complexity O(n * 2^n). It is primarily used for finding all possible palindrome       partitions",
    "timeComplexity": "O(n * 2^n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Finding all possible palindrome\n      partitions\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Finding all possible palindrome\n      partitions\n    ",
    "useCase": "Finding all possible palindrome\n      partitions\n    ",
    "pseudocode": "// Check if string is palindrome\nIS-PALINDROME(s, start, end):\n  while start < end:\n    if s[start] != s[end]:\n      return false\n    start += 1\n    end -= 1\n  return true\n\n// Main partitioning function\nPALINDROME-PARTITION(s):\n  result = []\n  current = []\n  \n  function BACKTRACK(start):\n    if start == len(s):\n      result.append(current.copy())\n      return\n    \n    for end in range(start, len(s)):\n      if IS-PALINDROME(s, start, end):\n        current.append(s[start:end+1])\n        BACKTRACK(end + 1)\n        current.pop()\n  \n  BACKTRACK(0)\n  return result",
    "keySteps": [
      "Uses backtracking to explore all possible partitions",
      "Can be optimized with dynamic programming for minimum cuts",
      "Useful for string manipulation and text analysis"
    ]
  },
  "null-pattern": {
    "name": "Null Pattern",
    "type": "Design Pattern",
    "description": "A design pattern that provides a default behavior for null objects",
    "timeComplexity": "O(1) for null checks and property access",
    "spaceComplexity": "O(1) for storing null object reference",
    "useCase": "Handle null/undefined values gracefully, prevent null pointer exceptions",
    "pseudocode": "# Null Pattern: Handle null/undefined values gracefully\n# Input: Object that may be null\n# Output: Safe access to object properties\n\nAlgorithm NULL-PATTERN(object)\n    if object = null then\n        return null\n    end if\n    \n    # Safe access to properties\n    result \u2190 object.property\n    \n    # Safe method calls\n    if object.method \u2260 null then\n        result \u2190 object.method()\n    end if\n    \n    return result\n\n# Example:\n# Input: object = null\n# Output: null\n#\n# Input: object = { property: \"value\", method: () => \"result\" }\n# Output: \"result\"",
    "keySteps": [
      "Check if the object is null before accessing properties",
      "Provide default behavior for null objects",
      "Implement safe method calls with null checks",
      "Return appropriate default values when object is null"
    ]
  },
  "network-flow": {
    "name": "Network Flow",
    "type": "V\u00b2E",
    "description": "Network Flow is an algorithm with time complexity O(V\u00b2E). It is primarily used for find maximum flow in a network",
    "timeComplexity": "O(V\u00b2E) &nbsp;|&nbsp; Space: O(V\u00b2) &nbsp;|&nbsp; Use: Find maximum flow in a network\n    ",
    "spaceComplexity": "O(V\u00b2) &nbsp;|&nbsp; Use: Find maximum flow in a network\n    ",
    "useCase": "Find maximum flow in a network\n    ",
    "pseudocode": "FORD-FULKERSON(G, s, t)\n1  for each edge (u,v) \u2208 G.E\n2      (u,v).f = 0\n3  while there exists a path p from s to t in residual network Gf\n4      cf(p) = min{cf(u,v) : (u,v) is in p}\n5      for each edge (u,v) in p\n6          if (u,v) \u2208 E\n7              (u,v).f = (u,v).f + cf(p)\n8          else\n9              (v,u).f = (v,u).f - cf(p)\n\nEDMONDS-KARP(G, s, t)\n1  for each edge (u,v) \u2208 G.E\n2      (u,v).f = 0\n3  while there exists a path p from s to t in residual network Gf\n4      cf(p) = min{cf(u,v) : (u,v) is in p}\n5      for each edge (u,v) in p\n6          if (u,v) \u2208 E\n7              (u,v).f = (u,v).f + cf(p)\n8          else\n9              (v,u).f = (v,u).f - cf(p)\n\nDINIC(G, s, t)\n1  for each edge (u,v) \u2208 G.E\n2      (u,v).f = 0\n3  while BFS(Gf, s, t) finds a path\n4      while DFS(Gf, s, t, \u221e) finds a blocking flow\n5          for each edge (u,v) in blocking flow\n6              if (u,v) \u2208 E\n7                  (u,v).f = (u,v).f + cf(p)\n8              else\n9                  (v,u).f = (v,u).f - cf(p)\n\n// Example:\n// Input: G = (V, E) where\n// V = {s, a, b, c, d, t}\n// E = {(s,a,10), (s,b,5), (a,b,2), (a,c,5), (b,c,8), (b,d,4), (c,t,7), (d,t,10)}\n//\n// Step 1: Initial flow = 0\n// Step 2: Find augmenting path s->a->c->t with flow 5\n// Step 3: Find augmenting path s->b->d->t with flow 4\n// Step 4: Find augmenting path s->a->b->c->t with flow 2\n//\n// Final flow: 11",
    "keySteps": [
      "Initialize: Set all flows to 0",
      "Find: Augmenting path in residual network",
      "Update: Flow along the path"
    ]
  },
  "monotonic-stack": {
    "name": "Monotonic Stack",
    "type": "Algorithm",
    "description": "Monotonic Stack is an algorithm with time complexity O(n). It is primarily used for next greater/smaller element",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Next greater/smaller element\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Next greater/smaller element\n    ",
    "useCase": "Next greater/smaller element\n    ",
    "pseudocode": "// Next greater element\nNEXT-GREATER-ELEMENT(A):\n    n \u2190 length[A]\n    S \u2190 empty stack\n    result[1..n] \u2190 -1\n    for i \u2190 1 to n:\n        while S not empty and A[TOP(S)] < A[i]:\n            result[POP(S)] \u2190 A[i]\n        PUSH(S, i)\n    return result\n\n// Next smaller element\nNEXT-SMALLER-ELEMENT(A):\n    n \u2190 length[A]\n    S \u2190 empty stack\n    result[1..n] \u2190 -1\n    for i \u2190 1 to n:\n        while S not empty and A[TOP(S)] > A[i]:\n            result[POP(S)] \u2190 A[i]\n        PUSH(S, i)\n    return result\n\n// Previous greater element\nPREVIOUS-GREATER-ELEMENT(A):\n    n \u2190 length[A]\n    S \u2190 empty stack\n    result[1..n] \u2190 -1\n    for i \u2190 n downto 1:\n        while S not empty and A[TOP(S)] < A[i]:\n            result[POP(S)] \u2190 A[i]\n        PUSH(S, i)\n    return result\n\n// Previous smaller element\nPREVIOUS-SMALLER-ELEMENT(A):\n    n \u2190 length[A]\n    S \u2190 empty stack\n    result[1..n] \u2190 -1\n    for i \u2190 n downto 1:\n        while S not empty and A[TOP(S)] > A[i]:\n            result[POP(S)] \u2190 A[i]\n        PUSH(S, i)\n    return result\n\n// Example:\n// Input: A = [4, 5, 2, 10, 8]\n//\n// NEXT-GREATER-ELEMENT(A):\n//   i = 1: S = [1], result = [-1, -1, -1, -1, -1]\n//   i = 2: S = [2], result = [5, -1, -1, -1, -1]\n//   i = 3: S = [2, 3], result = [5, -1, -1, -1, -1]\n//   i = 4: S = [4], result = [5, 10, 10, -1, -1]\n//   i = 5: S = [4, 5], result = [5, 10, 10, -1, -1]\n//   Final result: [5, 10, 10, -1, -1]",
    "keySteps": [
      "Initialize: Create empty stack and result array",
      "Process: Maintain monotonic property while processing elements",
      "Update: Store results for popped elements"
    ]
  },
  "monotonic-queue": {
    "name": "Monotonic Queue",
    "type": "Algorithm",
    "description": "Monotonic Queue is an algorithm with time complexity O(n). It is primarily used for sliding window maximum/minimum",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(k) &nbsp;|&nbsp; Use: Sliding window maximum/minimum\n    ",
    "spaceComplexity": "O(k) &nbsp;|&nbsp; Use: Sliding window maximum/minimum\n    ",
    "useCase": "Sliding window maximum/minimum\n    ",
    "pseudocode": "SLIDING-WINDOW-MAXIMUM(A, k)\n    let n be the length of A\n    let result[1\u2025n-k+1] be a new array\n    let Q be a new empty deque\n\n    for i \u2190 1 to n\n        do while Q is not empty and A[Q.back()] \u2264 A[i]\n            do Q.pop_back()\n            Q.push_back(i)\n            if Q.front() = i - k\n                then Q.pop_front()\n            if i \u2265 k\n                then result[i-k+1] \u2190 A[Q.front()]\n\n    return result\n\n// Example:\n// Input: A = [1, 3, -1, -3, 5, 3, 6, 7], k = 3\n//\n// i = 1: A[1] = 1\n//   Q = [1]\n//\n// i = 2: A[2] = 3\n//   Q = [2]\n//\n// i = 3: A[3] = -1\n//   Q = [2,3]\n//   result[1] = 3\n//\n// i = 4: A[4] = -3\n//   Q = [2,3,4]\n//   result[2] = 3\n//\n// i = 5: A[5] = 5\n//   Q = [5]\n//   result[3] = 5\n//\n// i = 6: A[6] = 3\n//   Q = [5,6]\n//   result[4] = 5\n//\n// i = 7: A[7] = 6\n//   Q = [7]\n//   result[5] = 6\n//\n// i = 8: A[8] = 7\n//   Q = [8]\n//   result[6] = 7\n//\n// Output: [3, 3, 5, 5, 6, 7]",
    "keySteps": [
      "Initialize: Create result array and empty deque",
      "Process: Maintain monotonic deque while sliding window",
      "Update: Remove elements outside window and smaller values"
    ]
  },
  "miller-rabin-primality-test": {
    "name": "Miller-Rabin Primality Test",
    "type": "Number Theory",
    "description": "Miller-Rabin Primality Test is an algorithm with time complexity O(k log\u00b3 n). It is primarily used for probabilistic primality test",
    "timeComplexity": "O(k log\u00b3 n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Probabilistic primality test\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Probabilistic primality test\n    ",
    "useCase": "Probabilistic primality test\n    ",
    "pseudocode": "# Miller-Rabin Primality Test\n# Input: Integer n > 2, number of rounds k\n# Output: \"composite\" or \"probably prime\"\n\nAlgorithm MILLER-RABIN-PRIMALITY-TEST(n, k)\n    # Handle edge cases\n    if n \u2264 1 then\n        return \"composite\"\n    if n \u2264 3 then\n        return \"prime\"\n    if n mod 2 = 0 then\n        return \"composite\"\n\n    # Write n-1 as d\u00b72^s\n    d \u2190 n - 1\n    s \u2190 0\n    while d mod 2 = 0 do\n        d \u2190 d / 2\n        s \u2190 s + 1\n    end while\n\n    # Test k times\n    for i \u2190 1 to k do\n        a \u2190 random integer in [2, n-2]\n        x \u2190 a^d mod n\n        if x = 1 or x = n-1 then\n            continue\n        end if\n\n        for j \u2190 1 to s-1 do\n            x \u2190 x\u00b2 mod n\n            if x = n-1 then\n                break\n            end if\n            if x = 1 then\n                return \"composite\"\n            end if\n        end for\n\n        if x \u2260 n-1 then\n            return \"composite\"\n        end if\n    end for\n\n    return \"probably prime\"\n\n# Example:\n# Input: n = 17, k = 5\n#\n# Step 1: n-1 = 16 = 1\u00b72^4\n#         d = 1, s = 4\n#\n# Round 1: a = 2\n#          x = 2^1 mod 17 = 2\n#          x\u00b2 mod 17 = 4\n#          x\u00b2 mod 17 = 16 = n-1\n#          continue\n#\n# Round 2: a = 3\n#          x = 3^1 mod 17 = 3\n#          x\u00b2 mod 17 = 9\n#          x\u00b2 mod 17 = 13\n#          x\u00b2 mod 17 = 16 = n-1\n#          continue\n#\n# ... (3 more rounds)\n#\n# Output: \"probably prime\"",
    "keySteps": [
      "Handle edge cases (n \u2264 1, n \u2264 3, even numbers)",
      "Factor n-1 into d\u00b72^s",
      "Choose random base a",
      "Test for strong pseudoprimes"
    ]
  },
  "merge-sort": {
    "name": "Merge Sort",
    "type": "n log n",
    "description": "Merge Sort is an algorithm with time complexity O(n log n). It is primarily used for stable sorting of arrays",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Stable sorting of arrays\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Stable sorting of arrays\n    ",
    "useCase": "Stable sorting of arrays\n    ",
    "pseudocode": "// Main merge sort function\nMERGE-SORT(array, start, end):\n    # If array has more than one element\n    if start < end:\n        # Find middle point\n        middle = floor of (start + end) / 2\n\n        # Sort left half\n        MERGE-SORT(array, start, middle)\n        # Sort right half\n        MERGE-SORT(array, middle + 1, end)\n        # Merge sorted halves\n        MERGE(array, start, middle, end)\n\n// Helper function to merge two sorted arrays\nMERGE(array, start, middle, end):\n    # Calculate sizes of left and right arrays\n    left_size = middle - start + 1\n    right_size = end - middle\n\n    # Create temporary arrays\n    left = new array of size left_size + 1\n    right = new array of size right_size + 1\n\n    # Copy data to temporary arrays\n    for i from 1 to left_size:\n        left[i] = array[start + i - 1]\n\n    for j from 1 to right_size:\n        right[j] = array[middle + j]\n\n    # Add sentinel values\n    left[left_size + 1] = infinity\n    right[right_size + 1] = infinity\n\n    # Merge the temporary arrays\n    i = 1\n    j = 1\n\n    for k from start to end:\n        if left[i] \u2264 right[j]:\n            array[k] = left[i]\n            i = i + 1\n        else:\n            array[k] = right[j]\n            j = j + 1",
    "keySteps": []
  },
  "memoization": {
    "name": "Memoization",
    "type": "Dynamic Programming",
    "description": "Memoization is an algorithm with time complexity O(n). It is primarily used for store computed results to avoid       redundant calculations",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Store computed results to avoid\n      redundant calculations\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Store computed results to avoid\n      redundant calculations\n    ",
    "useCase": "Store computed results to avoid\n      redundant calculations\n    ",
    "pseudocode": "# Memoization: Store computed results to avoid redundant calculations\n# Input: Function f with parameters, memoization table\n# Output: Result of function with parameters\n\nAlgorithm MEMOIZED-FIBONACCI(n)\n    # Initialize memoization table\n    memo \u2190 array of size n + 1\n    for i \u2190 0 to n do\n        memo[i] \u2190 -1\n    end for\n\n    # Helper function with memoization\n    function FIB(n)\n        if n \u2264 1 then\n            return n\n        end if\n\n        if memo[n] \u2260 -1 then\n            return memo[n]\n        end if\n\n        memo[n] \u2190 FIB(n - 1) + FIB(n - 2)\n        return memo[n]\n    end function\n\n    return FIB(n)\n\n# Example:\n# Input: n = 5\n#\n# Step 1: memo = [-1, -1, -1, -1, -1, -1]\n# Step 2: FIB(5)\n#         FIB(4) + FIB(3)\n#         (FIB(3) + FIB(2)) + (FIB(2) + FIB(1))\n#         ((FIB(2) + FIB(1)) + (FIB(1) + FIB(0))) + ((FIB(1) + FIB(0)) + 1)\n#         (((FIB(1) + FIB(0)) + 1) + (1 + 0)) + ((1 + 0) + 1)\n#         (((1 + 0) + 1) + (1 + 0)) + ((1 + 0) + 1)\n#         memo = [0, 1, 1, 2, 3, 5]\n#\n# Output: 5",
    "keySteps": [
      "Initialize memoization table",
      "Check if result exists in table",
      "Compute and store result if not found",
      "Return stored result"
    ]
  },
  "maximum-bipartite-matching": {
    "name": "Maximum Bipartite Matching",
    "type": "Algorithm",
    "description": "Maximum Bipartite Matching is an algorithm with time complexity O(VE). It is primarily used for find maximum matching in bipartite       graph",
    "timeComplexity": "O(VE) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find maximum matching in bipartite\n      graph\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find maximum matching in bipartite\n      graph\n    ",
    "useCase": "Find maximum matching in bipartite\n      graph\n    ",
    "pseudocode": "// Maximum bipartite matching using Ford-Fulkerson\nMAX-BIPARTITE-MATCHING(G):\n    // G is a bipartite graph with partitions L and R\n    // Add source s and sink t\n    s \u2190 new vertex\n    t \u2190 new vertex\n    for each u \u2208 L:\n        add edge (s, u)\n    for each v \u2208 R:\n        add edge (v, t)\n    // Find maximum flow\n    return FORD-FULKERSON(G, s, t)\n\n// Ford-Fulkerson algorithm\nFORD-FULKERSON(G, s, t):\n    for each edge (u, v) \u2208 G.E:\n        f[u, v] \u2190 0\n        f[v, u] \u2190 0\n    while there exists a path p from s to t in residual network Gf:\n        cf(p) \u2190 min{cf(u, v) : (u, v) is in p}\n        for each edge (u, v) in p:\n            f[u, v] \u2190 f[u, v] + cf(p)\n            f[v, u] \u2190 -f[u, v]\n    return f\n\n// Example:\n// Input: G = (L \u222a R, E), where\n// L = {1, 2, 3}, R = {4, 5, 6}\n// E = {(1,4), (1,5), (2,5), (3,4), (3,6)}\n//\n// Execution:\n// 1. Add source s and sink t\n// 2. Add edges: (s,1), (s,2), (s,3), (4,t), (5,t), (6,t)\n// 3. Find augmenting paths:\n//    - s\u21921\u21924\u2192t\n//    - s\u21922\u21925\u2192t\n//    - s\u21923\u21926\u2192t\n//\n// Output: Matching = {(1,4), (2,5), (3,6)}",
    "keySteps": [
      "Transform: Convert to flow network",
      "Find: Maximum flow using Ford-Fulkerson",
      "Extract: Matching from flow solution"
    ]
  },
  "matrix-traversal": {
    "name": "Matrix Traversal",
    "type": "Algorithm",
    "description": "Matrix Traversal is an algorithm with time complexity O(mn). It is primarily used for traverse 2d matrix in various       patterns",
    "timeComplexity": "O(mn) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Traverse 2D matrix in various\n      patterns\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Traverse 2D matrix in various\n      patterns\n    ",
    "useCase": "Traverse 2D matrix in various\n      patterns\n    ",
    "pseudocode": "// Matrix traversal patterns\nMATRIX-TRAVERSE(A):\n    m \u2190 rows[A]\n    n \u2190 columns[A]\n\n    // Row-wise traversal\n    for i \u2190 1 to m:\n        for j \u2190 1 to n:\n            process A[i, j]\n\n    // Column-wise traversal\n    for j \u2190 1 to n:\n        for i \u2190 1 to m:\n            process A[i, j]\n\n    // Diagonal traversal\n    for d \u2190 1 to m + n - 1:\n        for i \u2190 max(1, d - n + 1) to min(d, m):\n            j \u2190 d - i + 1\n            process A[i, j]\n\n// Example:\n// Input: A = [\n//   [1, 2, 3],\n//   [4, 5, 6],\n//   [7, 8, 9]\n// ]\n//\n// Row-wise: 1, 2, 3, 4, 5, 6, 7, 8, 9\n// Column-wise: 1, 4, 7, 2, 5, 8, 3, 6, 9\n// Diagonal: 1, 2, 4, 3, 5, 7, 6, 8, 9",
    "keySteps": [
      "Initialize: Get matrix dimensions",
      "Traverse: Process elements in desired pattern",
      "Process: Apply operation to each element"
    ]
  },
  "matrix-traversal-recursive": {
    "name": "Recursive Matrix Traversal",
    "type": "Algorithm",
    "description": "Recursive Matrix Traversal is an algorithm with time complexity O(mn). It is primarily used for recursive matrix traversal",
    "timeComplexity": "O(mn) &nbsp;|&nbsp; Space: O(m+n) &nbsp;|&nbsp; Use: Recursive matrix traversal\n    ",
    "spaceComplexity": "O(m+n) &nbsp;|&nbsp; Use: Recursive matrix traversal\n    ",
    "useCase": "Recursive matrix traversal\n    ",
    "pseudocode": "DFS-TRAVERSE(A, i, j, visited)\n    let m, n be the dimensions of A\n    if i < 1 or i > m or j < 1 or j > n or visited[i, j] = TRUE\n        then return\n\n    visited[i, j] \u2190 TRUE\n    result \u2190 A[i, j]\n\n    // Visit adjacent cells\n    DFS-TRAVERSE(A, i-1, j, visited)    // Up\n    DFS-TRAVERSE(A, i+1, j, visited)    // Down\n    DFS-TRAVERSE(A, i, j-1, visited)    // Left\n    DFS-TRAVERSE(A, i, j+1, visited)    // Right\n\n    return result\n\nRECURSIVE-TRAVERSE(A)\n    let m, n be the dimensions of A\n    let visited[1\u2025m, 1\u2025n] be a new array\n    let result[1\u2025m\u00b7n] be a new array\n    let idx \u2190 1\n\n    for i \u2190 1 to m\n        do for j \u2190 1 to n\n            do visited[i, j] \u2190 FALSE\n\n    for i \u2190 1 to m\n        do for j \u2190 1 to n\n            do if visited[i, j] = FALSE\n                then result[idx] \u2190 DFS-TRAVERSE(A, i, j, visited)\n                    idx \u2190 idx + 1\n\n    return result\n\n// Example:\n// Input: A = [1 2 3]\n//            [4 5 6]\n//            [7 8 9]\n//\n// Starting from (1,1):\n// 1. Visit (1,1) = 1\n// 2. Visit (2,1) = 4\n// 3. Visit (3,1) = 7\n// 4. Visit (3,2) = 8\n// 5. Visit (3,3) = 9\n// 6. Visit (2,3) = 6\n// 7. Visit (2,2) = 5\n// 8. Visit (1,2) = 2\n// 9. Visit (1,3) = 3\n//\n// Output: [1, 4, 7, 8, 9, 6, 5, 2, 3]",
    "keySteps": [
      "Initialize: Create visited matrix and result array",
      "DFS: Recursively visit unvisited adjacent cells",
      "Collect: Store visited values in result array"
    ]
  },
  "matrix-spiral-traversal": {
    "name": "Matrix Spiral Traversal",
    "type": "Algorithm",
    "description": "Matrix Spiral Traversal is an algorithm with time complexity O(mn). It is primarily used for traverse matrix in spiral order",
    "timeComplexity": "O(mn) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Traverse matrix in spiral order\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Traverse matrix in spiral order\n    ",
    "useCase": "Traverse matrix in spiral order\n    ",
    "pseudocode": "SPIRAL-TRAVERSE(A)\n    let m, n be the dimensions of A\n    let result[1\u2025m\u00b7n] be a new array\n    let top \u2190 1, bottom \u2190 m\n    let left \u2190 1, right \u2190 n\n    let idx \u2190 1\n\n    while top \u2264 bottom and left \u2264 right\n        do for i \u2190 left to right\n            do result[idx] \u2190 A[top, i]\n                idx \u2190 idx + 1\n            top \u2190 top + 1\n\n            for i \u2190 top to bottom\n                do result[idx] \u2190 A[i, right]\n                    idx \u2190 idx + 1\n                right \u2190 right - 1\n\n                if top \u2264 bottom\n                    then for i \u2190 right downto left\n                        do result[idx] \u2190 A[bottom, i]\n                            idx \u2190 idx + 1\n                        bottom \u2190 bottom - 1\n\n                        if left \u2264 right\n                            then for i \u2190 bottom downto top\n                                do result[idx] \u2190 A[i, left]\n                                    idx \u2190 idx + 1\n                                left \u2190 left + 1\n    return result\n\n// Example:\n// Input: A = [1  2  3  4]\n//            [5  6  7  8]\n//            [9 10 11 12]\n//\n// Traversal order:\n// 1. Top row: 1, 2, 3, 4\n// 2. Right column: 8, 12\n// 3. Bottom row: 11, 10, 9\n// 4. Left column: 5\n// 5. Middle: 6, 7\n//\n// Output: [1, 2, 3, 4, 8, 12, 11, 10, 9, 5, 6, 7]",
    "keySteps": [
      "Initialize: Set boundaries for spiral traversal",
      "Traverse: Move right, down, left, up in spiral pattern",
      "Update: Adjust boundaries after each complete spiral"
    ]
  },
  "matrix-spiral-recursive": {
    "name": "Matrix Spiral Traversal (Recursive)",
    "type": "Algorithm",
    "description": "Matrix Spiral Traversal (Recursive) is an algorithm with time complexity O(mn). It is primarily used for matrix traversal in spiral order",
    "timeComplexity": "O(mn) &nbsp;|&nbsp; Space: O(mn) &nbsp;|&nbsp; Use: Matrix traversal in spiral order\n    ",
    "spaceComplexity": "O(mn) &nbsp;|&nbsp; Use: Matrix traversal in spiral order\n    ",
    "useCase": "Matrix traversal in spiral order\n    ",
    "pseudocode": "// Recursive spiral traversal of matrix\nSPIRAL-TRAVERSE(A, top, bottom, left, right):\n    if top > bottom or left > right:\n        return\n    // Traverse top row\n    for i \u2190 left to right:\n        print A[top, i]\n    // Traverse right column\n    for i \u2190 top + 1 to bottom:\n        print A[i, right]\n    if top < bottom and left < right:\n        // Traverse bottom row\n        for i \u2190 right - 1 downto left:\n            print A[bottom, i]\n        // Traverse left column\n        for i \u2190 bottom - 1 downto top + 1:\n            print A[i, left]\n    // Recursively traverse inner matrix\n    SPIRAL-TRAVERSE(A, top + 1, bottom - 1, left + 1, right - 1)\n\n// Example:\n// Input: A = [\n//   [1, 2, 3, 4],\n//   [5, 6, 7, 8],\n//   [9, 10, 11, 12]\n// ]\n//\n// Execution:\n// 1. Outer layer: 1, 2, 3, 4, 8, 12, 11, 10, 9, 5\n// 2. Inner layer: 6, 7\n//\n// Output: [1, 2, 3, 4, 8, 12, 11, 10, 9, 5, 6, 7]",
    "keySteps": [
      "Base case: Check if traversal is complete",
      "Traverse: Process outer layer in spiral order",
      "Recurse: Process inner matrix with updated boundaries"
    ]
  },
  "matrix-operations": {
    "name": "Matrix Operations",
    "type": "Algorithm",
    "description": "Matrix Operations is an algorithm with time complexity O(n\u00b3). It is primarily used for matrix multiplication and operations",
    "timeComplexity": "O(n\u00b3) &nbsp;|&nbsp; Space: O(n\u00b2) &nbsp;|&nbsp; Use: Matrix multiplication and operations\n    ",
    "spaceComplexity": "O(n\u00b2) &nbsp;|&nbsp; Use: Matrix multiplication and operations\n    ",
    "useCase": "Matrix multiplication and operations\n    ",
    "pseudocode": "MATRIX-MULTIPLY(A, B)\n    let m, n, p be the dimensions of A and B\n    let C[1\u2025m, 1\u2025p] be a new matrix\n    for i \u2190 1 to m\n        do for j \u2190 1 to p\n            do C[i, j] \u2190 0\n                for k \u2190 1 to n\n                    do C[i, j] \u2190 C[i, j] + A[i, k] \u00b7 B[k, j]\n    return C\n\nMATRIX-TRANSPOSE(A)\n    let m, n be the dimensions of A\n    let B[1\u2025n, 1\u2025m] be a new matrix\n    for i \u2190 1 to m\n        do for j \u2190 1 to n\n            do B[j, i] \u2190 A[i, j]\n    return B\n\nMATRIX-ADD(A, B)\n    let m, n be the dimensions of A and B\n    let C[1\u2025m, 1\u2025n] be a new matrix\n    for i \u2190 1 to m\n        do for j \u2190 1 to n\n            do C[i, j] \u2190 A[i, j] + B[i, j]\n    return C\n\n// Example:\n// Matrix Multiplication:\n// A = [1 2]    B = [5 6]\n//     [3 4]        [7 8]\n//\n// C[1,1] = 1\u00b75 + 2\u00b77 = 19\n// C[1,2] = 1\u00b76 + 2\u00b78 = 22\n// C[2,1] = 3\u00b75 + 4\u00b77 = 43\n// C[2,2] = 3\u00b76 + 4\u00b78 = 50\n//\n// Result: [19 22]\n//         [43 50]\n//\n// Matrix Transpose:\n// A = [1 2 3]\n//     [4 5 6]\n//\n// Result: [1 4]\n//         [2 5]\n//         [3 6]\n//\n// Matrix Addition:\n// A = [1 2]    B = [5 6]\n//     [3 4]        [7 8]\n//\n// Result: [6  8]\n//         [10 12]",
    "keySteps": [
      "Multiplication: Three nested loops for dot product calculation",
      "Transpose: Swap row and column indices",
      "Addition: Element-wise sum of corresponding entries"
    ]
  },
  "matrix-exponentiation": {
    "name": "Matrix Exponentiation",
    "type": "Optimization Algorithm",
    "description": "Matrix Exponentiation is an algorithm with time complexity O(log n). It is primarily used for fast computation of matrix powers",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Fast computation of matrix powers\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Fast computation of matrix powers\n    ",
    "useCase": "Fast computation of matrix powers\n    ",
    "pseudocode": "// Compute matrix power using binary exponentiation\nMATRIX-POWER(matrix, power):\n    # Initialize result as identity matrix\n    result = IDENTITY-MATRIX(size of matrix)\n    current = matrix\n\n    # Process each bit of power\n    while power > 0:\n        # If current bit is set\n        if power mod 2 == 1:\n            # Multiply result by current matrix\n            result = MATRIX-MULTIPLY(result, current)\n\n        # Square current matrix\n        current = MATRIX-MULTIPLY(current, current)\n        # Move to next bit\n        power = power / 2\n\n    return result\n\n// Multiply two matrices\nMATRIX-MULTIPLY(A, B):\n    n = number of rows in A\n    m = number of columns in B\n    result = new n \u00d7 m matrix\n\n    # Compute each element\n    for i from 1 to n:\n        for j from 1 to m:\n            sum = 0\n            for k from 1 to number of columns in A:\n                sum = sum + A[i][k] * B[k][j]\n            result[i][j] = sum\n\n    return result",
    "keySteps": []
  },
  "matrix-chain-multiplication": {
    "name": "Matrix Chain Multiplication",
    "type": "n\u00b3",
    "description": "Matrix Chain Multiplication is an algorithm with time complexity O(n\u00b3). It is primarily used for finding optimal matrix       multiplication order",
    "timeComplexity": "O(n\u00b3) &nbsp;|&nbsp; Space: O(n\u00b2) &nbsp;|&nbsp; Use: Finding optimal matrix\n      multiplication order\n    ",
    "spaceComplexity": "O(n\u00b2) &nbsp;|&nbsp; Use: Finding optimal matrix\n      multiplication order\n    ",
    "useCase": "Finding optimal matrix\n      multiplication order\n    ",
    "pseudocode": "// Find minimum number of scalar multiplications\nMATRIX-CHAIN-ORDER(p):\n    n = length of p - 1\n    # Initialize tables for costs and splits\n    m = new n \u00d7 n table\n    s = new n \u00d7 n table\n\n    # Cost is zero when multiplying one matrix\n    for i from 1 to n:\n        m[i][i] = 0\n\n    # Consider chains of increasing length\n    for l from 2 to n:\n        for i from 1 to n - l + 1:\n            j = i + l - 1\n            m[i][j] = \u221e\n\n            # Try all possible split points\n            for k from i to j - 1:\n                # Compute cost of this split\n                cost = m[i][k] + m[k+1][j] + p[i-1] * p[k] * p[j]\n                if cost < m[i][j]:\n                    m[i][j] = cost\n                    s[i][j] = k\n\n    return m and s\n\n// Print optimal parenthesization\nPRINT-OPTIMAL-PARENS(s, i, j):\n    if i == j:\n        print \"A\" + i\n    else:\n        print \"(\"\n        PRINT-OPTIMAL-PARENS(s, i, s[i][j])\n        PRINT-OPTIMAL-PARENS(s, s[i][j] + 1, j)\n        print \")\"",
    "keySteps": []
  },
  "manachers-algorithm": {
    "name": "Manacher's Algorithm",
    "type": "String",
    "description": "Manacher's Algorithm is an algorithm with time complexity O(n). It is primarily used for find longest palindromic substring",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Find longest palindromic substring\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Find longest palindromic substring\n    ",
    "useCase": "Find longest palindromic substring\n    ",
    "pseudocode": "# Manacher's Algorithm: Find longest palindromic substring\n# Input: String S[1..n]\n# Output: Longest palindromic substring in S\n\nAlgorithm MANACHER(S)\n    # Transform string to handle even-length palindromes\n    T \u2190 \"#\" + S[1] + \"#\" + S[2] + \"#\" + ... + S[n] + \"#\"\n    n' \u2190 length[T]\n\n    # Initialize arrays\n    P \u2190 array of size n' filled with 0\n    C \u2190 1\n    R \u2190 1\n\n    for i \u2190 2 to n' do\n        # Mirror position\n        i_mirror \u2190 2 * C - i\n\n        # If i is within current right boundary\n        if i < R then\n            P[i] \u2190 min(R - i, P[i_mirror])\n        end if\n\n        # Expand around center\n        while T[i + P[i] + 1] = T[i - P[i] - 1] do\n            P[i] \u2190 P[i] + 1\n        end while\n\n        # Update center and right boundary if needed\n        if i + P[i] > R then\n            C \u2190 i\n            R \u2190 i + P[i]\n        end if\n    end for\n\n    # Find maximum length and center\n    max_len \u2190 0\n    center \u2190 0\n    for i \u2190 1 to n' do\n        if P[i] > max_len then\n            max_len \u2190 P[i]\n            center \u2190 i\n        end if\n    end for\n\n    # Extract and return longest palindrome\n    start \u2190 (center - max_len) / 2\n    return S[start..start + max_len - 1]\n\n# Example:\n# Input: S = \"babad\"\n#\n# Step 1: T = \"#b#a#b#a#d#\"\n# Step 2: P = [0, 1, 0, 3, 0, 1, 0, 1, 0, 1, 0]\n# Step 3: max_len = 3, center = 4\n#\n# Output: \"bab\"",
    "keySteps": [
      "Transform string to handle even-length palindromes",
      "Initialize arrays and boundaries",
      "Expand around each center and update boundaries",
      "Find and return longest palindrome"
    ]
  },
  "manacher": {
    "name": "Manacher's Algorithm",
    "type": "tree",
    "description": "Manacher's Algorithm is an algorithm with time complexity O(n). It is primarily used for finding longest palindromic substring",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Finding longest palindromic substring\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Finding longest palindromic substring\n    ",
    "useCase": "Finding longest palindromic substring\n    ",
    "pseudocode": "MANACHER(S):\n    // Transform string to handle even-length palindromes\n    T \u2190 \"#\" + JOIN(S, \"#\") + \"#\"\n    n \u2190 length(T)\n    P[1..n] \u2190 0\n    C \u2190 1    // center of current palindrome\n    R \u2190 1    // right boundary of current palindrome\n    \n    for i \u2190 2 to n-1:\n        // Mirror position\n        i_mirror \u2190 2C - i\n        \n        if i < R:\n            P[i] \u2190 min(R - i, P[i_mirror])\n        \n        // Expand palindrome centered at i\n        while T[i + P[i] + 1] = T[i - P[i] - 1]:\n            P[i] \u2190 P[i] + 1\n        \n        // Update center and right boundary if needed\n        if i + P[i] > R:\n            C \u2190 i\n            R \u2190 i + P[i]\n    \n    // Find maximum palindrome\n    max_len \u2190 0\n    center \u2190 0\n    for i \u2190 1 to n:\n        if P[i] > max_len:\n            max_len \u2190 P[i]\n            center \u2190 i\n    \n    // Extract palindrome from original string\n    start \u2190 (center - max_len) div 2\n    return S[start..start + max_len - 1]\n\n// Example:\n// Input: S = \"babad\"\n//\n// Transformed string T:\n// #b#a#b#a#d#\n//\n// P array:\n// [0,1,0,3,0,1,0,1,0]\n//\n// Longest palindrome: \"bab\" or \"aba\"",
    "keySteps": [
      "Linear time algorithm for finding longest palindrome",
      "Uses palindrome mirroring property for optimization",
      "Handles both odd and even length palindromes",
      "More efficient than O(n\u00b2) dynamic programming approach"
    ]
  },
  "longest-increasing-subsequence": {
    "name": "Longest Increasing Subsequence",
    "type": "Algorithm",
    "description": "Find the length of the longest strictly increasing subsequence in an array",
    "timeComplexity": "O(n log n) using binary search, O(n\u00b2) using dynamic programming",
    "spaceComplexity": "O(n) for storing the dp array or patience sorting array",
    "useCase": "Finding optimal sequences, pattern matching, data analysis",
    "pseudocode": "def lengthOfLIS(nums):\n    if not nums:\n        return 0\n    \n    # dp[i] represents the length of LIS ending at index i\n    dp = [1] * len(nums)\n    \n    for i in range(1, len(nums)):\n        for j in range(i):\n            if nums[i] > nums[j]:\n                dp[i] = max(dp[i], dp[j] + 1)\n    \n    return max(dp)\n\n# Binary search approach (O(n log n))\ndef lengthOfLIS_optimized(nums):\n    if not nums:\n        return 0\n    \n    # dp[i] represents the smallest tail of all increasing subsequences of length i+1\n    dp = []\n    \n    for num in nums:\n        # Find the first number in dp that is greater than or equal to num\n        i = bisect.bisect_left(dp, num)\n        if i == len(dp):\n            dp.append(num)\n        else:\n            dp[i] = num\n    \n    return len(dp)",
    "keySteps": [
      "Initialize dp array with 1s (each element is a subsequence of length 1)",
      "For each element, check all previous elements for increasing sequence",
      "Update dp[i] if a longer increasing subsequence is found",
      "Return the maximum value in dp array"
    ]
  },
  "linked-list": {
    "name": "Linked List",
    "type": "bit manipulation",
    "description": "Linked List is an algorithm with time complexity O(n). It is primarily used for dynamic data storage with efficient       insertions/deletions",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Dynamic data storage with efficient\n      insertions/deletions\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Dynamic data storage with efficient\n      insertions/deletions\n    ",
    "useCase": "Dynamic data storage with efficient\n      insertions/deletions\n    ",
    "pseudocode": "// Node structure\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next = None\n\n// Singly Linked List\nclass LinkedList:\n    def __init__(self):\n        self.head = None\n\n    # Insert at beginning\n    def insert_at_beginning(self, data):\n        new_node = Node(data)\n        new_node.next = self.head\n        self.head = new_node\n\n    # Insert at end\n    def insert_at_end(self, data):\n        new_node = Node(data)\n        if not self.head:\n            self.head = new_node\n            return\n        last = self.head\n        while last.next:\n            last = last.next\n        last.next = new_node\n\n    # Delete node\n    def delete_node(self, key):\n        temp = self.head\n        if temp and temp.data == key:\n            self.head = temp.next\n            return\n        while temp and temp.next:\n            if temp.next.data == key:\n                temp.next = temp.next.next\n                return\n            temp = temp.next\n\n    # Search node\n    def search(self, key):\n        current = self.head\n        while current:\n            if current.data == key:\n                return True\n            current = current.next\n        return False\n\n// Doubly Linked List\nclass DoublyLinkedList:\n    def __init__(self):\n        self.head = None\n        self.tail = None\n\n    # Insert at beginning\n    def insert_at_beginning(self, data):\n        new_node = Node(data)\n        if not self.head:\n            self.head = new_node\n            self.tail = new_node\n            return\n        new_node.next = self.head\n        self.head.prev = new_node\n        self.head = new_node\n\n    # Insert at end\n    def insert_at_end(self, data):\n        new_node = Node(data)\n        if not self.head:\n            self.head = new_node\n            self.tail = new_node\n            return\n        self.tail.next = new_node\n        new_node.prev = self.tail\n        self.tail = new_node\n\n    # Delete node\n    def delete_node(self, key):\n        current = self.head\n        while current:\n            if current.data == key:\n                if current.prev:\n                    current.prev.next = current.next\n                else:\n                    self.head = current.next\n                if current.next:\n                    current.next.prev = current.prev\n                else:\n                    self.tail = current.prev\n                return\n            current = current.next\n\n// Circular Linked List\nclass CircularLinkedList:\n    def __init__(self):\n        self.head = None\n\n    # Insert at beginning\n    def insert_at_beginning(self, data):\n        new_node = Node(data)\n        if not self.head:\n            new_node.next = new_node\n            self.head = new_node\n            return\n        last = self.head\n        while last.next != self.head:\n            last = last.next\n        new_node.next = self.head\n        last.next = new_node\n        self.head = new_node\n\n    # Insert at end\n    def insert_at_end(self, data):\n        new_node = Node(data)\n        if not self.head:\n            new_node.next = new_node\n            self.head = new_node\n            return\n        last = self.head\n        while last.next != self.head:\n            last = last.next\n        last.next = new_node\n        new_node.next = self.head",
    "keySteps": []
  },
  "linear-search": {
    "name": "Linear Search",
    "type": "Search",
    "description": "Linear Search is an algorithm with time complexity O(n). It is primarily used for find element in unsorted array",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find element in unsorted array\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find element in unsorted array\n    ",
    "useCase": "Find element in unsorted array\n    ",
    "pseudocode": "# Linear Search: Find element in unsorted array\n# Input: Array A[1..n], target value x\n# Output: Index of x in A if found, -1 otherwise\n\nAlgorithm LINEAR-SEARCH(A, x)\n    for i \u2190 1 to length[A] do\n        if A[i] = x then\n            return i\n        end if\n    end for\n    return -1\n\n# Example:\n# Input: A = [4, 2, 7, 1, 3], x = 7\n#\n# Step 1: i = 1, A[1] = 4 \u2260 7\n# Step 2: i = 2, A[2] = 2 \u2260 7\n# Step 3: i = 3, A[3] = 7 = 7\n#\n# Output: 3",
    "keySteps": [
      "Initialize loop through array",
      "Compare each element with target",
      "Return index if found",
      "Return -1 if not found"
    ]
  },
  "lca": {
    "name": "Lowest Common Ancestor",
    "type": "Algorithm",
    "description": "Lowest Common Ancestor is an algorithm with time complexity O(log n). It is primarily used for find lca in tree",
    "timeComplexity": "O(log n) per query &nbsp;|&nbsp; Space: O(n log n) &nbsp;|&nbsp; Use: Find LCA in tree\n    ",
    "spaceComplexity": "O(n log n) &nbsp;|&nbsp; Use: Find LCA in tree\n    ",
    "useCase": "Find LCA in tree\n    ",
    "pseudocode": "LCA-PREPROCESS(T)\n    let n be the number of vertices in T\n    let depth[1\u2025n] be a new array\n    let up[1\u2025n][0\u2025log n] be a new array\n\n    DFS-LCA(T, T.root, NIL, depth, up)\n    return (depth, up)\n\nDFS-LCA(T, u, p, depth, up)\n    up[u][0] \u2190 p\n    for i \u2190 1 to log n\n        do if up[u][i-1] \u2260 NIL\n            then up[u][i] \u2190 up[up[u][i-1]][i-1]\n            else up[u][i] \u2190 NIL\n\n    for each v in T.Adj[u]\n        do if v \u2260 p\n            then depth[v] \u2190 depth[u] + 1\n                DFS-LCA(T, v, u, depth, up)\n\nLCA-QUERY(u, v, depth, up)\n    if depth[u] < depth[v]\n        then swap(u, v)\n\n    for i \u2190 log n downto 0\n        do if depth[u] - (1 << i) \u2265 depth[v]\n            then u \u2190 up[u][i]\n\n    if u = v\n        then return u\n\n    for i \u2190 log n downto 0\n        do if up[u][i] \u2260 up[v][i]\n            then u \u2190 up[u][i]\n                v \u2190 up[v][i]\n\n    return up[u][0]\n\n// Example:\n// Input: Tree with edges (1,2), (1,3), (2,4), (2,5), (3,6)\n//\n// Preprocessing:\n//   depth = [0, 1, 1, 2, 2, 2]\n//   up[1] = [NIL, NIL, NIL]\n//   up[2] = [1, NIL, NIL]\n//   up[3] = [1, NIL, NIL]\n//   up[4] = [2, 1, NIL]\n//   up[5] = [2, 1, NIL]\n//   up[6] = [3, 1, NIL]\n//\n// Query: LCA(4,6)\n//   Step 1: Bring 4 to depth 2\n//   Step 2: Binary search for LCA\n//   Output: 1",
    "keySteps": [
      "Preprocess: Build binary lifting table",
      "Query: Bring nodes to same depth",
      "Binary Search: Find lowest common ancestor"
    ]
  },
  "lca-dfs": {
    "name": "LCA (DFS)",
    "type": "tree",
    "description": "LCA (DFS) is an algorithm with time complexity O(n). It is primarily used for finding lowest common ancestor in       binary trees",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(h) &nbsp;|&nbsp; Use: Finding lowest common ancestor in\n      binary trees\n    ",
    "spaceComplexity": "O(h) &nbsp;|&nbsp; Use: Finding lowest common ancestor in\n      binary trees\n    ",
    "useCase": "Finding lowest common ancestor in\n      binary trees\n    ",
    "pseudocode": "// LCA using DFS\nLCA-DFS(root, p, q):\n  if root == null or root == p or root == q:\n    return root\n  \n  left = LCA-DFS(root.left, p, q)\n  right = LCA-DFS(root.right, p, q)\n  \n  if left != null and right != null:\n    return root\n  return left if left != null else right\n\n// Alternative: Using Parent Pointers\nLCA-PARENT(root, p, q):\n  ancestors = new Set()\n  while p != null:\n    ancestors.add(p)\n    p = p.parent\n  \n  while q != null:\n    if q in ancestors:\n      return q\n    q = q.parent\n  return null",
    "keySteps": [
      "Works for both binary and n-ary trees",
      "Handles cases where one node is ancestor of the other",
      "Can be optimized for repeated queries using binary lifting"
    ]
  },
  "kruskals-algorithm": {
    "name": "Kruskal's Algorithm",
    "type": "E log E",
    "description": "Kruskal's Algorithm is an algorithm with time complexity O(E log E). It is primarily used for find minimum spanning tree",
    "timeComplexity": "O(E log E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find minimum spanning tree\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find minimum spanning tree\n    ",
    "useCase": "Find minimum spanning tree\n    ",
    "pseudocode": "# Kruskal's Algorithm: Find minimum spanning tree\n# Input: Graph G = (V, E) with edge weights\n# Output: Set of edges forming minimum spanning tree\n\nAlgorithm KRUSKAL(G)\n    # Initialize disjoint set for vertices\n    for each vertex v in V do\n        MAKE-SET(v)\n    end for\n\n    # Sort edges by weight\n    sort E by weight in non-decreasing order\n\n    # Initialize result\n    A \u2190 empty set\n\n    # Process edges in order\n    for each edge (u, v) in E do\n        if FIND-SET(u) \u2260 FIND-SET(v) then\n            A \u2190 A \u222a {(u, v)}\n            UNION(u, v)\n        end if\n    end for\n\n    return A\n\n# Example:\n# Input: G = (V, E) where\n# V = {a, b, c, d}\n# E = {(a,b,1), (a,c,4), (a,d,3), (b,c,2), (b,d,5), (c,d,6)}\n#\n# Step 1: Sort edges: (a,b,1), (b,c,2), (a,d,3), (a,c,4), (b,d,5), (c,d,6)\n# Step 2: Add (a,b), (b,c), (a,d)\n#\n# Output: {(a,b), (b,c), (a,d)}",
    "keySteps": [
      "Initialize disjoint sets for vertices",
      "Sort edges by weight",
      "Process edges in order and add to MST if no cycle",
      "Return set of edges forming MST"
    ]
  },
  "kruskal": {
    "name": "Kruskal's Algorithm",
    "type": "E log E",
    "description": "Kruskal's Algorithm is an algorithm with time complexity O(E log E). It is primarily used for minimum spanning tree in       undirected graphs",
    "timeComplexity": "O(E log E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Minimum spanning tree in\n      undirected graphs\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Minimum spanning tree in\n      undirected graphs\n    ",
    "useCase": "Minimum spanning tree in\n      undirected graphs\n    ",
    "pseudocode": "KRUSKAL(G, w):\n    A \u2190 \u2205\n    for each vertex v \u2208 G.V:\n        MAKE-SET(v)\n    sort G.E into nondecreasing order by weight w\n    for each edge (u, v) \u2208 G.E, taken in nondecreasing order by weight:\n        if FIND-SET(u) \u2260 FIND-SET(v):\n            A \u2190 A \u222a {(u, v)}\n            UNION(u, v)\n    return A\n\nMAKE-SET(x):\n    x.p \u2190 x\n    x.rank \u2190 0\n\nUNION(x, y):\n    LINK(FIND-SET(x), FIND-SET(y))\n\nLINK(x, y):\n    if x.rank > y.rank:\n        y.p \u2190 x\n    else:\n        x.p \u2190 y\n        if x.rank = y.rank:\n            y.rank \u2190 y.rank + 1\n\nFIND-SET(x):\n    if x \u2260 x.p:\n        x.p \u2190 FIND-SET(x.p)\n    return x.p\n\n// Example:\n// Input: G = (V, E) where\n// V = {a, b, c, d, e, f}\n// E = {(a,b,4), (a,c,3), (b,c,1), (b,d,2), (c,d,4), (d,e,2), (d,f,2), (e,f,3)}\n//\n// Sorted edges by weight:\n// (b,c,1), (b,d,2), (d,e,2), (d,f,2), (a,c,3), (e,f,3), (a,b,4), (c,d,4)\n//\n// MST edges in order of selection:\n// (b,c,1), (b,d,2), (d,e,2), (d,f,2), (a,c,3)\n//\n// Total weight: 10",
    "keySteps": [
      "Greedy algorithm that always selects minimum weight edge",
      "Uses disjoint-set data structure for efficient operations",
      "Produces minimum spanning tree for connected graphs",
      "Sorting edges: O(E log E)"
    ]
  },
  "kmp-algorithm": {
    "name": "Knuth-Morris-Pratt",
    "type": "n + m",
    "description": "\n          A linear time pattern matching algorithm that uses a preprocessed pattern to skip\n          unnecessary comparisons.\n        ",
    "timeComplexity": "O(n + m) where n is text length and m is pattern length",
    "spaceComplexity": "O(m) for storing the prefix function",
    "useCase": "Efficient string pattern matching, DNA sequence analysis, text search",
    "pseudocode": "# Knuth-Morris-Pratt: Pattern matching in strings\n# Input: Text T[1..n], Pattern P[1..m]\n# Output: All starting positions where P occurs in T\n\nAlgorithm KMP-MATCHER(T, P)\n    n \u2190 length[T]\n    m \u2190 length[P]\n\n    # Compute prefix function\n    \u03c0 \u2190 COMPUTE-PREFIX-FUNCTION(P)\n\n    q \u2190 0  # Number of characters matched\n    for i \u2190 1 to n do\n        while q > 0 and P[q + 1] \u2260 T[i] do\n            q \u2190 \u03c0[q]\n        end while\n        if P[q + 1] = T[i] then\n            q \u2190 q + 1\n        end if\n        if q = m then\n            print \"Pattern occurs at position\" i - m\n            q \u2190 \u03c0[q]\n        end if\n    end for\n\nAlgorithm COMPUTE-PREFIX-FUNCTION(P)\n    m \u2190 length[P]\n    \u03c0[1] \u2190 0\n    k \u2190 0\n    for q \u2190 2 to m do\n        while k > 0 and P[k + 1] \u2260 P[q] do\n            k \u2190 \u03c0[k]\n        end while\n        if P[k + 1] = P[q] then\n            k \u2190 k + 1\n        end if\n        \u03c0[q] \u2190 k\n    end for\n    return \u03c0\n\n# Example:\n# Input: T = \"ABABDABACDABABCABAB\", P = \"ABABCABAB\"\n#\n# Step 1: \u03c0 = [0, 0, 1, 2, 0, 1, 2, 3, 4]\n# Step 2: Match at position 10\n#\n# Output: Pattern occurs at position 10",
    "keySteps": [
      "Compute prefix function for pattern",
      "Match pattern against text using prefix function",
      "Skip unnecessary comparisons using prefix function",
      "Report all occurrences of pattern"
    ]
  },
  "karatsuba-multiplication": {
    "name": "Karatsuba Multiplication",
    "type": "n^log\u20823",
    "description": "Karatsuba Multiplication is an algorithm with time complexity O(n^log\u20823). It is primarily used for fast       multiplication of large integers",
    "timeComplexity": "O(n^log\u20823) \u2248 O(n^1.585) &nbsp;|&nbsp; Space: O(log n) &nbsp;|&nbsp; Use: Fast\n      multiplication of large integers\n    ",
    "spaceComplexity": "O(log n) &nbsp;|&nbsp; Use: Fast\n      multiplication of large integers\n    ",
    "useCase": "Fast\n      multiplication of large integers\n    ",
    "pseudocode": "KARATSUBA(x, y):\n    n \u2190 max(length(x), length(y))\n    if n \u2264 1:\n        return x \u00d7 y\n    \n    // Split numbers into high and low parts\n    m \u2190 \u2308n/2\u2309\n    x\u2081 \u2190 x div 10^m\n    x\u2080 \u2190 x mod 10^m\n    y\u2081 \u2190 y div 10^m\n    y\u2080 \u2190 y mod 10^m\n    \n    // Recursive calls\n    z\u2082 \u2190 KARATSUBA(x\u2081, y\u2081)\n    z\u2080 \u2190 KARATSUBA(x\u2080, y\u2080)\n    z\u2081 \u2190 KARATSUBA(x\u2081 + x\u2080, y\u2081 + y\u2080) - z\u2082 - z\u2080\n    \n    // Combine results\n    return z\u2082 \u00d7 10^(2m) + z\u2081 \u00d7 10^m + z\u2080\n\n// Example:\n// Input: x = 1234, y = 5678\n//\n// Split:\n// x\u2081 = 12, x\u2080 = 34\n// y\u2081 = 56, y\u2080 = 78\n//\n// Recursive calls:\n// z\u2082 = KARATSUBA(12, 56) = 672\n// z\u2080 = KARATSUBA(34, 78) = 2652\n// z\u2081 = KARATSUBA(46, 134) - 672 - 2652 = 6164 - 672 - 2652 = 2840\n//\n// Combine:\n// 672 \u00d7 10\u2074 + 2840 \u00d7 10\u00b2 + 2652 = 7,006,652",
    "keySteps": [
      "Divide-and-conquer algorithm for integer multiplication",
      "Reduces number of multiplications from 4 to 3",
      "More efficient than traditional O(n\u00b2) multiplication",
      "Recurrence: T(n) = 3T(n/2) + O(n)"
    ]
  },
  "kahn-topological-sort": {
    "name": "Kahn's Algorithm",
    "type": "V + E",
    "description": "Kahn's Algorithm is an algorithm with time complexity O(V + E). It is primarily used for topological sorting of dags",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Topological sorting of DAGs\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Topological sorting of DAGs\n    ",
    "useCase": "Topological sorting of DAGs\n    ",
    "pseudocode": "KAHN-TOPOLOGICAL-SORT(G):\n    // G is a directed acyclic graph\n    // Returns topological order or detects cycle\n    in_degree[1..V] \u2190 0\n    for each vertex v in G:\n        for each neighbor u of v:\n            in_degree[u] \u2190 in_degree[u] + 1\n    \n    Q \u2190 empty queue\n    for each vertex v in G:\n        if in_degree[v] = 0:\n            Q.enqueue(v)\n    \n    topo_order \u2190 empty list\n    while Q is not empty:\n        v \u2190 Q.dequeue()\n        topo_order.append(v)\n        \n        for each neighbor u of v:\n            in_degree[u] \u2190 in_degree[u] - 1\n            if in_degree[u] = 0:\n                Q.enqueue(u)\n    \n    if length(topo_order) \u2260 V:\n        return \"Graph contains a cycle\"\n    return topo_order\n\n// Example:\n// Graph G:\n// 1 \u2192 2 \u2192 3\n// \u2193   \u2193   \u2193\n// 4 \u2192 5 \u2192 6\n//\n// Initial in_degree:\n// [0,1,1,1,2,2]\n//\n// Topological order:\n// [1,2,4,3,5,6]",
    "keySteps": [
      "Finds topological order of vertices in a DAG",
      "Can detect cycles in directed graphs",
      "Uses in-degree counting and queue-based approach",
      "More efficient than DFS-based approach for large graphs"
    ]
  },
  "kadanes-algorithm": {
    "name": "Kadane's Algorithm",
    "type": "array",
    "description": "Kadane's Algorithm is an algorithm with time complexity O(n). It is primarily used for finding maximum subarray sum",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Finding maximum subarray sum\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Finding maximum subarray sum\n    ",
    "useCase": "Finding maximum subarray sum\n    ",
    "pseudocode": "// Find maximum subarray sum\nKADANE(A):\n  max_ending_here = A[1]\n  max_so_far = A[1]\n  for i = 2 to A.length:\n    max_ending_here = max(A[i], max_ending_here + A[i])\n    max_so_far = max(max_so_far, max_ending_here)\n  return max_so_far\n\n// Find maximum subarray sum with indices\nKADANE-WITH-INDICES(A):\n  max_ending_here = A[1]\n  max_so_far = A[1]\n  start = 1\n  end = 1\n  temp_start = 1\n  for i = 2 to A.length:\n    if A[i] > max_ending_here + A[i]:\n      max_ending_here = A[i]\n      temp_start = i\n    else:\n      max_ending_here = max_ending_here + A[i]\n    if max_ending_here > max_so_far:\n      max_so_far = max_ending_here\n      start = temp_start\n      end = i\n  return (max_so_far, start, end)\n\n// Find maximum circular subarray sum\nKADANE-CIRCULAR(A):\n  max_kadane = KADANE(A)\n  max_wrap = 0\n  for i = 1 to A.length:\n    max_wrap = max_wrap + A[i]\n    A[i] = -A[i]\n  max_wrap = max_wrap + KADANE(A)\n  return max(max_kadane, max_wrap)",
    "keySteps": []
  },
  "jump-search-algorithm": {
    "name": "Jump Search",
    "type": "Algorithm",
    "description": "Jump Search is an algorithm with time complexity O(\u221an). It is primarily used for search in sorted arrays",
    "timeComplexity": "O(\u221an) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Search in sorted arrays\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Search in sorted arrays\n    ",
    "useCase": "Search in sorted arrays\n    ",
    "pseudocode": "// Jump search in sorted array\nJUMP-SEARCH(A, x):\n    n \u2190 length[A]\n    step \u2190 \u230a\u221an\u230b\n    prev \u2190 0\n    // Jump through array\n    while A[min(step, n)] < x:\n        prev \u2190 step\n        step \u2190 step + \u230a\u221an\u230b\n        if prev \u2265 n:\n            return -1\n    // Linear search in block\n    while A[prev] < x:\n        prev \u2190 prev + 1\n        if prev = min(step, n):\n            return -1\n    if A[prev] = x:\n        return prev\n    return -1\n\n// Example:\n// Input: A = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], x = 7\n//\n// Execution:\n// 1. step = 3, prev = 0\n// 2. A[3] = 4 < 7: prev = 3, step = 6\n// 3. A[6] = 7 < 7: false\n// 4. Linear search from index 3 to 6\n// 5. Found at index 6\n//\n// Output: 6",
    "keySteps": [
      "Initialize: Calculate jump step size",
      "Jump: Skip through array in fixed steps",
      "Search: Linear search in identified block"
    ]
  },
  "job-scheduling": {
    "name": "Job Scheduling",
    "type": "Algorithm",
    "description": "Job Scheduling is an algorithm with time complexity O(n log n). It is primarily used for schedule jobs to minimize       completion time",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Schedule jobs to minimize\n      completion time\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Schedule jobs to minimize\n      completion time\n    ",
    "useCase": "Schedule jobs to minimize\n      completion time\n    ",
    "pseudocode": "JOB-SCHEDULING(jobs)\n    n \u2190 length[jobs]\n    sort jobs by finish time\n    let schedule[1\u2025n] be a new array\n    schedule[1] \u2190 jobs[1]\n    j \u2190 1\n    for i \u2190 2 to n\n        do if jobs[i].start \u2265 jobs[j].finish\n            then schedule[i] \u2190 jobs[i]\n                j \u2190 i\n    return schedule\n\n// Example:\n// Input: jobs = [\n//   {start: 1, finish: 2, profit: 50},\n//   {start: 3, finish: 5, profit: 20},\n//   {start: 6, finish: 19, profit: 100},\n//   {start: 2, finish: 100, profit: 200}\n// ]\n//\n// Step 1: Sort by finish time\n//         [{1,2,50}, {3,5,20}, {6,19,100}, {2,100,200}]\n//\n// Step 2: Select jobs\n//         Select job 1 (1-2)\n//         Skip job 2 (overlaps)\n//         Select job 3 (6-19)\n//         Skip job 4 (overlaps)\n//\n// Output: [{1,2,50}, {6,19,100}]",
    "keySteps": [
      "Sort: Jobs by finish time",
      "Select: First job",
      "Iterate: Through remaining jobs",
      "Add: Non-overlapping jobs to schedule"
    ]
  },
  "interval-scheduling": {
    "name": "Interval Scheduling",
    "type": "n log n",
    "description": "Interval Scheduling is an algorithm with time complexity O(n log n). It is primarily used for maximum non-overlapping       intervals",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Maximum non-overlapping\n      intervals\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Maximum non-overlapping\n      intervals\n    ",
    "useCase": "Maximum non-overlapping\n      intervals\n    ",
    "pseudocode": "INTERVAL-SCHEDULING(I):\n    // I is a list of intervals [start, end]\n    // Returns maximum set of non-overlapping intervals\n    \n    // Sort intervals by end time\n    SORT(I, key = end_time)\n    \n    selected \u2190 empty list\n    last_end \u2190 -\u221e\n    \n    for each interval [start, end] in I:\n        if start \u2265 last_end:\n            selected.append([start, end])\n            last_end \u2190 end\n    \n    return selected\n\n// Example:\n// Input intervals:\n// [1,4], [2,5], [3,6], [4,7], [5,8]\n//\n// Sorted by end time:\n// [1,4], [2,5], [3,6], [4,7], [5,8]\n//\n// Selected intervals:\n// [1,4], [4,7]",
    "keySteps": [
      "Greedy algorithm for interval selection",
      "Always selects interval with earliest end time",
      "Produces optimal solution for maximum non-overlapping intervals",
      "Optimal greedy solution for interval scheduling"
    ]
  },
  "interpolation-search": {
    "name": "Interpolation Search",
    "type": "Search",
    "description": "Interpolation Search is an algorithm with time complexity O(log log n). It is primarily used for find element in uniformly       distributed sorted array",
    "timeComplexity": "O(log log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find element in uniformly\n      distributed sorted array\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find element in uniformly\n      distributed sorted array\n    ",
    "useCase": "Find element in uniformly\n      distributed sorted array\n    ",
    "pseudocode": "# Interpolation Search: Find element in uniformly distributed sorted array\n# Input: Sorted array A[1..n], target value x\n# Output: Index of x in A if found, -1 otherwise\n\nAlgorithm INTERPOLATION-SEARCH(A, x)\n    low \u2190 1\n    high \u2190 length[A]\n\n    while low \u2264 high and x \u2265 A[low] and x \u2264 A[high] do\n        # Calculate position using interpolation formula\n        pos \u2190 low + ((x - A[low]) * (high - low)) / (A[high] - A[low])\n\n        if A[pos] = x then\n            return pos\n        end if\n\n        if A[pos] < x then\n            low \u2190 pos + 1\n        else\n            high \u2190 pos - 1\n        end if\n    end while\n\n    return -1\n\n# Example:\n# Input: A = [10, 20, 30, 40, 50, 60, 70, 80, 90], x = 50\n#\n# Step 1: low = 1, high = 9\n#         pos = 1 + ((50-10)*(9-1))/(90-10) = 5\n#         A[5] = 50\n#\n# Output: 5",
    "keySteps": [
      "Initialize search boundaries",
      "Calculate position using interpolation formula",
      "Adjust boundaries based on comparison",
      "Return index if found, -1 otherwise"
    ]
  },
  "insertion-sort": {
    "name": "Insertion Sort",
    "type": "n\u00b2",
    "description": "Insertion Sort is an algorithm with time complexity O(n\u00b2). It is primarily used for sorting array in-place",
    "timeComplexity": "O(n\u00b2) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Sorting array in-place\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Sorting array in-place\n    ",
    "useCase": "Sorting array in-place\n    ",
    "pseudocode": "# Insertion Sort: Build sorted array one element at a time\n# Input: Array A[1..n] of n elements\n# Output: Array A sorted in non-decreasing order\n\nINSERTION-SORT(A)\n    n \u2190 length[A]    # Number of elements in array\n\n    # Start from second element (index 2)\n    for j \u2190 2 to n do\n        key \u2190 A[j]    # Current element to insert\n        i \u2190 j - 1     # Start comparing with previous element\n\n        # Move elements greater than key one position ahead\n        while i > 0 and A[i] > key do\n            A[i+1] \u2190 A[i]    # Shift element right\n            i \u2190 i - 1         # Move left\n        end while\n\n        A[i+1] \u2190 key    # Insert key in correct position\n    end for\n\n# Example:\n# Input: A = [5, 2, 4, 6, 1, 3]\n# Pass 1: [2, 5, 4, 6, 1, 3]  # Insert 2\n# Pass 2: [2, 4, 5, 6, 1, 3]  # Insert 4\n# Pass 3: [2, 4, 5, 6, 1, 3]  # Insert 6\n# Pass 4: [1, 2, 4, 5, 6, 3]  # Insert 1\n# Pass 5: [1, 2, 3, 4, 5, 6]  # Insert 3\n# Output: [1, 2, 3, 4, 5, 6]",
    "keySteps": []
  },
  "inorder-traversal": {
    "name": "Inorder Tree Traversal",
    "type": "tree",
    "description": "Inorder Tree Traversal is an algorithm with time complexity O(n). It is primarily used for binary tree traversal       (left-root-right)",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(h) &nbsp;|&nbsp; Use: Binary tree traversal\n      (left-root-right)\n    ",
    "spaceComplexity": "O(h) &nbsp;|&nbsp; Use: Binary tree traversal\n      (left-root-right)\n    ",
    "useCase": "Binary tree traversal\n      (left-root-right)\n    ",
    "pseudocode": "// Recursive Inorder Traversal\nINORDER-TREE-WALK(x):\n    if x \u2260 NIL:\n        INORDER-TREE-WALK(x.left)\n        print x.key\n        INORDER-TREE-WALK(x.right)\n\n// Iterative Inorder Traversal using Stack\nITERATIVE-INORDER(x):\n    S \u2190 empty stack\n    current \u2190 x\n    while current \u2260 NIL or S is not empty:\n        while current \u2260 NIL:\n            PUSH(S, current)\n            current \u2190 current.left\n        current \u2190 POP(S)\n        print current.key\n        current \u2190 current.right\n\n// Morris Inorder Traversal (Threaded Binary Tree)\nMORRIS-INORDER(root):\n    current \u2190 root\n    while current \u2260 NIL:\n        if current.left = NIL:\n            print current.key\n            current \u2190 current.right\n        else:\n            // Find inorder predecessor\n            predecessor \u2190 current.left\n            while predecessor.right \u2260 NIL and predecessor.right \u2260 current:\n                predecessor \u2190 predecessor.right\n            \n            if predecessor.right = NIL:\n                predecessor.right \u2190 current\n                current \u2190 current.left\n            else:\n                predecessor.right \u2190 NIL\n                print current.key\n                current \u2190 current.right\n\n// Example:\n// Input: Binary tree\n//        4\n//      /   \\\\\n//     2     6\n//    / \\\\   / \\\\\n//   1   3 5   7\n//\n// Inorder traversal: 1 2 3 4 5 6 7",
    "keySteps": [
      "Recursive: Simple but uses call stack space",
      "Iterative: Uses explicit stack, better for large trees",
      "Morris: O(1) space, modifies tree structure temporarily",
      "Binary Search Tree validation"
    ]
  },
  "hungarian": {
    "name": "Hungarian Algorithm",
    "type": "Algorithm",
    "description": "Hungarian Algorithm is an algorithm with time complexity O(n\u00b3). It is primarily used for solve assignment problem",
    "timeComplexity": "O(n\u00b3) &nbsp;|&nbsp; Space: O(n\u00b2) &nbsp;|&nbsp; Use: Solve assignment problem\n    ",
    "spaceComplexity": "O(n\u00b2) &nbsp;|&nbsp; Use: Solve assignment problem\n    ",
    "useCase": "Solve assignment problem\n    ",
    "pseudocode": "HUNGARIAN(C)\n1  n = C.rows\n2  // Step 1: Subtract row minima\n3  for i = 1 to n\n4      row_min = min(C[i][j] for j = 1 to n)\n5      for j = 1 to n\n6          C[i][j] = C[i][j] - row_min\n7\n8  // Step 2: Subtract column minima\n9  for j = 1 to n\n10     col_min = min(C[i][j] for i = 1 to n)\n11     for i = 1 to n\n12         C[i][j] = C[i][j] - col_min\n13\n14 // Step 3: Cover all zeros with minimum lines\n15 while true\n16     // Find minimum uncovered value\n17     min_val = \u221e\n18     for i = 1 to n\n19         for j = 1 to n\n20             if not covered[i] and not covered[j]\n21                 min_val = min(min_val, C[i][j])\n22\n23     // Subtract from uncovered rows, add to covered columns\n24     for i = 1 to n\n25         for j = 1 to n\n26             if not covered[i] and not covered[j]\n27                 C[i][j] = C[i][j] - min_val\n28             else if covered[i] and covered[j]\n29                 C[i][j] = C[i][j] + min_val\n30\n31     // Try to find complete matching\n32     matching = FIND-MATCHING(C)\n33     if size(matching) == n\n34         return matching\n35\n36 FIND-MATCHING(C)\n37     n = C.rows\n38     matching = {}\n39     for i = 1 to n\n40         visited = [False] * n\n41         if DFS(i, visited, matching)\n42             continue\n43     return matching\n44\n45 DFS(u, visited, matching)\n46     for v = 1 to n\n47         if not visited[v] and C[u][v] == 0\n48             visited[v] = true\n49             if v not in matching or DFS(matching[v], visited, matching)\n50                 matching[v] = u\n51                 return true\n52     return false\n\n// Example:\n// Input: C = [[5, 2, 3],\n//             [2, 4, 6],\n//             [3, 6, 8]]\n//\n// Step 1: Subtract row minima\n//         [[3, 0, 1],\n//          [0, 2, 4],\n//          [0, 3, 5]]\n//\n// Step 2: Subtract column minima\n//         [[3, 0, 0],\n//          [0, 2, 3],\n//          [0, 3, 4]]\n//\n// Step 3: Find complete matching\n//         Matching: {(1,2), (2,1), (3,3)}\n//\n// Final assignment: [(1,2), (2,1), (3,3)]",
    "keySteps": [
      "Subtract: Row and column minima",
      "Cover: All zeros with minimum lines",
      "Find: Complete matching using DFS"
    ]
  },
  "huffman-coding": {
    "name": "Huffman Coding",
    "type": "Algorithm",
    "description": "Huffman Coding is an algorithm with time complexity O(n log n). It is primarily used for optimal prefix coding for data       compression",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Optimal prefix coding for data\n      compression\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Optimal prefix coding for data\n      compression\n    ",
    "useCase": "Optimal prefix coding for data\n      compression\n    ",
    "pseudocode": "HUFFMAN(C)\n    n \u2190 |C|\n    Q \u2190 C  // Min-priority queue\n    for i \u2190 1 to n - 1\n        do allocate a new node z\n            z.left \u2190 x \u2190 EXTRACT-MIN(Q)\n            z.right \u2190 y \u2190 EXTRACT-MIN(Q)\n            z.freq \u2190 x.freq + y.freq\n            INSERT(Q, z)\n    return EXTRACT-MIN(Q)  // Return root of tree\n\n// Example:\n// Input: C = [\n//   {char: 'a', freq: 45},\n//   {char: 'b', freq: 13},\n//   {char: 'c', freq: 12},\n//   {char: 'd', freq: 16},\n//   {char: 'e', freq: 9},\n//   {char: 'f', freq: 5}\n// ]\n//\n// Step 1: Create leaf nodes\n//         [a:45, b:13, c:12, d:16, e:9, f:5]\n//\n// Step 2: Combine f(5) and e(9) \u2192 14\n//         [a:45, b:13, c:12, d:16, fe:14]\n//\n// Step 3: Combine c(12) and b(13) \u2192 25\n//         [a:45, d:16, fe:14, cb:25]\n//\n// Step 4: Combine fe(14) and d(16) \u2192 30\n//         [a:45, cb:25, fed:30]\n//\n// Step 5: Combine cb(25) and fed(30) \u2192 55\n//         [a:45, cbfed:55]\n//\n// Step 6: Combine a(45) and cbfed(55) \u2192 100\n//         [acbfed:100]\n//\n// Output: Huffman codes\n// a: 0\n// b: 101\n// c: 100\n// d: 111\n// e: 1101\n// f: 1100",
    "keySteps": [
      "Create: Leaf nodes for each character",
      "Build: Min-priority queue",
      "Combine: Two lowest frequency nodes",
      "Repeat: Until single tree remains"
    ]
  },
  "hopcroft-karp": {
    "name": "Hopcroft-Karp Algorithm",
    "type": "\u221aV E",
    "description": "Hopcroft-Karp Algorithm is an algorithm with time complexity O(\u221aV E). It is primarily used for maximum bipartite matching",
    "timeComplexity": "O(\u221aV E) &nbsp;|&nbsp; Space: O(V + E) &nbsp;|&nbsp; Use: Maximum bipartite matching\n    ",
    "spaceComplexity": "O(V + E) &nbsp;|&nbsp; Use: Maximum bipartite matching\n    ",
    "useCase": "Maximum bipartite matching\n    ",
    "pseudocode": "HOPCROFT-KARP(G):\n    // G is a bipartite graph with left set L and right set R\n    // Returns maximum matching\n    matching \u2190 empty map  // stores current matching\n    dist \u2190 empty map      // stores distances for BFS\n    \n    function BFS():\n        Q \u2190 empty queue\n        for each u in L:\n            if u is unmatched:\n                dist[u] \u2190 0\n                Q.enqueue(u)\n            else:\n                dist[u] \u2190 \u221e\n        dist[nil] \u2190 \u221e\n        \n        while Q is not empty:\n            u \u2190 Q.dequeue()\n            if dist[u] < dist[nil]:\n                for each v in G.adj[u]:\n                    if dist[matching[v]] = \u221e:\n                        dist[matching[v]] \u2190 dist[u] + 1\n                        Q.enqueue(matching[v])\n        return dist[nil] \u2260 \u221e\n    \n    function DFS(u):\n        if u \u2260 nil:\n            for each v in G.adj[u]:\n                if dist[matching[v]] = dist[u] + 1:\n                    if DFS(matching[v]):\n                        matching[v] \u2190 u\n                        matching[u] \u2190 v\n                        return true\n            dist[u] \u2190 \u221e\n            return false\n        return true\n    \n    // Main algorithm\n    while BFS():\n        for each u in L:\n            if u is unmatched:\n                DFS(u)\n    \n    return matching\n\n// Example:\n// Bipartite graph G:\n// L = {1, 2, 3}\n// R = {4, 5, 6}\n// Edges: (1,4), (1,5), (2,5), (2,6), (3,4), (3,6)\n//\n// Maximum matching:\n// 1-4, 2-5, 3-6",
    "keySteps": [
      "Finds maximum matching in bipartite graphs",
      "Uses layered graph approach with BFS and DFS",
      "More efficient than Ford-Fulkerson for bipartite graphs",
      "Optimal for dense bipartite graphs"
    ]
  },
  "heavy-light-decomposition": {
    "name": "Heavy-Light Decomposition",
    "type": "Algorithm",
    "description": "Heavy-Light Decomposition is an algorithm with time complexity O(log n). It is primarily used for tree path queries",
    "timeComplexity": "O(log n) per query &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Tree path queries\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Tree path queries\n    ",
    "useCase": "Tree path queries\n    ",
    "pseudocode": "HLD(G)\n    let size[1\u2025n] be a new array\n    let parent[1\u2025n] be a new array\n    let depth[1\u2025n] be a new array\n    let head[1\u2025n] be a new array\n    let pos[1\u2025n] be a new array\n\n    DFS-SIZE(G, 1, 0)\n    DFS-HLD(G, 1, 1)\n    return (size, parent, depth, head, pos)\n\nDFS-SIZE(G, u, p)\n    size[u] \u2190 1\n    parent[u] \u2190 p\n    for each v in G.Adj[u]\n        do if v \u2260 p\n            then depth[v] \u2190 depth[u] + 1\n                DFS-SIZE(G, v, u)\n                size[u] \u2190 size[u] + size[v]\n\nDFS-HLD(G, u, h)\n    head[u] \u2190 h\n    let heavy \u2190 NIL\n    let max_size \u2190 0\n\n    for each v in G.Adj[u]\n        do if v \u2260 parent[u] and size[v] > max_size\n            then heavy \u2190 v\n                max_size \u2190 size[v]\n\n    if heavy \u2260 NIL\n        then DFS-HLD(G, heavy, h)\n            for each v in G.Adj[u]\n                do if v \u2260 parent[u] and v \u2260 heavy\n                    then DFS-HLD(G, v, v)\n\n// Example:\n// Input: Tree with edges (1,2), (1,3), (2,4), (2,5), (3,6)\n//\n// DFS-SIZE:\n//   size = [6, 3, 2, 1, 1, 1]\n//   parent = [0, 1, 1, 2, 2, 3]\n//   depth = [0, 1, 1, 2, 2, 2]\n//\n// DFS-HLD:\n//   head = [1, 1, 3, 1, 1, 3]\n//   pos = [1, 2, 4, 3, 5, 6]\n//\n// Output: Decomposed tree with heavy paths",
    "keySteps": [
      "Compute: Subtree sizes and parent pointers",
      "Identify: Heavy edges and light edges",
      "Decompose: Tree into heavy paths"
    ]
  },
  "heap": {
    "name": "Heap",
    "type": "log n",
    "description": "Heap is an algorithm with time complexity O(log n). It is primarily used for priority queue implementation",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Priority queue implementation\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Priority queue implementation\n    ",
    "useCase": "Priority queue implementation\n    ",
    "pseudocode": "// Get parent index\nPARENT(i):\n  return \u230ai/2\u230b\n\n// Get left child index\nLEFT(i):\n  return 2i\n\n// Get right child index\nRIGHT(i):\n  return 2i + 1\n\n// Maintain heap property\nMAX-HEAPIFY(A, i):\n  l = LEFT(i)\n  r = RIGHT(i)\n  largest = i\n  if l \u2264 A.heap-size and A[l] > A[i]:\n    largest = l\n  if r \u2264 A.heap-size and A[r] > A[largest]:\n    largest = r\n  if largest \u2260 i:\n    exchange A[i] with A[largest]\n    MAX-HEAPIFY(A, largest)\n\n// Build max heap\nBUILD-MAX-HEAP(A):\n  A.heap-size = A.length\n  for i = \u230aA.length/2\u230b downto 1:\n    MAX-HEAPIFY(A, i)\n\n// Extract maximum element\nHEAP-EXTRACT-MAX(A):\n  if A.heap-size < 1:\n    error \"heap underflow\"\n  max = A[1]\n  A[1] = A[A.heap-size]\n  A.heap-size = A.heap-size - 1\n  MAX-HEAPIFY(A, 1)\n  return max\n\n// Increase key value\nHEAP-INCREASE-KEY(A, i, key):\n  if key < A[i]:\n    error \"new key is smaller than current key\"\n  A[i] = key\n  while i > 1 and A[PARENT(i)] < A[i]:\n    exchange A[i] with A[PARENT(i)]\n    i = PARENT(i)\n\n// Insert new element\nMAX-HEAP-INSERT(A, key):\n  A.heap-size = A.heap-size + 1\n  A[A.heap-size] = -\u221e\n  HEAP-INCREASE-KEY(A, A.heap-size, key)",
    "keySteps": []
  },
  "heap-sort": {
    "name": "Heap Sort",
    "type": "Algorithm",
    "description": "Heap Sort is an algorithm with time complexity O(n log n). It is primarily used for in-place sorting with guaranteed       performance",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: In-place sorting with guaranteed\n      performance\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: In-place sorting with guaranteed\n      performance\n    ",
    "useCase": "In-place sorting with guaranteed\n      performance\n    ",
    "pseudocode": "// Standard Heap Sort\nHEAP-SORT(A):\n    n = len(A)\n\n    # Build max heap\n    for i = n//2 - 1 downto 0:\n        MAX-HEAPIFY(A, n, i)\n\n    # Extract elements one by one\n    for i = n-1 downto 0:\n        # Move current root to end\n        swap(A[0], A[i])\n        # Heapify reduced heap\n        MAX-HEAPIFY(A, i, 0)\n\nMAX-HEAPIFY(A, n, i):\n    largest = i\n    left = 2*i + 1\n    right = 2*i + 2\n\n    # Find largest among root and children\n    if left < n and A[left] > A[largest]:\n        largest = left\n    if right < n and A[right] > A[largest]:\n        largest = right\n\n    # If root is not largest, swap and heapify\n    if largest != i:\n        swap(A[i], A[largest])\n        MAX-HEAPIFY(A, n, largest)\n\n// Min Heap Sort\nMIN-HEAP-SORT(A):\n    n = len(A)\n\n    # Build min heap\n    for i = n//2 - 1 downto 0:\n        MIN-HEAPIFY(A, n, i)\n\n    # Extract elements one by one\n    for i = n-1 downto 0:\n        # Move current root to end\n        swap(A[0], A[i])\n        # Heapify reduced heap\n        MIN-HEAPIFY(A, i, 0)\n\nMIN-HEAPIFY(A, n, i):\n    smallest = i\n    left = 2*i + 1\n    right = 2*i + 2\n\n    # Find smallest among root and children\n    if left < n and A[left] < A[smallest]:\n        smallest = left\n    if right < n and A[right] < A[smallest]:\n        smallest = right\n\n    # If root is not smallest, swap and heapify\n    if smallest != i:\n        swap(A[i], A[smallest])\n        MIN-HEAPIFY(A, n, smallest)\n\n// Heap Sort with Custom Comparator\nHEAP-SORT-COMPARATOR(A, compare):\n    n = len(A)\n\n    # Build heap with custom comparator\n    for i = n//2 - 1 downto 0:\n        HEAPIFY-COMPARATOR(A, n, i, compare)\n\n    # Extract elements one by one\n    for i = n-1 downto 0:\n        swap(A[0], A[i])\n        HEAPIFY-COMPARATOR(A, i, 0, compare)\n\nHEAPIFY-COMPARATOR(A, n, i, compare):\n    target = i\n    left = 2*i + 1\n    right = 2*i + 2\n\n    # Find target using comparator\n    if left < n and compare(A[left], A[target]):\n        target = left\n    if right < n and compare(A[right], A[target]):\n        target = right\n\n    # If root is not target, swap and heapify\n    if target != i:\n        swap(A[i], A[target])\n        HEAPIFY-COMPARATOR(A, n, target, compare)",
    "keySteps": []
  },
  "heap-implementation": {
    "name": "Heap Implementation",
    "type": "Algorithm",
    "description": "Heap Implementation is an algorithm with time complexity O(log n). It is primarily used for priority queue operations",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Priority queue operations\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Priority queue operations\n    ",
    "useCase": "Priority queue operations\n    ",
    "pseudocode": "// Get parent index\nPARENT(i):\n    return \u230ai/2\u230b\n\n// Get left child index\nLEFT(i):\n    return 2i\n\n// Get right child index\nRIGHT(i):\n    return 2i + 1\n\n// Maintain heap property\nMAX-HEAPIFY(A, i):\n    l \u2190 LEFT(i)\n    r \u2190 RIGHT(i)\n    largest \u2190 i\n    if l \u2264 A.heap-size and A[l] > A[i]:\n        largest \u2190 l\n    if r \u2264 A.heap-size and A[r] > A[largest]:\n        largest \u2190 r\n    if largest \u2260 i:\n        exchange A[i] with A[largest]\n        MAX-HEAPIFY(A, largest)\n\n// Build max heap\nBUILD-MAX-HEAP(A):\n    A.heap-size \u2190 A.length\n    for i \u2190 \u230aA.length/2\u230b downto 1:\n        MAX-HEAPIFY(A, i)\n\n// Extract maximum element\nHEAP-EXTRACT-MAX(A):\n    if A.heap-size < 1:\n        error \"heap underflow\"\n    max \u2190 A[1]\n    A[1] \u2190 A[A.heap-size]\n    A.heap-size \u2190 A.heap-size - 1\n    MAX-HEAPIFY(A, 1)\n    return max\n\n// Increase key value\nHEAP-INCREASE-KEY(A, i, key):\n    if key < A[i]:\n        error \"new key is smaller than current key\"\n    A[i] \u2190 key\n    while i > 1 and A[PARENT(i)] < A[i]:\n        exchange A[i] with A[PARENT(i)]\n        i \u2190 PARENT(i)\n\n// Insert new element\nMAX-HEAP-INSERT(A, key):\n    A.heap-size \u2190 A.heap-size + 1\n    A[A.heap-size] \u2190 -\u221e\n    HEAP-INCREASE-KEY(A, A.heap-size, key)\n\n// Example:\n// Input: [4, 1, 3, 2, 16, 9, 10, 14, 8, 7]\n//\n// After BUILD-MAX-HEAP:\n//       16\n//     /    \\\\\n//   14      10\n//  /  \\\\    /  \\\\\n// 8    7  9    3\n// / \\\\  /\n// 2  4 1\n//\n// After HEAP-EXTRACT-MAX:\n//       14\n//     /    \\\\\n//   8       10\n//  / \\\\     / \\\\\n// 2   7   9   3\n// / \\\\\n// 1   4\n//\n// After MAX-HEAP-INSERT(15):\n//       15\n//     /    \\\\\n//   14      10\n//  /  \\\\    /  \\\\\n// 8    7  9    3\n// / \\\\  /\n// 2  4 1",
    "keySteps": [
      "Build: Create max heap from array using heapify",
      "Extract: Remove and return maximum element",
      "Insert: Add new element maintaining heap property"
    ]
  },
  "hash-table": {
    "name": "Hash Table",
    "type": "Data Structure",
    "description": "Hash Table is an algorithm with time complexity O(1). It is primarily used for fast key-value storage",
    "timeComplexity": "O(1) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Fast key-value storage\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Fast key-value storage\n    ",
    "useCase": "Fast key-value storage\n    ",
    "pseudocode": "// Hash function\nHASH(k, m):\n  return k mod m\n\n// Initialize table\nHASH-TABLE-INIT(T, m):\n  T.size = m\n  T.table = new array[m]\n  for i = 1 to m:\n    T.table[i] = NIL\n\n// Insert key-value pair\nHASH-INSERT(T, k, v):\n  h = HASH(k, T.size)\n  if T.table[h] == NIL:\n    T.table[h] = new list\n  LIST-INSERT(T.table[h], (k, v))\n\n// Search for key\nHASH-SEARCH(T, k):\n  h = HASH(k, T.size)\n  if T.table[h] == NIL:\n    return NIL\n  for each (key, value) in T.table[h]:\n    if key == k:\n      return value\n  return NIL\n\n// Delete key\nHASH-DELETE(T, k):\n  h = HASH(k, T.size)\n  if T.table[h] == NIL:\n    return\n  for each (key, value) in T.table[h]:\n    if key == k:\n      LIST-DELETE(T.table[h], (key, value))\n      return",
    "keySteps": []
  },
  "grid-traversal": {
    "name": "Grid Traversal",
    "type": "Algorithm",
    "description": "Grid Traversal is an algorithm with time complexity O(mn). It is primarily used for matrix traversal and path finding",
    "timeComplexity": "O(mn) &nbsp;|&nbsp; Space: O(mn) &nbsp;|&nbsp; Use: Matrix traversal and path finding\n    ",
    "spaceComplexity": "O(mn) &nbsp;|&nbsp; Use: Matrix traversal and path finding\n    ",
    "useCase": "Matrix traversal and path finding\n    ",
    "pseudocode": "GRID-TRAVERSAL(G)\n    let m be the number of rows in G\n    let n be the number of columns in G\n    let visited[1\u2025m][1\u2025n] be a new array\n    let result[1\u2025m][1\u2025n] be a new array\n\n    for i \u2190 1 to m\n        do for j \u2190 1 to n\n            do visited[i][j] \u2190 false\n               result[i][j] \u2190 0\n\n    let queue be a new empty queue\n    queue.enqueue((1,1))\n    visited[1][1] \u2190 true\n    result[1][1] \u2190 1\n\n    while queue is not empty\n        do (i,j) \u2190 queue.dequeue()\n           for each (di,dj) in [(0,1), (1,0), (0,-1), (-1,0)]\n               do ni \u2190 i + di\n                  nj \u2190 j + dj\n                  if 1 \u2264 ni \u2264 m and 1 \u2264 nj \u2264 n and not visited[ni][nj]\n                      then visited[ni][nj] \u2190 true\n                           result[ni][nj] \u2190 result[i][j] + 1\n                           queue.enqueue((ni,nj))\n\n    return result\n\n// Example:\n// Input: G = [\n//   [1, 1, 1],\n//   [1, 0, 1],\n//   [1, 1, 1]\n// ]\n//\n// Initial state:\n//   visited = [\n//     [true, false, false],\n//     [false, false, false],\n//     [false, false, false]\n//   ]\n//   result = [\n//     [1, 0, 0],\n//     [0, 0, 0],\n//     [0, 0, 0]\n//   ]\n//\n// After first iteration:\n//   visited = [\n//     [true, true, false],\n//     [true, false, false],\n//     [false, false, false]\n//   ]\n//   result = [\n//     [1, 2, 0],\n//     [2, 0, 0],\n//     [0, 0, 0]\n//   ]\n//\n// Final result:\n//   [\n//     [1, 2, 3],\n//     [2, 0, 4],\n//     [3, 4, 5]\n//   ]",
    "keySteps": [
      "Initialize: Create visited and result matrices",
      "Process: Use BFS to traverse grid in all directions",
      "Update: Track visited cells and distance from start"
    ]
  },
  "greedy": {
    "name": "Greedy",
    "type": "n log n",
    "description": "Greedy is an algorithm with time complexity O(n log n). It is primarily used for make locally optimal choices",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Make locally optimal choices\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Make locally optimal choices\n    ",
    "useCase": "Make locally optimal choices\n    ",
    "pseudocode": "// Activity Selection\nACTIVITY-SELECTION(S):\n  sort S by finish time\n  A = [S[0]]\n  last = 0\n  for i from 1 to n-1:\n    if S[i].start \u2265 S[last].finish:\n      A.append(S[i])\n      last = i\n  return A\n\n// Fractional Knapsack\nKNAPSACK(W, V, C):\n  sort items by value/weight ratio\n  total = 0\n  for i from 0 to n-1:\n    if C \u2265 W[i]:\n      total += V[i]\n      C -= W[i]\n    else:\n      total += (C/W[i]) * V[i]\n      break\n  return total\n\n// Huffman Coding\nHUFFMAN(C):\n  Q = priority queue of C\n  for i from 1 to n-1:\n    x = EXTRACT-MIN(Q)\n    y = EXTRACT-MIN(Q)\n    z = new node\n    z.left = x\n    z.right = y\n    z.freq = x.freq + y.freq\n    INSERT(Q, z)\n  return EXTRACT-MIN(Q)\n\n// Dijkstra's Algorithm\nDIJKSTRA(G, s):\n  dist = [\u221e] * n\n  prev = [NIL] * n\n  dist[s] = 0\n  Q = priority queue of all vertices\n  while Q is not empty:\n    u = EXTRACT-MIN(Q)\n    for each v in G.adj[u]:\n      if dist[v] > dist[u] + G.weight(u, v):\n        dist[v] = dist[u] + G.weight(u, v)\n        prev[v] = u\n  return (dist, prev)",
    "keySteps": []
  },
  "greedy-prim": {
    "name": "Prim's Algorithm",
    "type": "Algorithm",
    "description": "Prim's Algorithm is an algorithm with time complexity O((V+E). It is primarily used for finding minimum spanning tree",
    "timeComplexity": "O((V+E)logV) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree\n    ",
    "useCase": "Finding minimum spanning tree\n    ",
    "pseudocode": "// Standard Prim's Algorithm\ndef prim(graph, start):\n    # Initialize MST and visited set\n    mst = []\n    visited = {start}\n\n    # Priority queue for edges\n    import heapq\n    edges = [(weight, start, neighbor)\n             for neighbor, weight in graph[start].items()]\n    heapq.heapify(edges)\n\n    while edges and len(visited) < len(graph):\n        # Get minimum weight edge\n        weight, u, v = heapq.heappop(edges)\n\n        if v not in visited:\n            visited.add(v)\n            mst.append((u, v, weight))\n\n            # Add new edges to queue\n            for neighbor, weight in graph[v].items():\n                if neighbor not in visited:\n                    heapq.heappush(edges, (weight, v, neighbor))\n\n    return mst\n\n// Prim's with Early Exit\ndef prim_with_max_weight(graph, start, max_weight):\n    mst = []\n    visited = {start}\n    total_weight = 0\n\n    edges = [(weight, start, neighbor)\n             for neighbor, weight in graph[start].items()]\n    heapq.heapify(edges)\n\n    while edges and len(visited) < len(graph):\n        weight, u, v = heapq.heappop(edges)\n\n        if v not in visited and total_weight + weight <= max_weight:\n            visited.add(v)\n            mst.append((u, v, weight))\n            total_weight += weight\n\n            for neighbor, weight in graph[v].items():\n                if neighbor not in visited:\n                    heapq.heappush(edges, (weight, v, neighbor))\n        elif total_weight + weight > max_weight:\n            break\n\n    return mst, total_weight\n\n// Prim's with Maximum Degree\ndef prim_with_max_degree(graph, start, max_degree):\n    mst = []\n    visited = {start}\n    degree = {node: 0 for node in graph}\n    degree[start] = 0\n\n    edges = [(weight, start, neighbor)\n             for neighbor, weight in graph[start].items()]\n    heapq.heapify(edges)\n\n    while edges and len(visited) < len(graph):\n        weight, u, v = heapq.heappop(edges)\n\n        if v not in visited and degree[u] < max_degree and degree[v] < max_degree:\n            visited.add(v)\n            mst.append((u, v, weight))\n            degree[u] += 1\n            degree[v] += 1\n\n            for neighbor, weight in graph[v].items():\n                if neighbor not in visited:\n                    heapq.heappush(edges, (weight, v, neighbor))\n\n    return mst",
    "keySteps": []
  },
  "greedy-kruskal": {
    "name": "Kruskal's Algorithm",
    "type": "E log E",
    "description": "Kruskal's Algorithm is an algorithm with time complexity O(E log E). It is primarily used for finding minimum spanning tree",
    "timeComplexity": "O(E log E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree\n    ",
    "useCase": "Finding minimum spanning tree\n    ",
    "pseudocode": "// Standard Kruskal's Algorithm\ndef kruskal(graph):\n    # Initialize MST and parent array\n    mst = []\n    parent = {node: node for node in graph}\n    rank = {node: 0 for node in graph}\n\n    # Sort edges by weight\n    edges = [(weight, u, v)\n             for u in graph\n             for v, weight in graph[u].items()]\n    edges.sort()\n\n    def find(u):\n        if parent[u] != u:\n            parent[u] = find(parent[u])\n        return parent[u]\n\n    def union(u, v):\n        u_root = find(u)\n        v_root = find(v)\n        if u_root == v_root:\n            return False\n        if rank[u_root] > rank[v_root]:\n            parent[v_root] = u_root\n        else:\n            parent[u_root] = v_root\n            if rank[u_root] == rank[v_root]:\n                rank[v_root] += 1\n        return True\n\n    # Process edges\n    for weight, u, v in edges:\n        if union(u, v):\n            mst.append((u, v, weight))\n\n    return mst\n\n// Kruskal's with Maximum Degree\ndef kruskal_with_max_degree(graph, max_degree):\n    mst = []\n    parent = {node: node for node in graph}\n    rank = {node: 0 for node in graph}\n    degree = {node: 0 for node in graph}\n\n    edges = [(weight, u, v)\n             for u in graph\n             for v, weight in graph[u].items()]\n    edges.sort()\n\n    def find(u):\n        if parent[u] != u:\n            parent[u] = find(parent[u])\n        return parent[u]\n\n    def union(u, v):\n        if degree[u] >= max_degree or degree[v] >= max_degree:\n            return False\n        u_root = find(u)\n        v_root = find(v)\n        if u_root == v_root:\n            return False\n        if rank[u_root] > rank[v_root]:\n            parent[v_root] = u_root\n        else:\n            parent[u_root] = v_root\n            if rank[u_root] == rank[v_root]:\n                rank[v_root] += 1\n        degree[u] += 1\n        degree[v] += 1\n        return True\n\n    for weight, u, v in edges:\n        if union(u, v):\n            mst.append((u, v, weight))\n\n    return mst\n\n// Kruskal's with Edge Limit\ndef kruskal_with_edge_limit(graph, max_edges):\n    mst = []\n    parent = {node: node for node in graph}\n    rank = {node: 0 for node in graph}\n\n    edges = [(weight, u, v)\n             for u in graph\n             for v, weight in graph[u].items()]\n    edges.sort()\n\n    def find(u):\n        if parent[u] != u:\n            parent[u] = find(parent[u])\n        return parent[u]\n\n    def union(u, v):\n        u_root = find(u)\n        v_root = find(v)\n        if u_root == v_root:\n            return False\n        if rank[u_root] > rank[v_root]:\n            parent[v_root] = u_root\n        else:\n            parent[u_root] = v_root\n            if rank[u_root] == rank[v_root]:\n                rank[v_root] += 1\n        return True\n\n    for weight, u, v in edges:\n        if len(mst) >= max_edges:\n            break\n        if union(u, v):\n            mst.append((u, v, weight))\n\n    return mst",
    "keySteps": []
  },
  "greedy-job-scheduling": {
    "name": "Job Scheduling",
    "type": "Algorithm",
    "description": "Job Scheduling is an algorithm with time complexity O(n log n). It is primarily used for scheduling jobs to maximize       profit or minimize completion time",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Scheduling jobs to maximize\n      profit or minimize completion time\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Scheduling jobs to maximize\n      profit or minimize completion time\n    ",
    "useCase": "Scheduling jobs to maximize\n      profit or minimize completion time\n    ",
    "pseudocode": "// Standard Job Scheduling\ndef job_scheduling(jobs):\n    # Sort jobs by finish time\n    jobs.sort(key=lambda x: x[1])\n\n    selected = []\n    last_finish = 0\n\n    for job in jobs:\n        start, finish, profit = job\n        if start >= last_finish:\n            selected.append(job)\n            last_finish = finish\n\n    return selected\n\n// Job Scheduling with Deadlines\ndef job_scheduling_deadlines(jobs):\n    # Sort jobs by profit in descending order\n    jobs.sort(key=lambda x: x[2], reverse=True)\n\n    max_deadline = max(job[1] for job in jobs)\n    schedule = [None] * (max_deadline + 1)\n\n    for job in jobs:\n        start, deadline, profit = job\n        # Find latest available slot\n        for slot in range(deadline, 0, -1):\n            if schedule[slot] is None:\n                schedule[slot] = job\n                break\n\n    return [job for job in schedule if job is not None]\n\n// Job Scheduling with Weights\ndef job_scheduling_weights(jobs):\n    # Sort jobs by profit/weight ratio\n    jobs.sort(key=lambda x: x[2]/x[1], reverse=True)\n\n    current_time = 0\n    total_profit = 0\n\n    for job in jobs:\n        duration, weight, profit = job\n        current_time += duration\n        total_profit += profit\n\n    return total_profit\n\n# Examples:\n\n# Standard Job Scheduling\n# Input:\n# jobs = [\n#     (1, 3, 5),  # (start, finish, profit)\n#     (2, 5, 6),\n#     (4, 6, 5),\n#     (6, 7, 4),\n#     (5, 8, 11)\n# ]\n# Output:\n# selected = [(1, 3, 5), (4, 6, 5), (6, 7, 4)]\n# Total profit: 14\n\n# Job Scheduling with Deadlines\n# Input:\n# jobs = [\n#     (1, 2, 100),  # (duration, deadline, profit)\n#     (1, 1, 19),\n#     (2, 2, 27),\n#     (1, 1, 25),\n#     (3, 1, 15)\n# ]\n# Output:\n# schedule = [(1, 2, 100), (1, 1, 25)]\n# Total profit: 125\n\n# Job Scheduling with Weights\n# Input:\n# jobs = [\n#     (2, 1, 100),  # (duration, weight, profit)\n#     (1, 1, 19),\n#     (2, 1, 27),\n#     (1, 1, 25),\n#     (3, 1, 15)\n# ]\n# Output:\n# total_profit = 186",
    "keySteps": [
      "Sort: Jobs by finish time, profit, or profit/weight ratio",
      "Select: Jobs that don't conflict with previous selections",
      "Update: Schedule or profit based on selected jobs"
    ]
  },
  "greedy-hungarian": {
    "name": "Hungarian Algorithm",
    "type": "Algorithm",
    "description": "Hungarian Algorithm is an algorithm with time complexity O(n\u00b3). It is primarily used for solve assignment problem",
    "timeComplexity": "O(n\u00b3) &nbsp;|&nbsp; Space: O(n\u00b2) &nbsp;|&nbsp; Use: Solve assignment problem\n    ",
    "spaceComplexity": "O(n\u00b2) &nbsp;|&nbsp; Use: Solve assignment problem\n    ",
    "useCase": "Solve assignment problem\n    ",
    "pseudocode": "// Hungarian algorithm for assignment problem\nHUNGARIAN(C):\n    n \u2190 rows[C]\n    // Step 1: Subtract row minima\n    for i \u2190 1 to n:\n        row_min \u2190 min(C[i, 1..n])\n        for j \u2190 1 to n:\n            C[i, j] \u2190 C[i, j] - row_min\n\n    // Step 2: Subtract column minima\n    for j \u2190 1 to n:\n        col_min \u2190 min(C[1..n, j])\n        for i \u2190 1 to n:\n            C[i, j] \u2190 C[i, j] - col_min\n\n    // Step 3: Find minimum number of lines\n    while true:\n        // Find maximum matching\n        matching \u2190 FIND-MAX-MATCHING(C)\n        if size(matching) = n:\n            return matching\n\n        // Find minimum uncovered value\n        min_val \u2190 \u221e\n        for i \u2190 1 to n:\n            for j \u2190 1 to n:\n                if not covered[i] and not covered[j]:\n                    min_val \u2190 min(min_val, C[i, j])\n\n        // Update matrix\n        for i \u2190 1 to n:\n            for j \u2190 1 to n:\n                if not covered[i] and not covered[j]:\n                    C[i, j] \u2190 C[i, j] - min_val\n                else if covered[i] and covered[j]:\n                    C[i, j] \u2190 C[i, j] + min_val\n\n// Example:\n// Input: C = [\n//   [3, 5, 6],\n//   [2, 4, 7],\n//   [3, 5, 8]\n// ]\n//\n// Step 1: Subtract row minima\n// [\n//   [0, 2, 3],\n//   [0, 2, 5],\n//   [0, 2, 5]\n// ]\n//\n// Step 2: Subtract column minima\n// [\n//   [0, 0, 0],\n//   [0, 0, 2],\n//   [0, 0, 2]\n// ]\n//\n// Step 3: Find matching\n// Output: {(1,1), (2,2), (3,3)}",
    "keySteps": [
      "Reduce: Subtract row and column minima",
      "Match: Find maximum matching",
      "Update: Adjust matrix until perfect matching"
    ]
  },
  "greedy-huffman-coding": {
    "name": "Huffman Coding",
    "type": "Algorithm",
    "description": "Huffman Coding is an algorithm with time complexity O(n log n). It is primarily used for data compression",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Data compression\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Data compression\n    ",
    "useCase": "Data compression\n    ",
    "pseudocode": "// Standard Huffman Coding\nclass Node:\n    def __init__(self, symbol=None, freq=0, left=None, right=None):\n        self.symbol = symbol\n        self.freq = freq\n        self.left = left\n        self.right = right\n\ndef build_huffman_tree(frequencies):\n    # Create leaf nodes\n    nodes = [Node(symbol, freq) for symbol, freq in frequencies.items()]\n\n    # Build tree\n    while len(nodes) > 1:\n        # Get two nodes with minimum frequency\n        nodes.sort(key=lambda x: x.freq)\n        left = nodes.pop(0)\n        right = nodes.pop(0)\n\n        # Create new internal node\n        internal = Node(freq=left.freq + right.freq, left=left, right=right)\n        nodes.append(internal)\n\n    return nodes[0]\n\ndef build_codes(node, prefix=\"\", codes={}):\n    if node.symbol is not None:\n        codes[node.symbol] = prefix\n    else:\n        build_codes(node.left, prefix + \"0\", codes)\n        build_codes(node.right, prefix + \"1\", codes)\n    return codes\n\n// Adaptive Huffman Coding\nclass AdaptiveNode:\n    def __init__(self, symbol=None, freq=0, left=None, right=None, parent=None):\n        self.symbol = symbol\n        self.freq = freq\n        self.left = left\n        self.right = right\n        self.parent = parent\n\ndef update_tree(node):\n    # Update frequencies\n    while node is not None:\n        node.freq += 1\n        node = node.parent\n\n// Canonical Huffman Coding\ndef build_canonical_codes(lengths):\n    # Sort symbols by code length\n    symbols = sorted(lengths.items(), key=lambda x: (x[1], x[0]))\n\n    # Generate canonical codes\n    code = 0\n    prev_length = 0\n    codes = {}\n\n    for symbol, length in symbols:\n        if length > prev_length:\n            code <<= (length - prev_length)\n        codes[symbol] = format(code, f'0{length}b')\n        code += 1\n        prev_length = length\n\n    return codes",
    "keySteps": []
  },
  "greedy-fractional-knapsack": {
    "name": "Fractional Knapsack Problem",
    "type": "Algorithm",
    "description": "Fractional Knapsack Problem is an algorithm with time complexity O(nW). It is primarily used for optimal item selection with weight       constraint",
    "timeComplexity": "O(nW) &nbsp;|&nbsp; Space: O(nW) &nbsp;|&nbsp; Use: Optimal item selection with weight\n      constraint\n    ",
    "spaceComplexity": "O(nW) &nbsp;|&nbsp; Use: Optimal item selection with weight\n      constraint\n    ",
    "useCase": "Optimal item selection with weight\n      constraint\n    ",
    "pseudocode": "// 0-1 Knapsack problem\nKNAPSACK(w, v, W):\n    n \u2190 length[w]\n    // Initialize DP table\n    let dp[0..n, 0..W] be a new table\n    for i \u2190 0 to n:\n        for j \u2190 0 to W:\n            dp[i, j] \u2190 0\n\n    // Fill DP table\n    for i \u2190 1 to n:\n        for j \u2190 0 to W:\n            if w[i] > j:\n                dp[i, j] \u2190 dp[i-1, j]\n            else:\n                dp[i, j] \u2190 max(dp[i-1, j], v[i] + dp[i-1, j-w[i]])\n\n    // Reconstruct solution\n    j \u2190 W\n    S \u2190 \u2205\n    for i \u2190 n downto 1:\n        if dp[i, j] \u2260 dp[i-1, j]:\n            S \u2190 S \u222a {i}\n            j \u2190 j - w[i]\n\n    return dp[n, W], S\n\n// Example:\n// Input: w = [2, 3, 4, 5], v = [3, 4, 5, 6], W = 5\n//\n// DP Table:\n//   0 1 2 3 4 5\n// 0 0 0 0 0 0 0\n// 1 0 0 3 3 3 3\n// 2 0 0 3 4 4 7\n// 3 0 0 3 4 5 7\n// 4 0 0 3 4 5 7\n//\n// Output: max_value = 7, items = {1, 2}",
    "keySteps": [
      "Initialize: Create DP table",
      "Fill: Compute optimal values",
      "Reconstruct: Find selected items"
    ]
  },
  "greedy-ford-fulkerson": {
    "name": "Ford-Fulkerson Algorithm",
    "type": "Algorithm",
    "description": "Ford-Fulkerson Algorithm is an algorithm with time complexity O(E * max_flow). It is primarily used for finding maximum flow in       networks",
    "timeComplexity": "O(E * max_flow) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding maximum flow in\n      networks\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding maximum flow in\n      networks\n    ",
    "useCase": "Finding maximum flow in\n      networks\n    ",
    "pseudocode": "// Standard Ford-Fulkerson\ndef ford_fulkerson(graph, source, sink):\n    # Initialize residual graph and max flow\n    residual = {u: {v: graph[u][v] for v in graph[u]}\n                for u in graph}\n    max_flow = 0\n\n    def bfs():\n        # Find augmenting path using BFS\n        parent = {source: None}\n        queue = [source]\n\n        while queue:\n            u = queue.pop(0)\n            for v in residual[u]:\n                if v not in parent and residual[u][v] > 0:\n                    parent[v] = u\n                    if v == sink:\n                        return parent\n                    queue.append(v)\n        return None\n\n    # Find and process augmenting paths\n    while True:\n        parent = bfs()\n        if not parent:\n            break\n\n        # Find minimum residual capacity\n        path_flow = float('inf')\n        v = sink\n        while v != source:\n            u = parent[v]\n            path_flow = min(path_flow, residual[u][v])\n            v = u\n\n        # Update residual capacities\n        v = sink\n        while v != source:\n            u = parent[v]\n            residual[u][v] -= path_flow\n            residual[v][u] += path_flow\n            v = u\n\n        max_flow += path_flow\n\n    return max_flow\n\n// Ford-Fulkerson with Capacity Scaling\ndef ford_fulkerson_capacity_scaling(graph, source, sink):\n    residual = {u: {v: graph[u][v] for v in graph[u]}\n                for u in graph}\n    max_flow = 0\n\n    # Find maximum capacity\n    max_capacity = max(graph[u][v]\n                      for u in graph\n                      for v in graph[u])\n\n    # Start with largest power of 2\n    delta = 1\n    while delta * 2 <= max_capacity:\n        delta *= 2\n\n    def bfs(delta):\n        parent = {source: None}\n        queue = [source]\n\n        while queue:\n            u = queue.pop(0)\n            for v in residual[u]:\n                if v not in parent and residual[u][v] >= delta:\n                    parent[v] = u\n                    if v == sink:\n                        return parent\n                    queue.append(v)\n        return None\n\n    while delta >= 1:\n        while True:\n            parent = bfs(delta)\n            if not parent:\n                break\n\n            path_flow = float('inf')\n            v = sink\n            while v != source:\n                u = parent[v]\n                path_flow = min(path_flow, residual[u][v])\n                v = u\n\n            v = sink\n            while v != source:\n                u = parent[v]\n                residual[u][v] -= path_flow\n                residual[v][u] += path_flow\n                v = u\n\n            max_flow += path_flow\n\n        delta //= 2\n\n    return max_flow\n\n// Ford-Fulkerson with Multiple Sources/Sinks\ndef ford_fulkerson_multiple(graph, sources, sinks):\n    # Add super source and super sink\n    super_source = 'S'\n    super_sink = 'T'\n\n    # Initialize residual graph\n    residual = {u: {v: graph[u][v] for v in graph[u]}\n                for u in graph}\n    residual[super_source] = {s: float('inf') for s in sources}\n    residual[super_sink] = {}\n\n    for u in graph:\n        if u not in residual:\n            residual[u] = {}\n        if u in sinks:\n            residual[u][super_sink] = float('inf')\n\n    max_flow = 0\n\n    def bfs():\n        parent = {super_source: None}\n        queue = [super_source]\n\n        while queue:\n            u = queue.pop(0)\n            for v in residual[u]:\n                if v not in parent and residual[u][v] > 0:\n                    parent[v] = u\n                    if v == super_sink:\n                        return parent\n                    queue.append(v)\n        return None\n\n    while True:\n        parent = bfs()\n        if not parent:\n            break\n\n        path_flow = float('inf')\n        v = super_sink\n        while v != super_source:\n            u = parent[v]\n            path_flow = min(path_flow, residual[u][v])\n            v = u\n\n        v = super_sink\n        while v != super_source:\n            u = parent[v]\n            residual[u][v] -= path_flow\n            residual[v][u] += path_flow\n            v = u\n\n        max_flow += path_flow\n\n    return max_flow",
    "keySteps": []
  },
  "greedy-edmonds-karp": {
    "name": "Edmonds-Karp Algorithm",
    "type": "Algorithm",
    "description": "Edmonds-Karp Algorithm is an algorithm with time complexity O(VE\u00b2). It is primarily used for finding maximum flow in networks",
    "timeComplexity": "O(VE\u00b2) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding maximum flow in networks\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding maximum flow in networks\n    ",
    "useCase": "Finding maximum flow in networks\n    ",
    "pseudocode": "// Standard Edmonds-Karp\ndef edmonds_karp(graph, source, sink):\n    # Initialize residual graph and max flow\n    residual = {u: {v: graph[u][v] for v in graph[u]}\n                for u in graph}\n    max_flow = 0\n\n    def bfs():\n        # Find shortest augmenting path using BFS\n        parent = {source: None}\n        queue = [source]\n\n        while queue:\n            u = queue.pop(0)\n            for v in residual[u]:\n                if v not in parent and residual[u][v] > 0:\n                    parent[v] = u\n                    if v == sink:\n                        return parent\n                    queue.append(v)\n        return None\n\n    # Find and process augmenting paths\n    while True:\n        parent = bfs()\n        if not parent:\n            break\n\n        # Find minimum residual capacity\n        path_flow = float('inf')\n        v = sink\n        while v != source:\n            u = parent[v]\n            path_flow = min(path_flow, residual[u][v])\n            v = u\n\n        # Update residual capacities\n        v = sink\n        while v != source:\n            u = parent[v]\n            residual[u][v] -= path_flow\n            residual[v][u] += path_flow\n            v = u\n\n        max_flow += path_flow\n\n    return max_flow\n\n// Edmonds-Karp with Edge Capacities\ndef edmonds_karp_edge_capacities(graph, source, sink, min_capacity):\n    residual = {u: {v: graph[u][v] for v in graph[u]}\n                for u in graph}\n    max_flow = 0\n\n    def bfs():\n        parent = {source: None}\n        queue = [source]\n\n        while queue:\n            u = queue.pop(0)\n            for v in residual[u]:\n                if v not in parent and residual[u][v] >= min_capacity:\n                    parent[v] = u\n                    if v == sink:\n                        return parent\n                    queue.append(v)\n        return None\n\n    while True:\n        parent = bfs()\n        if not parent:\n            break\n\n        path_flow = float('inf')\n        v = sink\n        while v != source:\n            u = parent[v]\n            path_flow = min(path_flow, residual[u][v])\n            v = u\n\n        v = sink\n        while v != source:\n            u = parent[v]\n            residual[u][v] -= path_flow\n            residual[v][u] += path_flow\n            v = u\n\n        max_flow += path_flow\n\n    return max_flow\n\n// Edmonds-Karp with Vertex Capacities\ndef edmonds_karp_vertex_capacities(graph, source, sink, vertex_capacities):\n    # Split each vertex into in and out nodes\n    residual = {}\n    for u in graph:\n        residual[f\"{u}_in\"] = {f\"{u}_out\": vertex_capacities[u]}\n        residual[f\"{u}_out\"] = {}\n\n    # Add original edges\n    for u in graph:\n        for v in graph[u]:\n            residual[f\"{u}_out\"][f\"{v}_in\"] = graph[u][v]\n\n    # Add source and sink\n    residual[source] = {f\"{source}_in\": float('inf')}\n    residual[f\"{sink}_out\"] = {sink: float('inf')}\n\n    max_flow = 0\n\n    def bfs():\n        parent = {source: None}\n        queue = [source]\n\n        while queue:\n            u = queue.pop(0)\n            for v in residual[u]:\n                if v not in parent and residual[u][v] > 0:\n                    parent[v] = u\n                    if v == sink:\n                        return parent\n                    queue.append(v)\n        return None\n\n    while True:\n        parent = bfs()\n        if not parent:\n            break\n\n        path_flow = float('inf')\n        v = sink\n        while v != source:\n            u = parent[v]\n            path_flow = min(path_flow, residual[u][v])\n            v = u\n\n        v = sink\n        while v != source:\n            u = parent[v]\n            residual[u][v] -= path_flow\n            residual[v][u] += path_flow\n            v = u\n\n        max_flow += path_flow\n\n    return max_flow",
    "keySteps": []
  },
  "greedy-dinic": {
    "name": "Dinic's Algorithm",
    "type": "Algorithm",
    "description": "Dinic's Algorithm is an algorithm with time complexity O(V\u00b2E). It is primarily used for finding maximum flow in networks",
    "timeComplexity": "O(V\u00b2E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding maximum flow in networks\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding maximum flow in networks\n    ",
    "useCase": "Finding maximum flow in networks\n    ",
    "pseudocode": "// Standard Dinic's Algorithm\ndef dinic(graph, source, sink):\n    # Initialize residual graph and max flow\n    residual = {u: {v: graph[u][v] for v in graph[u]}\n                for u in graph}\n    max_flow = 0\n\n    def bfs():\n        # Build level graph using BFS\n        level = {source: 0}\n        queue = [source]\n\n        while queue:\n            u = queue.pop(0)\n            for v in residual[u]:\n                if v not in level and residual[u][v] > 0:\n                    level[v] = level[u] + 1\n                    if v == sink:\n                        return level\n                    queue.append(v)\n        return None\n\n    def dfs(u, flow):\n        if u == sink:\n            return flow\n\n        for v in residual[u]:\n            if level[v] == level[u] + 1 and residual[u][v] > 0:\n                path_flow = dfs(v, min(flow, residual[u][v]))\n                if path_flow > 0:\n                    residual[u][v] -= path_flow\n                    residual[v][u] += path_flow\n                    return path_flow\n        return 0\n\n    # Find blocking flows\n    while True:\n        level = bfs()\n        if not level:\n            break\n\n        while True:\n            flow = dfs(source, float('inf'))\n            if flow == 0:\n                break\n            max_flow += flow\n\n    return max_flow",
    "keySteps": [
      "Initialize: Residual graph and max flow",
      "Build: Level graph using BFS",
      "Find: Blocking flow using DFS"
    ]
  },
  "greedy-activity-selection": {
    "name": "Greedy Activity Selection",
    "type": "Algorithm",
    "description": "Greedy Activity Selection is an algorithm with time complexity O(n log n). It is primarily used for select maximum number of       non-overlapping activities",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Select maximum number of\n      non-overlapping activities\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Select maximum number of\n      non-overlapping activities\n    ",
    "useCase": "Select maximum number of\n      non-overlapping activities\n    ",
    "pseudocode": "GREEDY-ACTIVITY-SELECTOR(s, f)\n    n \u2190 length[s]\n    A \u2190 {a\u2081}  // First activity is always selected\n    k \u2190 1\n    for m \u2190 2 to n\n        do if s[m] \u2265 f[k]\n            then A \u2190 A \u222a {a\u2098}\n                k \u2190 m\n    return A\n\n// Example:\n// Input: s = [1, 3, 0, 5, 8, 5]  // Start times\n//        f = [2, 4, 6, 7, 9, 9]  // Finish times\n//\n// Step 1: Sort activities by finish time\n//         a\u2081: (1,2)\n//         a\u2082: (3,4)\n//         a\u2083: (0,6)\n//         a\u2084: (5,7)\n//         a\u2085: (8,9)\n//         a\u2086: (5,9)\n//\n// Step 2: Select activities\n//         Select a\u2081 (1-2)\n//         Skip a\u2083 (overlaps)\n//         Select a\u2082 (3-4)\n//         Skip a\u2086 (overlaps)\n//         Select a\u2084 (5-7)\n//         Select a\u2085 (8-9)\n//\n// Output: {a\u2081, a\u2082, a\u2084, a\u2085}",
    "keySteps": [
      "Sort: Activities by finish time",
      "Select: First activity",
      "Iterate: Through remaining activities",
      "Add: Non-overlapping activities to set"
    ]
  },
  "graph-topological-sort": {
    "name": "Topological Sort",
    "type": "Algorithm",
    "description": "Topological Sort is an algorithm with time complexity O(V + E). It is primarily used for linear ordering of vertices in a       dag",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Linear ordering of vertices in a\n      DAG\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Linear ordering of vertices in a\n      DAG\n    ",
    "useCase": "Linear ordering of vertices in a\n      DAG\n    ",
    "pseudocode": "// DFS-based Topological Sort\nTOPOLOGICAL-SORT(G):\n    visited = [False] * |V|\n    order = []\n    for v in V:\n        if not visited[v]:\n            DFS(G, v, visited, order)\n    return reversed(order)\n\n// Kahn's Algorithm\nKAHN-TOPOLOGICAL-SORT(G):\n    in_degree = [0] * |V|\n    for v in V:\n        for u in G.adj[v]:\n            in_degree[u] += 1\n\n    queue = []\n    for v in V:\n        if in_degree[v] == 0:\n            queue.append(v)\n\n    order = []\n    while queue:\n        v = queue.pop(0)\n        order.append(v)\n        for u in G.adj[v]:\n            in_degree[u] -= 1\n            if in_degree[u] == 0:\n                queue.append(u)\n\n    if len(order) != |V|:\n        return \"Graph has a cycle\"\n    return order\n\n// Topological Sort with Cycle Detection\nTOPOLOGICAL-SORT-CYCLE(G):\n    visited = [False] * |V|\n    recursion_stack = [False] * |V|\n    order = []\n\n    for v in V:\n        if not visited[v]:\n            if DFS-CYCLE(G, v, visited, recursion_stack, order):\n                return \"Graph has a cycle\"\n\n    return reversed(order)\n\nDFS-CYCLE(G, v, visited, recursion_stack, order):\n    visited[v] = True\n    recursion_stack[v] = True\n\n    for u in G.adj[v]:\n        if not visited[u]:\n            if DFS-CYCLE(G, u, visited, recursion_stack, order):\n                return True\n        elif recursion_stack[u]:\n            return True\n\n    recursion_stack[v] = False\n    order.append(v)\n    return False",
    "keySteps": []
  },
  "graph-scc": {
    "name": "Strongly Connected Components",
    "type": "Algorithm",
    "description": "Strongly Connected Components is an algorithm with time complexity O(V + E). It is primarily used for finding strongly connected       components in directed graphs",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding strongly connected\n      components in directed graphs\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding strongly connected\n      components in directed graphs\n    ",
    "useCase": "Finding strongly connected\n      components in directed graphs\n    ",
    "pseudocode": "// Kosaraju's Algorithm\nKOSARAJU-SCC(G):\n    # First DFS pass\n    visited = [False] * |V|\n    order = []\n    for v in V:\n        if not visited[v]:\n            DFS(G, v, visited, order)\n\n    # Reverse graph\n    G_rev = REVERSE-GRAPH(G)\n\n    # Second DFS pass\n    visited = [False] * |V|\n    components = []\n    for v in reversed(order):\n        if not visited[v]:\n            component = []\n            DFS(G_rev, v, visited, component)\n            components.append(component)\n    return components\n\n// Tarjan's Algorithm\nTARJAN-SCC(G):\n    index = 0\n    indices = [-1] * |V|\n    low = [-1] * |V|\n    on_stack = [False] * |V|\n    stack = []\n    components = []\n\n    for v in V:\n        if indices[v] == -1:\n            STRONGLY-CONNECTED(v)\n    return components\n\nSTRONGLY-CONNECTED(v):\n    indices[v] = index\n    low[v] = index\n    index = index + 1\n    stack.append(v)\n    on_stack[v] = True\n\n    for w in G.adj[v]:\n        if indices[w] == -1:\n            STRONGLY-CONNECTED(w)\n            low[v] = min(low[v], low[w])\n        elif on_stack[w]:\n            low[v] = min(low[v], indices[w])\n\n    if low[v] == indices[v]:\n        component = []\n        while True:\n            w = stack.pop()\n            on_stack[w] = False\n            component.append(w)\n            if w == v:\n                break\n        components.append(component)\n\n// Gabow's Algorithm\nGABOW-SCC(G):\n    index = 0\n    indices = [-1] * |V|\n    path = []\n    components = []\n\n    for v in V:\n        if indices[v] == -1:\n            GABOW-DFS(v)\n    return components\n\nGABOW-DFS(v):\n    indices[v] = index\n    index = index + 1\n    path.append(v)\n\n    for w in G.adj[v]:\n        if indices[w] == -1:\n            GABOW-DFS(w)\n        else:\n            while path and indices[path[-1]] > indices[w]:\n                path.pop()\n\n    if path[-1] == v:\n        component = []\n        while True:\n            w = path.pop()\n            component.append(w)\n            if w == v:\n                break\n        components.append(component)",
    "keySteps": []
  },
  "graph-representation": {
    "name": "Graph Representation",
    "type": "V+E",
    "description": "Graph Representation is an algorithm with time complexity O(V+E). It is primarily used for efficient graph storage and       traversal",
    "timeComplexity": "O(V+E) &nbsp;|&nbsp; Space: O(V+E) &nbsp;|&nbsp; Use: Efficient graph storage and\n      traversal\n    ",
    "spaceComplexity": "O(V+E) &nbsp;|&nbsp; Use: Efficient graph storage and\n      traversal\n    ",
    "useCase": "Efficient graph storage and\n      traversal\n    ",
    "pseudocode": "// Adjacency List Representation\nADJ-LIST-REP(G):\n    n \u2190 |G.V|\n    Adj[1..n] \u2190 empty lists\n    for each edge (u, v) \u2208 G.E:\n        APPEND(Adj[u], v)\n        if G is undirected:\n            APPEND(Adj[v], u)\n    return Adj\n\n// Adjacency Matrix Representation\nADJ-MATRIX-REP(G):\n    n \u2190 |G.V|\n    M[1..n, 1..n] \u2190 0\n    for each edge (u, v) \u2208 G.E:\n        M[u, v] \u2190 1\n        if G is undirected:\n            M[v, u] \u2190 1\n    return M\n\n// Edge List Representation\nEDGE-LIST-REP(G):\n    E \u2190 empty list\n    for each edge (u, v) \u2208 G.E:\n        APPEND(E, (u, v))\n    return E\n\n// Example:\n// Input: G = (V, E) where\n// V = {1, 2, 3, 4}\n// E = {(1,2), (2,3), (3,4), (4,1)}\n//\n// Adjacency List:\n// 1: [2, 4]\n// 2: [1, 3]\n// 3: [2, 4]\n// 4: [3, 1]\n//\n// Adjacency Matrix:\n//   1 2 3 4\n// 1 0 1 0 1\n// 2 1 0 1 0\n// 3 0 1 0 1\n// 4 1 0 1 0\n//\n// Edge List:\n// [(1,2), (2,3), (3,4), (4,1)]",
    "keySteps": [
      "Adjacency List: O(V+E) space, efficient for sparse graphs",
      "Adjacency Matrix: O(V\u00b2) space, efficient for dense graphs",
      "Edge List: O(E) space, useful for algorithms that process edges",
      "Check edge existence: O(1) matrix, O(deg(v)) list"
    ]
  },
  "graph-prim": {
    "name": "Prim's Algorithm",
    "type": "Algorithm",
    "description": "Prim's Algorithm is an algorithm with time complexity O(E log V). It is primarily used for finding minimum spanning tree in       weighted graphs",
    "timeComplexity": "O(E log V) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree in\n      weighted graphs\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding minimum spanning tree in\n      weighted graphs\n    ",
    "useCase": "Finding minimum spanning tree in\n      weighted graphs\n    ",
    "pseudocode": "// Standard Prim's Algorithm\nPRIM(G):\n    # Initialize\n    key = [\u221e] * |V|\n    parent = [None] * |V|\n    in_mst = [False] * |V|\n\n    # Start with vertex 0\n    key[0] = 0\n\n    for _ in range(|V|):\n        # Find minimum key vertex\n        u = min((v for v in range(|V|) if not in_mst[v]), key=lambda v: key[v])\n        in_mst[u] = True\n\n        # Update keys of adjacent vertices\n        for v in G.adj[u]:\n            if not in_mst[v] and G.weight(u, v) < key[v]:\n                key[v] = G.weight(u, v)\n                parent[v] = u\n\n    return parent\n\n// Prim's with Priority Queue\nPRIM-PQ(G):\n    # Initialize\n    key = [\u221e] * |V|\n    parent = [None] * |V|\n    in_mst = [False] * |V|\n    pq = PriorityQueue()\n\n    # Start with vertex 0\n    key[0] = 0\n    pq.put((0, 0))\n\n    while not pq.empty():\n        _, u = pq.get()\n        if in_mst[u]:\n            continue\n\n        in_mst[u] = True\n        for v in G.adj[u]:\n            weight = G.weight(u, v)\n            if not in_mst[v] and weight < key[v]:\n                key[v] = weight\n                parent[v] = u\n                pq.put((weight, v))\n\n    return parent\n\n// Prim's with Fibonacci Heap\nPRIM-FH(G):\n    # Initialize\n    key = [\u221e] * |V|\n    parent = [None] * |V|\n    in_mst = [False] * |V|\n    fh = FibonacciHeap()\n\n    # Start with vertex 0\n    key[0] = 0\n    nodes = [fh.insert(key[v], v) for v in range(|V|)]\n\n    while not fh.empty():\n        u = fh.extract_min().value\n        in_mst[u] = True\n\n        for v in G.adj[u]:\n            weight = G.weight(u, v)\n            if not in_mst[v] and weight < key[v]:\n                key[v] = weight\n                parent[v] = u\n                fh.decrease_key(nodes[v], weight)\n\n    return parent",
    "keySteps": []
  },
  "graph-kosaraju": {
    "name": "Kosaraju's Algorithm",
    "type": "V + E",
    "description": "Kosaraju's Algorithm is an algorithm with time complexity O(V + E). It is primarily used for find strongly connected components",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find strongly connected components\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find strongly connected components\n    ",
    "useCase": "Find strongly connected components\n    ",
    "pseudocode": "KOSARAJU(G)\n    let n be the number of vertices in G\n    let visited[1\u2025n] be a new array\n    let order be a new empty stack\n    let components be a new empty list\n\n    for each vertex u in G.V\n        do visited[u] \u2190 FALSE\n\n    for each vertex u in G.V\n        do if not visited[u]\n            then DFS-FIRST(G, u, visited, order)\n\n    let G^T be the transpose of G\n    for each vertex u in G.V\n        do visited[u] \u2190 FALSE\n\n    while order is not empty\n        do let u \u2190 order.pop()\n            if not visited[u]\n                then let component be a new empty list\n                    DFS-SECOND(G^T, u, visited, component)\n                    components.append(component)\n\n    return components\n\nDFS-FIRST(G, u, visited, order)\n    visited[u] \u2190 TRUE\n    for each v in G.Adj[u]\n        do if not visited[v]\n            then DFS-FIRST(G, v, visited, order)\n    order.push(u)\n\nDFS-SECOND(G, u, visited, component)\n    visited[u] \u2190 TRUE\n    component.append(u)\n    for each v in G.Adj[u]\n        do if not visited[v]\n            then DFS-SECOND(G, v, visited, component)\n\n// Example:\n// Input: G with edges (1,2), (2,3), (3,1), (2,4), (4,5), (5,6), (6,4)\n//\n// First DFS:\n//   Order: [3, 2, 1, 6, 5, 4]\n//\n// Second DFS on G^T:\n//   Component 1: [1, 2, 3]\n//   Component 2: [4, 5, 6]\n//\n// Output: [[1, 2, 3], [4, 5, 6]]",
    "keySteps": [
      "First DFS: Fill order with vertices by finish time",
      "Transpose: Create reverse graph",
      "Second DFS: Process vertices in reverse order"
    ]
  },
  "graph-implementation": {
    "name": "Graph Implementation",
    "type": "Algorithm",
    "description": "Graph Implementation is an algorithm with time complexity O(V+E). It is primarily used for graph representation and traversal",
    "timeComplexity": "O(V+E) &nbsp;|&nbsp; Space: O(V+E) &nbsp;|&nbsp; Use: Graph representation and traversal\n    ",
    "spaceComplexity": "O(V+E) &nbsp;|&nbsp; Use: Graph representation and traversal\n    ",
    "useCase": "Graph representation and traversal\n    ",
    "pseudocode": "// Adjacency list representation\nGRAPH-ADJ-LIST(V, E):\n    n \u2190 length[V]\n    Adj[1..n] \u2190 empty lists\n    for each edge (u, v) \u2208 E:\n        APPEND(Adj[u], v)\n        if graph is undirected:\n            APPEND(Adj[v], u)\n    return Adj\n\n// Adjacency matrix representation\nGRAPH-ADJ-MATRIX(V, E):\n    n \u2190 length[V]\n    M[1..n, 1..n] \u2190 0\n    for each edge (u, v) \u2208 E:\n        M[u, v] \u2190 1\n        if graph is undirected:\n            M[v, u] \u2190 1\n    return M\n\n// Depth-first search\nDFS(G):\n    for each vertex u \u2208 G.V:\n        color[u] \u2190 WHITE\n        \u03c0[u] \u2190 NIL\n    time \u2190 0\n    for each vertex u \u2208 G.V:\n        if color[u] = WHITE:\n            DFS-VISIT(G, u)\n\nDFS-VISIT(G, u):\n    time \u2190 time + 1\n    d[u] \u2190 time\n    color[u] \u2190 GRAY\n    for each v \u2208 G.Adj[u]:\n        if color[v] = WHITE:\n            \u03c0[v] \u2190 u\n            DFS-VISIT(G, v)\n    color[u] \u2190 BLACK\n    time \u2190 time + 1\n    f[u] \u2190 time\n\n// Breadth-first search\nBFS(G, s):\n    for each vertex u \u2208 G.V - {s}:\n        color[u] \u2190 WHITE\n        d[u] \u2190 \u221e\n        \u03c0[u] \u2190 NIL\n    color[s] \u2190 GRAY\n    d[s] \u2190 0\n    \u03c0[s] \u2190 NIL\n    Q \u2190 empty queue\n    ENQUEUE(Q, s)\n    while Q not empty:\n        u \u2190 DEQUEUE(Q)\n        for each v \u2208 G.Adj[u]:\n            if color[v] = WHITE:\n                color[v] \u2190 GRAY\n                d[v] \u2190 d[u] + 1\n                \u03c0[v] \u2190 u\n                ENQUEUE(Q, v)\n        color[u] \u2190 BLACK\n\n// Example:\n// Input: V = {1, 2, 3, 4}, E = {(1,2), (2,3), (3,4), (4,1)}\n//\n// Adjacency List:\n//   1: [2, 4]\n//   2: [1, 3]\n//   3: [2, 4]\n//   4: [3, 1]\n//\n// Adjacency Matrix:\n//   1 2 3 4\n// 1 0 1 0 1\n// 2 1 0 1 0\n// 3 0 1 0 1\n// 4 1 0 1 0",
    "keySteps": [
      "Representation: Choose between adjacency list or matrix",
      "Traversal: Implement DFS and BFS algorithms",
      "Properties: Track discovery/finish times and predecessors"
    ]
  },
  "graph-floyd-warshall": {
    "name": "Floyd-Warshall Algorithm",
    "type": "Algorithm",
    "description": "Floyd-Warshall Algorithm is an algorithm with time complexity O(V\u00b3). It is primarily used for finding all pairs shortest paths in       weighted graphs",
    "timeComplexity": "O(V\u00b3) &nbsp;|&nbsp; Space: O(V\u00b2) &nbsp;|&nbsp; Use: Finding all pairs shortest paths in\n      weighted graphs\n    ",
    "spaceComplexity": "O(V\u00b2) &nbsp;|&nbsp; Use: Finding all pairs shortest paths in\n      weighted graphs\n    ",
    "useCase": "Finding all pairs shortest paths in\n      weighted graphs\n    ",
    "pseudocode": "// Standard Floyd-Warshall\nFLOYD-WARSHALL(G):\n    # Initialize distance matrix\n    dist = [[\u221e] * |V| for _ in range(|V|)]\n    for i in range(|V|):\n        dist[i][i] = 0\n    for (u, v, w) in G.E:\n        dist[u][v] = w\n\n    # Main algorithm\n    for k in range(|V|):\n        for i in range(|V|):\n            for j in range(|V|):\n                if dist[i][k] + dist[k][j] < dist[i][j]:\n                    dist[i][j] = dist[i][k] + dist[k][j]\n\n    return dist\n\n// Floyd-Warshall with Path Reconstruction\nFLOYD-WARSHALL-PATH(G):\n    # Initialize distance and next matrices\n    dist = [[\u221e] * |V| for _ in range(|V|)]\n    next = [[None] * |V| for _ in range(|V|)]\n\n    for i in range(|V|):\n        dist[i][i] = 0\n    for (u, v, w) in G.E:\n        dist[u][v] = w\n        next[u][v] = v\n\n    # Main algorithm\n    for k in range(|V|):\n        for i in range(|V|):\n            for j in range(|V|):\n                if dist[i][k] + dist[k][j] < dist[i][j]:\n                    dist[i][j] = dist[i][k] + dist[k][j]\n                    next[i][j] = next[i][k]\n\n    return dist, next\n\n// Path reconstruction\nRECONSTRUCT-PATH(u, v, next):\n    if next[u][v] is None:\n        return []\n    path = [u]\n    while u != v:\n        u = next[u][v]\n        path.append(u)\n    return path\n\n// Floyd-Warshall with Negative Cycle Detection\nFLOYD-WARSHALL-NEGATIVE(G):\n    # Initialize distance matrix\n    dist = [[\u221e] * |V| for _ in range(|V|)]\n    for i in range(|V|):\n        dist[i][i] = 0\n    for (u, v, w) in G.E:\n        dist[u][v] = w\n\n    # Main algorithm\n    for k in range(|V|):\n        for i in range(|V|):\n            for j in range(|V|):\n                if dist[i][k] + dist[k][j] < dist[i][j]:\n                    dist[i][j] = dist[i][k] + dist[k][j]\n\n    # Check for negative cycles\n    for i in range(|V|):\n        if dist[i][i] < 0:\n            return \"Graph contains negative cycle\"\n\n    return dist",
    "keySteps": []
  },
  "graph-dijkstra": {
    "name": "Dijkstra's Algorithm",
    "type": "Algorithm",
    "description": "Dijkstra's Algorithm is an algorithm with time complexity O((V + E). It is primarily used for single-source shortest       paths in weighted graphs",
    "timeComplexity": "O((V + E) log V) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Single-source shortest\n      paths in weighted graphs\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Single-source shortest\n      paths in weighted graphs\n    ",
    "useCase": "Single-source shortest\n      paths in weighted graphs\n    ",
    "pseudocode": "// Standard Dijkstra\nDIJKSTRA(G, w, s):\n  INITIALIZE-SINGLE-SOURCE(G, s)\n  S = \u2205\n  Q = G.V\n  while Q \u2260 \u2205:\n    u = EXTRACT-MIN(Q)\n    S = S \u222a {u}\n    for each v in G.adj[u]:\n      RELAX(u, v, w)\n\nINITIALIZE-SINGLE-SOURCE(G, s):\n  for each vertex v in G.V:\n    v.d = \u221e\n    v.\u03c0 = NIL\n  s.d = 0\n\nRELAX(u, v, w):\n  if v.d > u.d + w(u, v):\n    v.d = u.d + w(u, v)\n    v.\u03c0 = u\n\n// Priority Queue Implementation\nDIJKSTRA-PQ(G, w, s):\n  dist = [\u221e] * n\n  prev = [NIL] * n\n  dist[s] = 0\n  Q = priority queue of (vertex, distance)\n  while Q is not empty:\n    u = EXTRACT-MIN(Q)\n    for each v in G.adj[u]:\n      if dist[v] > dist[u] + w(u, v):\n        dist[v] = dist[u] + w(u, v)\n        prev[v] = u\n        DECREASE-KEY(Q, v, dist[v])\n  return (dist, prev)\n\n// Path Reconstruction\nGET-PATH(prev, s, t):\n  path = []\n  u = t\n  while u \u2260 NIL:\n    path.append(u)\n    u = prev[u]\n  return reverse(path)",
    "keySteps": []
  },
  "graph-bridges": {
    "name": "Bridges",
    "type": "V + E",
    "description": "Bridges is an algorithm with time complexity O(V + E). It is primarily used for find critical edges in graph",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find critical edges in graph\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find critical edges in graph\n    ",
    "useCase": "Find critical edges in graph\n    ",
    "pseudocode": "FIND-BRIDGES(G)\n    let n be the number of vertices in G\n    let disc[1\u2025n] be a new array\n    let low[1\u2025n] be a new array\n    let parent[1\u2025n] be a new array\n    let bridges be a new empty list\n    let time \u2190 0\n\n    for each vertex u in G.V\n        do disc[u] \u2190 -1\n            low[u] \u2190 -1\n            parent[u] \u2190 NIL\n\n    for each vertex u in G.V\n        do if disc[u] = -1\n            then DFS-BRIDGES(G, u, disc, low, parent, bridges, time)\n\n    return bridges\n\nDFS-BRIDGES(G, u, disc, low, parent, bridges, time)\n    time \u2190 time + 1\n    disc[u] \u2190 time\n    low[u] \u2190 time\n\n    for each v in G.Adj[u]\n        do if disc[v] = -1\n            then parent[v] \u2190 u\n                DFS-BRIDGES(G, v, disc, low, parent, bridges, time)\n                low[u] \u2190 min(low[u], low[v])\n                if low[v] > disc[u]\n                    then bridges.append((u,v))\n            else if v \u2260 parent[u]\n                then low[u] \u2190 min(low[u], disc[v])\n\n// Example:\n// Input: G with edges (1,2), (2,3), (3,4), (4,1), (1,3)\n//\n// DFS from vertex 1:\n//   disc = [1, 2, 3, 4]\n//   low = [1, 1, 1, 1]\n//   parent = [NIL, 1, 2, 3]\n//\n// Bridge check:\n//   Edge (2,3): low[3] = 1 > disc[2] = 2? No\n//   Edge (3,4): low[4] = 1 > disc[3] = 3? No\n//   Edge (4,1): low[1] = 1 > disc[4] = 4? No\n//   Edge (1,3): low[3] = 1 > disc[1] = 1? No\n//\n// Output: [] (no bridges)",
    "keySteps": [
      "Initialize: Set up discovery and low values",
      "DFS: Track discovery time and low values",
      "Identify: Check conditions for bridge edges"
    ]
  },
  "graph-bellman-ford": {
    "name": "Bellman-Ford Algorithm",
    "type": "Algorithm",
    "description": "Bellman-Ford Algorithm is an algorithm with time complexity O(VE). It is primarily used for finding single-source shortest paths       with negative weights",
    "timeComplexity": "O(VE) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding single-source shortest paths\n      with negative weights\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding single-source shortest paths\n      with negative weights\n    ",
    "useCase": "Finding single-source shortest paths\n      with negative weights\n    ",
    "pseudocode": "// Standard Bellman-Ford\nBELLMAN-FORD(G, s):\n    # Initialize\n    dist = [\u221e] * |V|\n    parent = [None] * |V|\n    dist[s] = 0\n\n    # Relax edges |V|-1 times\n    for i in range(|V|-1):\n        for (u, v, w) in G.E:\n            if dist[u] + w < dist[v]:\n                dist[v] = dist[u] + w\n                parent[v] = u\n\n    # Check for negative cycles\n    for (u, v, w) in G.E:\n        if dist[u] + w < dist[v]:\n            return \"Graph contains negative cycle\"\n\n    return dist, parent\n\n// Bellman-Ford with Path Reconstruction\nBELLMAN-FORD-PATH(G, s):\n    # Initialize\n    dist = [\u221e] * |V|\n    parent = [None] * |V|\n    dist[s] = 0\n\n    # Relax edges |V|-1 times\n    for i in range(|V|-1):\n        for (u, v, w) in G.E:\n            if dist[u] + w < dist[v]:\n                dist[v] = dist[u] + w\n                parent[v] = u\n\n    # Check for negative cycles\n    for (u, v, w) in G.E:\n        if dist[u] + w < dist[v]:\n            return \"Graph contains negative cycle\"\n\n    return dist, parent\n\n// Path reconstruction\nRECONSTRUCT-PATH(s, v, parent):\n    if v == s:\n        return [s]\n    if parent[v] is None:\n        return []\n    path = RECONSTRUCT-PATH(s, parent[v], parent)\n    path.append(v)\n    return path\n\n// Bellman-Ford with Early Termination\nBELLMAN-FORD-EARLY(G, s):\n    # Initialize\n    dist = [\u221e] * |V|\n    parent = [None] * |V|\n    dist[s] = 0\n\n    # Relax edges until no improvement\n    for i in range(|V|-1):\n        improved = False\n        for (u, v, w) in G.E:\n            if dist[u] + w < dist[v]:\n                dist[v] = dist[u] + w\n                parent[v] = u\n                improved = True\n        if not improved:\n            break\n\n    # Check for negative cycles\n    for (u, v, w) in G.E:\n        if dist[u] + w < dist[v]:\n            return \"Graph contains negative cycle\"\n\n    return dist, parent",
    "keySteps": []
  },
  "graph-basics": {
    "name": "Graph Basics",
    "type": "Data Structure",
    "description": "Graph Basics is an algorithm with time complexity O(V + E). It is primarily used for representing relationships between       objects",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Representing relationships between\n      objects\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Representing relationships between\n      objects\n    ",
    "useCase": "Representing relationships between\n      objects\n    ",
    "pseudocode": "// Graph representation\nGRAPH-REPRESENTATION(V, E):\n  G = new Graph\n  G.V = V  // Set of vertices\n  G.E = E  // Set of edges\n  G.adj = new Array(V.length + 1)  // Adjacency list\n  for v in V:\n    G.adj[v] = new List\n  for (u, v) in E:\n    G.adj[u].append(v)\n    G.adj[v].append(u)  // For undirected graph\n  return G\n\n// Depth-first search\nDFS(G, s):\n  for v in G.V:\n    v.color = WHITE\n    v.parent = NIL\n  time = 0\n  for v in G.V:\n    if v.color = WHITE:\n      DFS-VISIT(G, v)\n\nDFS-VISIT(G, u):\n  time = time + 1\n  u.d = time\n  u.color = GRAY\n  for v in G.adj[u]:\n    if v.color = WHITE:\n      v.parent = u\n      DFS-VISIT(G, v)\n  u.color = BLACK\n  time = time + 1\n  u.f = time\n\n// Breadth-first search\nBFS(G, s):\n  for v in G.V:\n    v.color = WHITE\n    v.d = \u221e\n    v.parent = NIL\n  s.color = GRAY\n  s.d = 0\n  s.parent = NIL\n  Q = new Queue\n  Q.enqueue(s)\n  while Q is not empty:\n    u = Q.dequeue()\n    for v in G.adj[u]:\n      if v.color = WHITE:\n        v.color = GRAY\n        v.d = u.d + 1\n        v.parent = u\n        Q.enqueue(v)\n    u.color = BLACK",
    "keySteps": []
  },
  "graph-articulation-points": {
    "name": "Articulation Points",
    "type": "Graph Algorithm",
    "description": "Articulation Points is an algorithm with time complexity O(V + E). It is primarily used for find critical vertices in graph",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find critical vertices in graph\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find critical vertices in graph\n    ",
    "useCase": "Find critical vertices in graph\n    ",
    "pseudocode": "FIND-ARTICULATION-POINTS(G)\n    let n be the number of vertices in G\n    let disc[1\u2025n] be a new array\n    let low[1\u2025n] be a new array\n    let parent[1\u2025n] be a new array\n    let ap[1\u2025n] be a new array\n    let time \u2190 0\n\n    for each vertex u in G.V\n        do disc[u] \u2190 -1\n            low[u] \u2190 -1\n            parent[u] \u2190 NIL\n            ap[u] \u2190 FALSE\n\n    for each vertex u in G.V\n        do if disc[u] = -1\n            then DFS-AP(G, u, disc, low, parent, ap, time)\n\n    return ap\n\nDFS-AP(G, u, disc, low, parent, ap, time)\n    let children \u2190 0\n    time \u2190 time + 1\n    disc[u] \u2190 time\n    low[u] \u2190 time\n\n    for each v in G.Adj[u]\n        do if disc[v] = -1\n            then children \u2190 children + 1\n                parent[v] \u2190 u\n                DFS-AP(G, v, disc, low, parent, ap, time)\n                low[u] \u2190 min(low[u], low[v])\n                if parent[u] = NIL and children > 1\n                    then ap[u] \u2190 TRUE\n                if parent[u] \u2260 NIL and low[v] \u2265 disc[u]\n                    then ap[u] \u2190 TRUE\n            else if v \u2260 parent[u]\n                then low[u] \u2190 min(low[u], disc[v])\n\n// Example:\n// Input: G with edges (1,2), (2,3), (3,4), (4,1), (1,3)\n//\n// DFS from vertex 1:\n//   disc = [1, 2, 3, 4]\n//   low = [1, 1, 1, 1]\n//   parent = [NIL, 1, 2, 3]\n//\n// Articulation points:\n//   Vertex 1: TRUE (root with multiple children)\n//   Vertex 2: FALSE\n//   Vertex 3: FALSE\n//   Vertex 4: FALSE\n//\n// Output: [TRUE, FALSE, FALSE, FALSE]",
    "keySteps": [
      "Initialize: Set up discovery and low values",
      "DFS: Track discovery time and low values",
      "Identify: Check conditions for articulation points"
    ]
  },
  "fractional-knapsack": {
    "name": "Fractional Knapsack",
    "type": "Algorithm",
    "description": "Fractional Knapsack is an algorithm with time complexity O(n log n). It is primarily used for maximize value while keeping       weight under capacity",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Maximize value while keeping\n      weight under capacity\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Maximize value while keeping\n      weight under capacity\n    ",
    "useCase": "Maximize value while keeping\n      weight under capacity\n    ",
    "pseudocode": "FRACTIONAL-KNAPSACK(W, w, v)\n    n \u2190 length[w]\n    for i \u2190 1 to n\n        do x[i] \u2190 0\n    weight \u2190 0\n    for i \u2190 1 to n\n        do if weight + w[i] \u2264 W\n            then x[i] \u2190 1\n                weight \u2190 weight + w[i]\n            else x[i] \u2190 (W - weight) / w[i]\n                weight \u2190 W\n                return x\n\n// Example:\n// Input: W = 50\n//        w = [10, 20, 30]\n//        v = [60, 100, 120]\n//\n// Step 1: Sort items by value/weight ratio\n//        [6, 5, 4]\n//\n// Step 2: Take items in order\n//        Take all of item 1 (10 units)\n//        Take all of item 2 (20 units)\n//        Take 20/30 of item 3\n//\n// Output: [1, 1, 0.666...]",
    "keySteps": [
      "Sort: Items by value/weight ratio",
      "Take: Items in order of highest ratio",
      "Fill: Take fraction of last item if needed"
    ]
  },
  "ford-fulkerson": {
    "name": "Ford-Fulkerson Algorithm",
    "type": "E|f*|",
    "description": "Ford-Fulkerson Algorithm is an algorithm with time complexity O(E|f*|). It is primarily used for maximum flow in networks",
    "timeComplexity": "O(E|f*|) &nbsp;|&nbsp; Space: O(V + E) &nbsp;|&nbsp; Use: Maximum flow in networks\n    ",
    "spaceComplexity": "O(V + E) &nbsp;|&nbsp; Use: Maximum flow in networks\n    ",
    "useCase": "Maximum flow in networks\n    ",
    "pseudocode": "FORD-FULKERSON(G, s, t):\n    // G is a flow network with source s and sink t\n    // Returns maximum flow value\n    for each edge (u,v) in G.E:\n        f[u,v] \u2190 0\n        f[v,u] \u2190 0\n    \n    while there exists path p from s to t in residual network Gf:\n        cf(p) \u2190 min{cf(u,v): (u,v) is in p}\n        for each edge (u,v) in p:\n            f[u,v] \u2190 f[u,v] + cf(p)\n            f[v,u] \u2190 -f[u,v]\n    \n    return sum of f[s,v] for all v\n\n// Example:\n// Flow network G:\n// s \u2192 1 \u2192 t\n//   \u2198 2 \u2197\n//\n// Capacities:\n// s\u21921: 10, s\u21922: 8\n// 1\u2192t: 4, 2\u2192t: 9\n//\n// Initial flow: 0\n// After first augmentation: 4\n// After second augmentation: 8\n// Final maximum flow: 12",
    "keySteps": [
      "Finds maximum flow in a flow network",
      "Uses residual networks and augmenting paths",
      "Can be implemented with different path-finding methods",
      "With Edmonds-Karp: O(VE\u00b2) time complexity"
    ]
  },
  "floyd-warshall": {
    "name": "Floyd-Warshall Algorithm",
    "type": "V\u00b3",
    "description": "Floyd-Warshall Algorithm is an algorithm with time complexity O(V\u00b3). It is primarily used for all-pairs shortest paths",
    "timeComplexity": "O(V\u00b3) &nbsp;|&nbsp; Space: O(V\u00b2) &nbsp;|&nbsp; Use: All-pairs shortest paths\n    ",
    "spaceComplexity": "O(V\u00b2) &nbsp;|&nbsp; Use: All-pairs shortest paths\n    ",
    "useCase": "All-pairs shortest paths\n    ",
    "pseudocode": "FLOYD-WARSHALL(G):\n    // G is a weighted directed graph\n    // Returns shortest paths between all pairs of vertices\n    n \u2190 number of vertices in G\n    dist[1..n][1..n] \u2190 \u221e\n    next[1..n][1..n] \u2190 null\n    \n    // Initialize distances\n    for each vertex v in G:\n        dist[v][v] \u2190 0\n    for each edge (u,v) in G:\n        dist[u][v] \u2190 weight(u,v)\n        next[u][v] \u2190 v\n    \n    // Main algorithm\n    for k \u2190 1 to n:\n        for i \u2190 1 to n:\n            for j \u2190 1 to n:\n                if dist[i][k] + dist[k][j] < dist[i][j]:\n                    dist[i][j] \u2190 dist[i][k] + dist[k][j]\n                    next[i][j] \u2190 next[i][k]\n    \n    return dist, next\n\n// Example:\n// Graph G:\n// 1 \u2192 2 (weight: 3)\n// 2 \u2192 3 (weight: 4)\n// 3 \u2192 1 (weight: 2)\n// 1 \u2192 3 (weight: 6)\n//\n// Initial dist matrix:\n// 0 3 6\n// \u221e 0 4\n// 2 \u221e 0\n//\n// Final dist matrix:\n// 0 3 6\n// 6 0 4\n// 2 5 0",
    "keySteps": [
      "Finds shortest paths between all pairs of vertices",
      "Handles negative edge weights (but not negative cycles)",
      "Can detect negative cycles through diagonal elements",
      "More efficient than running Dijkstra's V times for dense graphs"
    ]
  },
  "floyd-cycle-detection": {
    "name": "Floyd Cycle Detection",
    "type": "Algorithm",
    "description": "\n        A technique to detect cycles in linked lists using two pointers moving at different speeds\n      ",
    "timeComplexity": "O(n) where n is the number of nodes",
    "spaceComplexity": "O(1) using only two pointers",
    "useCase": "Detect cycles in linked lists, find cycle start node",
    "pseudocode": "FLOYD-CYCLE-DETECTION(head)\n    let slow \u2190 head\n    let fast \u2190 head\n\n    while fast \u2260 null and fast.next \u2260 null\n        do slow \u2190 slow.next\n           fast \u2190 fast.next.next\n           if slow = fast\n               then return true\n\n    return false\n\nFIND-CYCLE-START(head)\n    let slow \u2190 head\n    let fast \u2190 head\n\n    while fast \u2260 null and fast.next \u2260 null\n        do slow \u2190 slow.next\n           fast \u2190 fast.next.next\n           if slow = fast\n               then break\n\n    if fast = null or fast.next = null\n        then return null\n\n    slow \u2190 head\n    while slow \u2260 fast\n        do slow \u2190 slow.next\n           fast \u2190 fast.next\n\n    return slow\n\n// Example:\n// Input: 1 \u2192 2 \u2192 3 \u2192 4 \u2192 5 \u2192 3 (cycle back to 3)\n//\n// Initial state:\n//   slow = 1, fast = 1\n//\n// First iteration:\n//   slow = 2, fast = 3\n//\n// Second iteration:\n//   slow = 3, fast = 5\n//\n// Third iteration:\n//   slow = 4, fast = 3\n//\n// Fourth iteration:\n//   slow = 5, fast = 5 (cycle detected)\n//\n// Finding cycle start:\n//   slow = 1, fast = 5\n//   slow = 2, fast = 3\n//   slow = 3, fast = 3 (cycle start found)\n//\n// Output: Cycle exists, starts at node 3",
    "keySteps": [
      "Initialize: Set slow and fast pointers to head",
      "Detect: Move pointers at different speeds until they meet",
      "Find: Reset slow pointer and move both at same speed"
    ]
  },
  "fibonacci": {
    "name": "Fibonacci",
    "type": "Algorithm",
    "description": "A sequence where each number is the sum of the two preceding ones",
    "timeComplexity": "O(n) for iterative approach, O(2^n) for recursive",
    "spaceComplexity": "O(1) for iterative, O(n) for recursive call stack",
    "useCase": "Dynamic programming, sequence generation, mathematical modeling",
    "pseudocode": "function fibonacci(n):\n    if n <= 1:\n        return n\n    \n    a, b = 0, 1\n    for i in range(2, n + 1):\n        a, b = b, a + b\n    \n    return b",
    "keySteps": [
      "Initialize first two numbers (0 and 1)",
      "Iterate through sequence, updating values",
      "Use two variables to track previous numbers",
      "Return the nth number in the sequence"
    ]
  },
  "fibonacci-search": {
    "name": "Fibonacci Search",
    "type": "Algorithm",
    "description": "Fibonacci Search is an algorithm with time complexity O(log n). It is primarily used for search in sorted array using       fibonacci numbers",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Search in sorted array using\n      Fibonacci numbers\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Search in sorted array using\n      Fibonacci numbers\n    ",
    "useCase": "Search in sorted array using\n      Fibonacci numbers\n    ",
    "pseudocode": "FIBONACCI-SEARCH(A, x)\n1  // Initialize Fibonacci numbers\n2  fib2 = 0  // (m-2)'th Fibonacci number\n3  fib1 = 1  // (m-1)'th Fibonacci number\n4  fib = fib2 + fib1  // m'th Fibonacci number\n5\n6  // Find smallest Fibonacci number >= n\n7  while fib < n\n8      fib2 = fib1\n9      fib1 = fib\n10     fib = fib2 + fib1\n11\n12 // Initialize offset\n13 offset = -1\n14\n15 while fib {'>'} 1\n16     // Check if fib2 is valid index\n17     i = min(offset + fib2, n - 1)\n18\n19     // If x is greater than value at i,\n20     // cut the subarray from offset to i\n21     if A[i] < x\n22         fib = fib1\n23         fib1 = fib2\n24         fib2 = fib - fib1\n25         offset = i\n26\n27     // If x is less than value at i,\n28     // cut the subarray after i+1\n29     else if A[i] {'>'} x\n30         fib = fib2\n31         fib1 = fib1 - fib2\n32         fib2 = fib - fib1\n33\n34     // Element found\n35     else\n36         return i\n37\n38 // Compare last element\n39 if fib1 and A[offset + 1] == x\n40     return offset + 1\n41\n42 // Element not found\n43 return -1\n\n// Example:\n// Input: A = [1, 4, 6, 8, 9, 10, 14, 15, 16], x = 14\n//\n// Step 1: Find Fibonacci numbers\n//         fib2 = 5, fib1 = 8, fib = 13\n//\n// Step 2: Compare A[5] = 10 < 14\n//         offset = 5, fib2 = 3, fib1 = 5, fib = 8\n//\n// Step 3: Compare A[8] = 16 {'>'} 14\n//         fib2 = 2, fib1 = 3, fib = 5\n//\n// Step 4: Compare A[7] = 15 {'>'} 14\n//         fib2 = 1, fib1 = 2, fib = 3\n//\n// Step 5: Compare A[6] = 14 = 14\n//         Return 6",
    "keySteps": [
      "Initialize: Find smallest Fibonacci number {\">=\"} array length",
      "Compare: Use Fibonacci numbers to divide search space",
      "Update: Fibonacci numbers based on comparison result",
      "Return: Index if found, -1 if not found"
    ]
  },
  "fenwick-tree": {
    "name": "Fenwick Tree",
    "type": "Algorithm",
    "description": "Fenwick Tree is an algorithm with time complexity O(log n). It is primarily used for efficient prefix sums and point       updates",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Efficient prefix sums and point\n      updates\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Efficient prefix sums and point\n      updates\n    ",
    "useCase": "Efficient prefix sums and point\n      updates\n    ",
    "pseudocode": "FENWICK-TREE(A)\n    let n be the length of A\n    let tree[1\u2025n] be a new array\n\n    for i \u2190 1 to n\n        do tree[i] \u2190 0\n\n    for i \u2190 1 to n\n        do UPDATE(tree, i, A[i])\n\n    return tree\n\nUPDATE(tree, idx, delta)\n    while idx \u2264 n\n        do tree[idx] \u2190 tree[idx] + delta\n            idx \u2190 idx + (idx & -idx)\n\nQUERY(tree, idx)\n    let sum \u2190 0\n    while idx > 0\n        do sum \u2190 sum + tree[idx]\n            idx \u2190 idx - (idx & -idx)\n    return sum\n\n// Example:\n// Input: A = [1, 3, 5, 7, 9, 11]\n//\n// Initial tree:\n//   tree = [0, 0, 0, 0, 0, 0]\n//\n// After updates:\n//   tree = [1, 4, 5, 16, 9, 20]\n//\n// Query(4):\n//   idx = 4: sum = 16\n//   idx = 0: return 16\n//\n// Query(6):\n//   idx = 6: sum = 20\n//   idx = 4: sum = 36\n//   idx = 0: return 36\n//\n// Output: Prefix sums [1, 4, 9, 16, 25, 36]",
    "keySteps": [
      "Initialize: Create tree array and set all values to 0",
      "Update: Add value to all affected nodes using LSB",
      "Query: Sum values from all relevant nodes using LSB"
    ]
  },
  "fast-fourier-transform": {
    "name": "Fast Fourier Transform",
    "type": "Number Theory",
    "description": "Fast Fourier Transform is an algorithm with time complexity O(n log n). It is primarily used for polynomial multiplication",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Polynomial multiplication\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Polynomial multiplication\n    ",
    "useCase": "Polynomial multiplication\n    ",
    "pseudocode": "# Fast Fourier Transform\n# Input: Array a of complex numbers, length n (power of 2)\n# Output: Array y of complex numbers (DFT of a)\n\nAlgorithm FFT(a, n)\n    if n = 1 then\n        return a\n\n    # Split into even and odd indices\n    a_even \u2190 array of length n/2\n    a_odd \u2190 array of length n/2\n    for i \u2190 0 to n/2 - 1 do\n        a_even[i] \u2190 a[2i]\n        a_odd[i] \u2190 a[2i + 1]\n    end for\n\n    # Recursive calls\n    y_even \u2190 FFT(a_even, n/2)\n    y_odd \u2190 FFT(a_odd, n/2)\n\n    # Combine results\n    y \u2190 array of length n\n    \u03c9 \u2190 e^(2\u03c0i/n)\n    for k \u2190 0 to n/2 - 1 do\n        y[k] \u2190 y_even[k] + \u03c9^k \u00b7 y_odd[k]\n        y[k + n/2] \u2190 y_even[k] - \u03c9^k \u00b7 y_odd[k]\n    end for\n\n    return y\n\n# Inverse FFT\nAlgorithm IFFT(y, n)\n    # Conjugate input\n    for i \u2190 0 to n-1 do\n        y[i] \u2190 conjugate(y[i])\n    end for\n\n    # Apply FFT\n    a \u2190 FFT(y, n)\n\n    # Conjugate and scale\n    for i \u2190 0 to n-1 do\n        a[i] \u2190 conjugate(a[i]) / n\n    end for\n\n    return a\n\n# Example:\n# Input: a = [1, 2, 3, 4], n = 4\n#\n# Step 1: Split into even and odd\n#         a_even = [1, 3]\n#         a_odd = [2, 4]\n#\n# Step 2: Recursive calls\n#         y_even = FFT([1, 3], 2) = [4, -2]\n#         y_odd = FFT([2, 4], 2) = [6, -2]\n#\n# Step 3: Combine results\n#         \u03c9 = e^(2\u03c0i/4) = i\n#         y[0] = 4 + 6 = 10\n#         y[1] = -2 + i\u00b7(-2) = -2 - 2i\n#         y[2] = 4 - 6 = -2\n#         y[3] = -2 - i\u00b7(-2) = -2 + 2i\n#\n# Output: [10, -2-2i, -2, -2+2i]",
    "keySteps": [
      "Split input into even and odd indices",
      "Recursively compute FFT on halves",
      "Combine results using roots of unity",
      "Inverse FFT uses conjugation and scaling"
    ]
  },
  "fast-and-slow-pointers": {
    "name": "Fast and Slow Pointers",
    "type": "Algorithm",
    "description": "\n          A technique using two pointers moving at different speeds to detect cycles or find middle\n          elements\n        ",
    "timeComplexity": "O(n)",
    "spaceComplexity": "O(1)",
    "useCase": "Detecting cycles in linked lists, finding the middle node, or partitioning arrays\n        ",
    "pseudocode": "function hasCycle(head):\n    if not head or not head.next:\n        return False\n    \n    slow = head\n    fast = head\n    \n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n        \n        if slow == fast:\n            return True\n    \n    return False\n\nfunction findMiddle(head):\n    if not head:\n        return None\n    \n    slow = head\n    fast = head\n    \n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n    \n    return slow",
    "keySteps": [
      "Initialize two pointers, slow and fast, at the head of the list",
      "Move slow by one step and fast by two steps in each iteration",
      "Check for cycle: if slow and fast meet, a cycle exists",
      "For finding the middle: when fast reaches the end, slow is at the middle"
    ]
  },
  "extended-euclidean-algorithm": {
    "name": "Extended Euclidean",
    "type": "Number Theory",
    "description": "Extended Euclidean is an algorithm with time complexity O(log min(a,b). It is primarily used for find gcd and       b\u00e9zout coefficients",
    "timeComplexity": "O(log min(a,b)) &nbsp;|&nbsp; Space: O(log min(a,b)) &nbsp;|&nbsp; Use: Find GCD and\n      B\u00e9zout coefficients\n    ",
    "spaceComplexity": "O(log min(a,b)) &nbsp;|&nbsp; Use: Find GCD and\n      B\u00e9zout coefficients\n    ",
    "useCase": "Find GCD and\n      B\u00e9zout coefficients\n    ",
    "pseudocode": "# Extended Euclidean Algorithm\n# Input: Integers a, b\n# Output: Tuple (d, x, y) where d = gcd(a,b) and ax + by = d\n\nAlgorithm EXTENDED-EUCLID(a, b)\n    if b = 0 then\n        return (a, 1, 0)\n    end if\n\n    (d', x', y') \u2190 EXTENDED-EUCLID(b, a mod b)\n    d \u2190 d'\n    x \u2190 y'\n    y \u2190 x' - \u230aa/b\u230b \u00b7 y'\n    return (d, x, y)\n\n# Example:\n# Input: a = 30, b = 18\n#\n# Step 1: a = 30, b = 18\n#         a mod b = 12\n#         Recursive call: a = 18, b = 12\n#\n# Step 2: a = 18, b = 12\n#         a mod b = 6\n#         Recursive call: a = 12, b = 6\n#\n# Step 3: a = 12, b = 6\n#         a mod b = 0\n#         Base case: return (6, 1, 0)\n#\n# Step 4: Back to Step 2\n#         d = 6, x = 0, y = 1 - \u230a18/12\u230b\u00b70 = 1\n#         return (6, 0, 1)\n#\n# Step 5: Back to Step 1\n#         d = 6, x = 1, y = 0 - \u230a30/18\u230b\u00b71 = -1\n#         return (6, 1, -1)\n#\n# Output: (6, 1, -1)\n#\n# Verification:\n# 6 = 30\u00b71 + 18\u00b7(-1)",
    "keySteps": [
      "Base case: Return GCD and coefficients when b = 0",
      "Recursively compute GCD and coefficients",
      "Update coefficients using floor division",
      "Return GCD and B\u00e9zout coefficients"
    ]
  },
  "exponential-search": {
    "name": "Exponential Search",
    "type": "log i",
    "description": "Exponential Search is an algorithm with time complexity O(log i). It is primarily used for find element in unbounded sorted       array",
    "timeComplexity": "O(log i) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find element in unbounded sorted\n      array\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find element in unbounded sorted\n      array\n    ",
    "useCase": "Find element in unbounded sorted\n      array\n    ",
    "pseudocode": "# Exponential Search: Find element in unbounded sorted array\n# Input: Sorted array A[1..n], target value x\n# Output: Index of x in A if found, -1 otherwise\n\nAlgorithm EXPONENTIAL-SEARCH(A, x)\n    n \u2190 length[A]\n\n    # If x is at first position\n    if A[1] = x then\n        return 1\n    end if\n\n    # Find range for binary search\n    i \u2190 1\n    while i < n and A[i] \u2264 x do\n        i \u2190 i * 2\n    end while\n\n    # Binary search in found range\n    return BINARY-SEARCH(A, i/2, min(i, n), x)\n\nAlgorithm BINARY-SEARCH(A, low, high, x)\n    while low \u2264 high do\n        mid \u2190 \u230a(low + high)/2\u230b\n        if A[mid] = x then\n            return mid\n        else if A[mid] < x then\n            low \u2190 mid + 1\n        else\n            high \u2190 mid - 1\n        end if\n    end while\n    return -1\n\n# Example:\n# Input: A = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100], x = 70\n#\n# Step 1: i = 1, A[1] = 10 \u2260 70\n# Step 2: i = 2, A[2] = 20 \u2264 70\n# Step 3: i = 4, A[4] = 40 \u2264 70\n# Step 4: i = 8, A[8] = 80 > 70\n# Step 5: Binary search in range [4,8]\n#         mid = 6, A[6] = 60 < 70\n#         mid = 7, A[7] = 70 = 70\n#\n# Output: 7",
    "keySteps": [
      "Check if element is at first position",
      "Find range by exponentially increasing index",
      "Perform binary search in found range",
      "Return index if found, -1 otherwise"
    ]
  },
  "edit-distance": {
    "name": "Edit Distance",
    "type": "mn",
    "description": "Edit Distance is an algorithm with time complexity O(mn). It is primarily used for string similarity and transformation",
    "timeComplexity": "O(mn) &nbsp;|&nbsp; Space: O(mn) &nbsp;|&nbsp; Use: String similarity and transformation\n    ",
    "spaceComplexity": "O(mn) &nbsp;|&nbsp; Use: String similarity and transformation\n    ",
    "useCase": "String similarity and transformation\n    ",
    "pseudocode": "EDIT-DISTANCE(s, t):\n    // s and t are input strings\n    // Returns minimum number of operations to transform s to t\n    m \u2190 length(s)\n    n \u2190 length(t)\n    dp[0..m][0..n] \u2190 0\n    \n    // Initialize first row and column\n    for i \u2190 0 to m:\n        dp[i][0] \u2190 i\n    for j \u2190 0 to n:\n        dp[0][j] \u2190 j\n    \n    // Fill dp table\n    for i \u2190 1 to m:\n        for j \u2190 1 to n:\n            if s[i-1] = t[j-1]:\n                dp[i][j] \u2190 dp[i-1][j-1]\n            else:\n                dp[i][j] \u2190 1 + min(\n                    dp[i-1][j],    // deletion\n                    dp[i][j-1],    // insertion\n                    dp[i-1][j-1]   // substitution\n                )\n    \n    return dp[m][n]\n\n// Example:\n// Input: s = \"kitten\", t = \"sitting\"\n//\n// dp table:\n//    s i t t i n g\n// k  1 2 3 4 5 6 7\n// i  2 1 2 3 4 5 6\n// t  3 2 1 2 3 4 5\n// t  4 3 2 1 2 3 4\n// e  5 4 3 2 2 3 4\n// n  6 5 4 3 3 2 3\n//\n// Operations:\n// 1. kitten \u2192 sitten (substitute 'k' with 's')\n// 2. sitten \u2192 sittin (substitute 'e' with 'i')\n// 3. sittin \u2192 sitting (insert 'g')\n//\n// Edit distance: 3",
    "keySteps": [
      "Dynamic programming solution for string transformation",
      "Handles three operations: insertion, deletion, substitution",
      "Can be extended to include transposition and other operations",
      "Can be optimized to O(min(m,n)) space"
    ]
  },
  "dynamic-programming": {
    "name": "Dynamic Programming",
    "type": "n\u00b2",
    "description": "Dynamic Programming is an algorithm with time complexity O(n\u00b2). It is primarily used for optimization problems with         overlapping subproblems",
    "timeComplexity": "O(n\u00b2) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Optimization problems with\n        overlapping subproblems\n      ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Optimization problems with\n        overlapping subproblems\n      ",
    "useCase": "Optimization problems with\n        overlapping subproblems\n      ",
    "pseudocode": "// Fibonacci\nFIBONACCI(n):\n  if n \u2264 1:\n    return n\n  dp = [0] * (n + 1)\n  dp[1] = 1\n  for i from 2 to n:\n    dp[i] = dp[i-1] + dp[i-2]\n  return dp[n]\n\n// Longest Common Subsequence\nLCS(X, Y):\n  m = length(X)\n  n = length(Y)\n  dp = [0] * (n + 1)\n  for i from 1 to m:\n    prev = 0\n    for j from 1 to n:\n      temp = dp[j]\n      if X[i-1] == Y[j-1]:\n        dp[j] = prev + 1\n      else:\n        dp[j] = max(dp[j], dp[j-1])\n      prev = temp\n  return dp[n]\n\n// Knapsack\nKNAPSACK(W, V, C):\n  n = length(W)\n  dp = [0] * (C + 1)\n  for i from 1 to n:\n    for j from C downto W[i-1]:\n      dp[j] = max(dp[j], dp[j-W[i-1]] + V[i-1])\n  return dp[C]\n\n// Matrix Chain Multiplication\nMCM(P):\n  n = length(P) - 1\n  dp = [0] * n\n  for l from 2 to n:\n    for i from 0 to n-l:\n      j = i + l - 1\n      dp[i][j] = \u221e\n      for k from i to j-1:\n        cost = dp[i][k] + dp[k+1][j] + P[i]*P[k+1]*P[j+1]\n        if cost < dp[i][j]:\n          dp[i][j] = cost\n  return dp[0][n-1]",
    "keySteps": []
  },
  "dynamic-programming-pattern": {
    "name": "DP Pattern",
    "type": "string",
    "description": "DP Pattern is an algorithm with time complexity O(n). It is primarily used for solving problems with overlapping       subproblems",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Solving problems with overlapping\n      subproblems\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Solving problems with overlapping\n      subproblems\n    ",
    "useCase": "Solving problems with overlapping\n      subproblems\n    ",
    "pseudocode": "DP-PATTERN(n)\n    # Define state and dependencies\n    state \u2190 array[n+1]\n\n    # Initialize base cases\n    state[0] \u2190 base_case_0\n    state[1] \u2190 base_case_1\n\n    # Fill DP table\n    for i \u2190 2 to n\n        # Compute state from previous states\n        state[i] \u2190 compute_state(state[i-1], state[i-2])\n\n    return state[n]\n\n# Example:\n# Input: n = 5\n# State: dp[i] represents solution for subproblem of size i\n# Base cases: dp[0] = 0, dp[1] = 1\n# Recurrence: dp[i] = dp[i-1] + dp[i-2]\n# Output: dp[5] = 5",
    "keySteps": [
      "Define: State and dependencies",
      "Initialize: Base cases",
      "Compute: States in correct order"
    ]
  },
  "dynamic-programming-iterative": {
    "name": "Iterative DP",
    "type": "dynamic programming",
    "description": "Iterative DP is an algorithm with time complexity O(n). It is primarily used for solving problems with bottom-up       approach",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Solving problems with bottom-up\n      approach\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Solving problems with bottom-up\n      approach\n    ",
    "useCase": "Solving problems with bottom-up\n      approach\n    ",
    "pseudocode": "ITERATIVE-DP(n)\n    # Initialize DP array with base cases\n    dp[0] \u2190 base_case_0\n    dp[1] \u2190 base_case_1\n\n    # Fill DP array\n    for i \u2190 2 to n\n        dp[i] \u2190 compute_from_previous(dp[i-1], dp[i-2])\n\n    return dp[n]\n\n# Example:\n# Input: n = 5\n# Base cases: dp[0] = 0, dp[1] = 1\n# Compute: dp[i] = dp[i-1] + dp[i-2]\n# Output: dp[5] = 5",
    "keySteps": [
      "Initialize: DP array with base cases",
      "Fill: DP array from bottom up",
      "Return: Final state value"
    ]
  },
  "dynamic-programming-coin-change": {
    "name": "Coin Change (DP)",
    "type": "n*m",
    "description": "Coin Change (DP) is an algorithm with time complexity O(n*m). It is primarily used for finding minimum coins needed for       amount",
    "timeComplexity": "O(n*m) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Finding minimum coins needed for\n      amount\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Finding minimum coins needed for\n      amount\n    ",
    "useCase": "Finding minimum coins needed for\n      amount\n    ",
    "pseudocode": "COIN-CHANGE(coins, amount)\n    # Initialize DP array with infinity\n    dp[0..amount] \u2190 \u221e\n    dp[0] \u2190 0  # Base case: 0 coins needed for amount 0\n\n    # Fill DP array\n    for i \u2190 1 to amount\n        for each coin in coins\n            if coin \u2264 i\n                dp[i] \u2190 min(dp[i], dp[i - coin] + 1)\n\n    if dp[amount] = \u221e\n        return -1\n    else\n        return dp[amount]\n\n# Example:\n# Input: coins = [1, 2, 5], amount = 11\n# dp array after filling:\n# [0, 1, 1, 2, 2, 1, 2, 2, 3, 3, 2, 3]\n# Output: 3  # 5 + 5 + 1",
    "keySteps": [
      "Initialize: DP array with infinity and base case",
      "Fill: DP array by trying each coin",
      "Return: Minimum coins or -1 if impossible"
    ]
  },
  "doubly-linked-list": {
    "name": "Doubly Linked List",
    "type": "Data Structure",
    "description": "A linked list where each node has references to both the next and previous nodes",
    "timeComplexity": "O(n) for access/search, O(1) for insertion/deletion",
    "spaceComplexity": "O(n) for storing n nodes",
    "useCase": "When you need bidirectional traversal and O(1) insertion/deletion at both ends",
    "pseudocode": "class Node:\n    def __init__(self, data):\n        self.data = data\n        self.next = None\n        self.prev = None\n\nclass DoublyLinkedList:\n    def __init__(self):\n        self.head = None\n        self.tail = None\n    \n    def insert_at_beginning(self, data):\n        new_node = Node(data)\n        if self.head is None:\n            self.head = new_node\n            self.tail = new_node\n        else:\n            new_node.next = self.head\n            self.head.prev = new_node\n            self.head = new_node\n    \n    def insert_at_end(self, data):\n        new_node = Node(data)\n        if self.tail is None:\n            self.head = new_node\n            self.tail = new_node\n        else:\n            new_node.prev = self.tail\n            self.tail.next = new_node\n            self.tail = new_node",
    "keySteps": [
      "Each node contains data and pointers to both next and previous nodes",
      "Maintain head and tail pointers for O(1) access to both ends",
      "Update both next and prev pointers when inserting or deleting nodes",
      "Handle edge cases: empty list, single node, first/last node operations"
    ]
  },
  "divide-and-conquer": {
    "name": "Divide and Conquer",
    "type": "n log n",
    "description": "Divide and Conquer is an algorithm with time complexity O(n log n). It is primarily used for break problems into smaller       subproblems",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Break problems into smaller\n      subproblems\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Break problems into smaller\n      subproblems\n    ",
    "useCase": "Break problems into smaller\n      subproblems\n    ",
    "pseudocode": "// Merge Sort\nMERGE-SORT(A, l, r):\n  if l \u2265 r:\n    return\n  mid = floor((l + r) / 2)\n  MERGE-SORT(A, l, mid)\n  MERGE-SORT(A, mid+1, r)\n  MERGE(A, l, mid, r)\n\n// Quick Sort\nQUICK-SORT(A, l, r):\n  if l \u2265 r:\n    return\n  p = PARTITION(A, l, r)\n  QUICK-SORT(A, l, p-1)\n  QUICK-SORT(A, p+1, r)\n\n// Binary Search\nBINARY-SEARCH(A, l, r, x):\n  if l > r:\n    return -1\n  mid = floor((l + r) / 2)\n  if A[mid] == x:\n    return mid\n  if A[mid] > x:\n    return BINARY-SEARCH(A, l, mid-1, x)\n  return BINARY-SEARCH(A, mid+1, r, x)\n\n// Strassen's Matrix Multiplication\nSTRASSEN(A, B):\n  if A is 1x1:\n    return A * B\n  split A and B into 4 submatrices\n  P1 = STRASSEN(A11, B12 - B22)\n  P2 = STRASSEN(A11 + A12, B22)\n  P3 = STRASSEN(A21 + A22, B11)\n  P4 = STRASSEN(A22, B21 - B11)\n  P5 = STRASSEN(A11 + A22, B11 + B22)\n  P6 = STRASSEN(A12 - A22, B21 + B22)\n  P7 = STRASSEN(A11 - A21, B11 + B12)\n  C11 = P5 + P4 - P2 + P6\n  C12 = P1 + P2\n  C21 = P3 + P4\n  C22 = P5 + P1 - P3 - P7\n  return combine C11, C12, C21, C22",
    "keySteps": []
  },
  "dijkstra": {
    "name": "Dijkstra's Algorithm",
    "type": "--gradient-from",
    "description": "Dijkstra's Algorithm is an algorithm with time complexity O((V+E). It is primarily used for finding shortest paths from a       source",
    "timeComplexity": "O((V+E)logV) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Finding shortest paths from a\n      source\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Finding shortest paths from a\n      source\n    ",
    "useCase": "Finding shortest paths from a\n      source\n    ",
    "pseudocode": "// Standard Dijkstra (Greedy Approach)\nDIJKSTRA(G, w, s)\n1  INITIALIZE-SINGLE-SOURCE(G, s)\n2  S = \u2205  // Set of processed vertices\n3  Q = G.V  // Priority queue of vertices\n4  while Q \u2260 \u2205\n5      u = EXTRACT-MIN(Q)  // Greedy choice: vertex with minimum distance\n6      S = S \u222a {u}\n7      for each vertex v \u2208 G.Adj[u]\n8          RELAX(u, v, w)\n\nINITIALIZE-SINGLE-SOURCE(G, s)\n1  for each vertex v \u2208 G.V\n2      v.d = \u221e\n3      v.\u03c0 = NIL\n4  s.d = 0\n\nRELAX(u, v, w)\n1  if v.d > u.d + w(u, v)\n2      v.d = u.d + w(u, v)\n3      v.\u03c0 = u\n\n// Dijkstra with Path Reconstruction\nDIJKSTRA-WITH-PATH(G, w, s, t)\n1  INITIALIZE-SINGLE-SOURCE(G, s)\n2  S = \u2205\n3  Q = G.V\n4  while Q \u2260 \u2205\n5      u = EXTRACT-MIN(Q)\n6      if u == t\n7          break\n8      S = S \u222a {u}\n9      for each vertex v \u2208 G.Adj[u]\n10         RELAX(u, v, w)\n11  return CONSTRUCT-PATH(s, t)\n\nCONSTRUCT-PATH(s, t)\n1  path = []\n2  u = t\n3  while u \u2260 NIL\n4      path.append(u)\n5      u = u.\u03c0\n6  return REVERSE(path)\n\n// Bidirectional Dijkstra (Optimization)\nBIDIRECTIONAL-DIJKSTRA(G, w, s, t)\n1  INITIALIZE-SINGLE-SOURCE(G, s)\n2  INITIALIZE-SINGLE-SOURCE(G, t)\n3  S_f = \u2205  // Forward search set\n4  S_b = \u2205  // Backward search set\n5  Q_f = G.V  // Forward priority queue\n6  Q_b = G.V  // Backward priority queue\n7  min_dist = \u221e\n8  meeting_node = NIL\n9  while Q_f \u2260 \u2205 and Q_b \u2260 \u2205\n10     u = EXTRACT-MIN(Q_f)\n11     if u \u2208 S_f\n12         continue\n13     S_f = S_f \u222a {u}\n14     if u \u2208 S_b\n15         total_dist = u.d + u.d_b\n16         if total_dist < min_dist\n17             min_dist = total_dist\n18             meeting_node = u\n19     for each vertex v \u2208 G.Adj[u]\n20         if v \u2209 S_f\n21             RELAX(u, v, w)\n22     u = EXTRACT-MIN(Q_b)\n23     if u \u2208 S_b\n24         continue\n25     S_b = S_b \u222a {u}\n26     if u \u2208 S_f\n27         total_dist = u.d + u.d_b\n28         if total_dist < min_dist\n29             min_dist = total_dist\n30             meeting_node = u\n31     for each vertex v \u2208 G.Adj[u]\n32         if v \u2209 S_b\n33             RELAX(u, v, w)\n34 return min_dist, meeting_node",
    "keySteps": []
  },
  "digit-dp": {
    "name": "Digit Dynamic Programming",
    "type": "d * s * b",
    "description": "Digit Dynamic Programming is an algorithm with time complexity O(d * s * b). It is primarily used for number range problems",
    "timeComplexity": "O(d * s * b) &nbsp;|&nbsp; Space: O(d * s) &nbsp;|&nbsp; Use: Number range problems\n    ",
    "spaceComplexity": "O(d * s) &nbsp;|&nbsp; Use: Number range problems\n    ",
    "useCase": "Number range problems\n    ",
    "pseudocode": "DIGIT-DP(low, high, condition):\n    // low and high are the range boundaries\n    // condition is a function that checks digit constraints\n    // Returns count of numbers in range satisfying condition\n    \n    function COUNT(n):\n        digits \u2190 convert n to array of digits\n        d \u2190 length(digits)\n        dp[d][s][tight] \u2190 -1  // Initialize memoization table\n        \n        function SOLVE(pos, sum, tight):\n            if pos = d:\n                return 1 if condition(sum) else 0\n            \n            if dp[pos][sum][tight] \u2260 -1:\n                return dp[pos][sum][tight]\n            \n            limit \u2190 digits[pos] if tight else 9\n            count \u2190 0\n            \n            for digit \u2190 0 to limit:\n                new_tight \u2190 tight and (digit = limit)\n                new_sum \u2190 sum + digit\n                if condition(new_sum):\n                    count \u2190 count + SOLVE(pos + 1, new_sum, new_tight)\n            \n            dp[pos][sum][tight] \u2190 count\n            return count\n        \n        return SOLVE(0, 0, true)\n    \n    return COUNT(high) - COUNT(low - 1)\n\n// Example: Count numbers with digit sum = target\n// Range: [1, 1000], target = 10\n//\n// For number 123:\n// pos=0: digit=1, sum=1, tight=true\n// pos=1: digit=2, sum=3, tight=true\n// pos=2: digit=3, sum=6, tight=true\n//\n// For number 910:\n// pos=0: digit=9, sum=9, tight=true\n// pos=1: digit=1, sum=10, tight=true\n// pos=2: digit=0, sum=10, tight=false",
    "keySteps": [
      "Efficiently solves number range problems",
      "Uses digit-by-digit processing with memoization",
      "Handles constraints on digits and their properties",
      "Efficient for large number ranges with digit constraints"
    ]
  },
  "dfs": {
    "name": "DFS",
    "type": "V + E",
    "description": "DFS is an algorithm with time complexity O(V + E). It is primarily used for topological sort, cycle detection,       and strongly connected components",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Topological sort, cycle detection,\n      and strongly connected components\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Topological sort, cycle detection,\n      and strongly connected components\n    ",
    "useCase": "Topological sort, cycle detection,\n      and strongly connected components\n    ",
    "pseudocode": "// Standard DFS\nDFS(G):\n  for each vertex u in G.V:\n    u.color = WHITE\n    u.\u03c0 = NIL\n  time = 0\n  for each vertex u in G.V:\n    if u.color == WHITE:\n      DFS-VISIT(G, u)\n\nDFS-VISIT(G, u):\n  time = time + 1\n  u.d = time\n  u.color = GRAY\n  for each v in G.adj[u]:\n    if v.color == WHITE:\n      v.\u03c0 = u\n      DFS-VISIT(G, v)\n  u.color = BLACK\n  time = time + 1\n  u.f = time\n\n// Topological Sort\nTOPOLOGICAL-SORT(G):\n  DFS(G)\n  sort vertices by decreasing finish time\n  return sorted vertices\n\n// Cycle Detection\nHAS-CYCLE(G):\n  for each vertex u in G.V:\n    u.color = WHITE\n  for each vertex u in G.V:\n    if u.color == WHITE:\n      if DFS-CYCLE(G, u):\n        return true\n  return false\n\nDFS-CYCLE(G, u):\n  u.color = GRAY\n  for each v in G.adj[u]:\n    if v.color == WHITE:\n      if DFS-CYCLE(G, v):\n        return true\n    elif v.color == GRAY:\n      return true\n  u.color = BLACK\n  return false\n\n// Strongly Connected Components\nSCC(G):\n  DFS(G)\n  compute G^T\n  DFS(G^T) in order of decreasing finish time\n  return trees in depth-first forest",
    "keySteps": []
  },
  "dfs-linked-list": {
    "name": "DFS (Linked List)",
    "type": "graph",
    "description": "DFS (Linked List) is an algorithm with time complexity O(n). It is primarily used for traverse linked list depth-first",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Traverse linked list depth-first\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Traverse linked list depth-first\n    ",
    "useCase": "Traverse linked list depth-first\n    ",
    "pseudocode": "// Node structure for linked list\nNODE:\n    key\n    next\n    visited\n\n// DFS on linked list\nDFS-LINKED-LIST(head):\n    if head = NIL:\n        return\n\n    // Mark current node as visited\n    head.visited \u2190 true\n    process head.key\n\n    // Recursively visit next node if not visited\n    if head.next \u2260 NIL and not head.next.visited:\n        DFS-LINKED-LIST(head.next)\n\n// Example:\n// Input: 1 \u2192 2 \u2192 3 \u2192 4 \u2192 5\n//\n// Execution:\n// 1. Visit 1, visited = {1}\n// 2. Visit 2, visited = {1,2}\n// 3. Visit 3, visited = {1,2,3}\n// 4. Visit 4, visited = {1,2,3,4}\n// 5. Visit 5, visited = {1,2,3,4,5}\n//\n// Output: 1, 2, 3, 4, 5",
    "keySteps": [
      "Visit: Process current node",
      "Mark: Node as visited",
      "Recurse: Visit next unvisited node"
    ]
  },
  "dfs-graph": {
    "name": "DFS Graph",
    "type": "Algorithm",
    "description": "Depth-First Search for Graph Traversal",
    "timeComplexity": "O(V + E) where V is vertices and E is edges",
    "spaceComplexity": "O(V) for visited set and recursion stack",
    "useCase": "Finding connected components, cycle detection, topological sorting",
    "pseudocode": "function DFS(graph, start):\n    visited = set()\n    stack = [start]\n    \n    while stack is not empty:\n        current = stack.pop()\n        \n        if current not in visited:\n            visited.add(current)\n            process(current)\n            \n            for neighbor in graph[current]:\n                if neighbor not in visited:\n                    stack.append(neighbor)",
    "keySteps": [
      "Initialize: Visited set and stack with start vertex",
      "Process: Pop vertex from stack and mark as visited",
      "Explore: Add unvisited neighbors to stack",
      "Repeat: Until stack is empty"
    ]
  },
  "dfs-binary-tree": {
    "name": "DFS (Binary Tree)",
    "type": "tree",
    "description": "DFS (Binary Tree) is an algorithm with time complexity O(n). It is primarily used for traverse binary tree in depth-first       order",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(h) &nbsp;|&nbsp; Use: Traverse binary tree in depth-first\n      order\n    ",
    "spaceComplexity": "O(h) &nbsp;|&nbsp; Use: Traverse binary tree in depth-first\n      order\n    ",
    "useCase": "Traverse binary tree in depth-first\n      order\n    ",
    "pseudocode": "# DFS Binary Tree: Traverse binary tree in depth-first order\n# Input: Binary tree T with root node\n# Output: List of nodes in DFS order\n\nAlgorithm DFS-BINARY-TREE(T)\n    if T.root = NIL then\n        return empty list\n    end if\n\n    result \u2190 empty list\n    stack \u2190 empty stack\n    stack.push(T.root)\n\n    while stack is not empty do\n        node \u2190 stack.pop()\n        result.append(node.value)\n\n        # Push right child first so left is processed first\n        if node.right \u2260 NIL then\n            stack.push(node.right)\n        end if\n\n        if node.left \u2260 NIL then\n            stack.push(node.left)\n        end if\n    end while\n\n    return result\n\n# Example:\n# Input: Binary tree\n#        1\n#       / \\\n#      2   3\n#     / \\   \\\n#    4   5   6\n#\n# Step 1: Push 1\n# Step 2: Pop 1, Push 3, Push 2\n# Step 3: Pop 2, Push 5, Push 4\n# Step 4: Pop 4\n# Step 5: Pop 5\n# Step 6: Pop 3, Push 6\n# Step 7: Pop 6\n#\n# Output: [1, 2, 4, 5, 3, 6]",
    "keySteps": [
      "Initialize stack and result list",
      "Push root node onto stack",
      "Process nodes in stack order, pushing right then left children",
      "Return list of processed nodes"
    ]
  },
  "counting-sort": {
    "name": "Counting Sort",
    "type": "n+k",
    "description": "Counting Sort is an algorithm with time complexity O(n+k). It is primarily used for sorting integers with small range",
    "timeComplexity": "O(n+k) &nbsp;|&nbsp; Space: O(n+k) &nbsp;|&nbsp; Use: Sorting integers with small range\n    ",
    "spaceComplexity": "O(n+k) &nbsp;|&nbsp; Use: Sorting integers with small range\n    ",
    "useCase": "Sorting integers with small range\n    ",
    "pseudocode": "// Standard Counting Sort\nCOUNTING-SORT(A):\n    # Find maximum value\n    max_val = max(A)\n    n = len(A)\n\n    # Initialize count array\n    count = [0] * (max_val + 1)\n    output = [0] * n\n\n    # Store count of each element\n    for x in A:\n        count[x] += 1\n\n    # Change count[i] to position of element\n    for i in range(1, max_val + 1):\n        count[i] += count[i-1]\n\n    # Build output array\n    for i in range(n-1, -1, -1):\n        output[count[A[i]]-1] = A[i]\n        count[A[i]] -= 1\n\n    return output\n\n// Counting Sort with Negative Numbers\nCOUNTING-SORT-NEGATIVE(A):\n    # Find min and max values\n    min_val = min(A)\n    max_val = max(A)\n    range_val = max_val - min_val + 1\n    n = len(A)\n\n    # Initialize count array\n    count = [0] * range_val\n    output = [0] * n\n\n    # Store count of each element\n    for x in A:\n        count[x - min_val] += 1\n\n    # Change count[i] to position of element\n    for i in range(1, range_val):\n        count[i] += count[i-1]\n\n    # Build output array\n    for i in range(n-1, -1, -1):\n        output[count[A[i] - min_val]-1] = A[i]\n        count[A[i] - min_val] -= 1\n\n    return output\n\n// Counting Sort with Objects\nCOUNTING-SORT-OBJECTS(A, key_func):\n    # Find maximum key value\n    max_key = max(key_func(x) for x in A)\n    n = len(A)\n\n    # Initialize count array\n    count = [0] * (max_key + 1)\n    output = [None] * n\n\n    # Store count of each key\n    for x in A:\n        count[key_func(x)] += 1\n\n    # Change count[i] to position of element\n    for i in range(1, max_key + 1):\n        count[i] += count[i-1]\n\n    # Build output array\n    for i in range(n-1, -1, -1):\n        key = key_func(A[i])\n        output[count[key]-1] = A[i]\n        count[key] -= 1\n\n    return output\n\n// Counting Sort with Radix\nCOUNTING-SORT-RADIX(A, exp):\n    n = len(A)\n    output = [0] * n\n    count = [0] * 10\n\n    # Store count of occurrences\n    for i in range(n):\n        index = (A[i] // exp) % 10\n        count[index] += 1\n\n    # Change count[i] to position of digit\n    for i in range(1, 10):\n        count[i] += count[i-1]\n\n    # Build output array\n    for i in range(n-1, -1, -1):\n        index = (A[i] // exp) % 10\n        output[count[index]-1] = A[i]\n        count[index] -= 1\n\n    # Copy output to A\n    for i in range(n):\n        A[i] = output[i]",
    "keySteps": []
  },
  "circular-linked-list": {
    "name": "Circular Linked List",
    "type": "Algorithm",
    "description": "Circular Linked List is an algorithm with time complexity O(n). It is primarily used for circular data structure operations",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Circular data structure operations\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Circular data structure operations\n    ",
    "useCase": "Circular data structure operations\n    ",
    "pseudocode": "// Node structure\nNODE(key):\n    key \u2190 key\n    next \u2190 null\n\n// Insert at beginning\nCIRCULAR-INSERT-HEAD(L, x):\n    x.next \u2190 x\n    if L.head = null:\n        L.head \u2190 x\n    else:\n        x.next \u2190 L.head\n        last \u2190 L.head\n        while last.next \u2260 L.head:\n            last \u2190 last.next\n        last.next \u2190 x\n        L.head \u2190 x\n\n// Insert at end\nCIRCULAR-INSERT-TAIL(L, x):\n    x.next \u2190 x\n    if L.head = null:\n        L.head \u2190 x\n    else:\n        last \u2190 L.head\n        while last.next \u2260 L.head:\n            last \u2190 last.next\n        last.next \u2190 x\n        x.next \u2190 L.head\n\n// Delete node\nCIRCULAR-DELETE(L, x):\n    if L.head = null:\n        return\n    if L.head = x and L.head.next = L.head:\n        L.head \u2190 null\n        return\n    if L.head = x:\n        last \u2190 L.head\n        while last.next \u2260 L.head:\n            last \u2190 last.next\n        L.head \u2190 L.head.next\n        last.next \u2190 L.head\n        return\n    prev \u2190 L.head\n    while prev.next \u2260 L.head and prev.next \u2260 x:\n        prev \u2190 prev.next\n    if prev.next = x:\n        prev.next \u2190 prev.next.next\n\n// Traverse list\nCIRCULAR-TRAVERSE(L):\n    if L.head = null:\n        return\n    current \u2190 L.head\n    repeat:\n        print(current.key)\n        current \u2190 current.next\n    until current = L.head\n\n// Example:\n// Input: Operations [INSERT-HEAD(1), INSERT-TAIL(2), INSERT-HEAD(3), DELETE(1)]\n//\n// After INSERT-HEAD(1):\n//   1 -> 1\n//\n// After INSERT-TAIL(2):\n//   1 -> 2 -> 1\n//\n// After INSERT-HEAD(3):\n//   3 -> 1 -> 2 -> 3\n//\n// After DELETE(1):\n//   3 -> 2 -> 3",
    "keySteps": [
      "Insert: Add node while maintaining circular structure",
      "Delete: Remove node and update circular links",
      "Traverse: Visit all nodes in circular order"
    ]
  },
  "chinese-remainder-theorem": {
    "name": "Chinese Remainder Theorem",
    "type": "n\u00b2",
    "description": "Chinese Remainder Theorem is an algorithm with time complexity O(n\u00b2). It is primarily used for solve system of congruences",
    "timeComplexity": "O(n\u00b2) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Solve system of congruences\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Solve system of congruences\n    ",
    "useCase": "Solve system of congruences\n    ",
    "pseudocode": "CRT(a, m)\n    let n be the length of a\n    let M \u2190 1\n    for i \u2190 1 to n\n        do M \u2190 M \u00b7 m[i]\n\n    let x \u2190 0\n    for i \u2190 1 to n\n        do let Mi \u2190 M / m[i]\n            let yi \u2190 MODULAR-INVERSE(Mi, m[i])\n            x \u2190 x + a[i] \u00b7 Mi \u00b7 yi\n\n    return x mod M\n\nMODULAR-INVERSE(a, m)\n    let g, x, y be the result of EXTENDED-EUCLID(a, m)\n    if g \u2260 1\n        then return NIL\n    return x mod m\n\nEXTENDED-EUCLID(a, b)\n    if b = 0\n        then return (a, 1, 0)\n    let (d', x', y') \u2190 EXTENDED-EUCLID(b, a mod b)\n    let d \u2190 d'\n    let x \u2190 y'\n    let y \u2190 x' - \u230aa/b\u230b \u00b7 y'\n    return (d, x, y)\n\n// Example:\n// Input: a = [2, 3, 2], m = [3, 5, 7]\n//\n// M = 3\u00b75\u00b77 = 105\n//\n// For i = 1:\n//   M\u2081 = 105/3 = 35\n//   y\u2081 = 2 (inverse of 35 mod 3)\n//\n// For i = 2:\n//   M\u2082 = 105/5 = 21\n//   y\u2082 = 1 (inverse of 21 mod 5)\n//\n// For i = 3:\n//   M\u2083 = 105/7 = 15\n//   y\u2083 = 1 (inverse of 15 mod 7)\n//\n// x = 2\u00b735\u00b72 + 3\u00b721\u00b71 + 2\u00b715\u00b71 = 233\n//\n// Output: 233 mod 105 = 23",
    "keySteps": [
      "Compute: Product of all moduli",
      "Calculate: Modular inverses using extended Euclidean algorithm",
      "Combine: Solutions using CRT formula"
    ]
  },
  "bucket-sort": {
    "name": "Bucket Sort",
    "type": "array",
    "description": "Bucket Sort is an algorithm with time complexity O(n). It is primarily used for sorting uniformly distributed numbers",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Sorting uniformly distributed numbers\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Sorting uniformly distributed numbers\n    ",
    "useCase": "Sorting uniformly distributed numbers\n    ",
    "pseudocode": "// Standard Bucket Sort\nBUCKET-SORT(A):\n    # Initialize buckets\n    n = len(A)\n    buckets = [[] for _ in range(n)]\n\n    # Distribute elements into buckets\n    for x in A:\n        bucket_idx = int(x * n)\n        buckets[bucket_idx].append(x)\n\n    # Sort individual buckets\n    for bucket in buckets:\n        INSERTION-SORT(bucket)\n\n    # Concatenate buckets\n    result = []\n    for bucket in buckets:\n        result.extend(bucket)\n\n    return result\n\n// Bucket Sort with Custom Range\nBUCKET-SORT-RANGE(A, min_val, max_val):\n    # Initialize buckets\n    n = len(A)\n    buckets = [[] for _ in range(n)]\n\n    # Distribute elements into buckets\n    for x in A:\n        bucket_idx = int((x - min_val) / (max_val - min_val) * (n-1))\n        buckets[bucket_idx].append(x)\n\n    # Sort individual buckets\n    for bucket in buckets:\n        INSERTION-SORT(bucket)\n\n    # Concatenate buckets\n    result = []\n    for bucket in buckets:\n        result.extend(bucket)\n\n    return result\n\n// Bucket Sort with Linked Lists\nBUCKET-SORT-LIST(A):\n    # Initialize buckets\n    n = len(A)\n    buckets = [LinkedList() for _ in range(n)]\n\n    # Distribute elements into buckets\n    for x in A:\n        bucket_idx = int(x * n)\n        buckets[bucket_idx].append(x)\n\n    # Sort individual buckets\n    for bucket in buckets:\n        bucket.sort()\n\n    # Concatenate buckets\n    result = []\n    for bucket in buckets:\n        result.extend(bucket.to_list())\n\n    return result\n\n// Bucket Sort with Counting Sort\nBUCKET-SORT-COUNTING(A):\n    # Initialize buckets\n    n = len(A)\n    buckets = [[] for _ in range(n)]\n\n    # Distribute elements into buckets\n    for x in A:\n        bucket_idx = int(x * n)\n        buckets[bucket_idx].append(x)\n\n    # Sort individual buckets using counting sort\n    for bucket in buckets:\n        if bucket:\n            max_val = max(bucket)\n            count = [0] * (max_val + 1)\n            for x in bucket:\n                count[x] += 1\n            sorted_bucket = []\n            for i in range(max_val + 1):\n                sorted_bucket.extend([i] * count[i])\n            bucket[:] = sorted_bucket\n\n    # Concatenate buckets\n    result = []\n    for bucket in buckets:\n        result.extend(bucket)\n\n    return result",
    "keySteps": []
  },
  "bubble-sort": {
    "name": "Bubble Sort",
    "type": "n\u00b2",
    "description": "Bubble Sort is an algorithm with time complexity O(n\u00b2). It is primarily used for sorting array in-place",
    "timeComplexity": "O(n\u00b2) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Sorting array in-place\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Sorting array in-place\n    ",
    "useCase": "Sorting array in-place\n    ",
    "pseudocode": "# Bubble Sort: Repeatedly swap adjacent elements if they are in wrong order\n# Input: Array A[1..n] of n elements\n# Output: Array A sorted in non-decreasing order\n\nBUBBLE-SORT(A)\n    n \u2190 length[A]    # Number of elements in array\n\n    # Outer loop: n-1 passes needed\n    for i \u2190 1 to n-1 do\n        # Inner loop: compare adjacent elements\n        for j \u2190 1 to n-i do\n            # Swap if elements are in wrong order\n            if A[j] > A[j+1] then\n                # Exchange A[j] and A[j+1]\n                temp \u2190 A[j]\n                A[j] \u2190 A[j+1]\n                A[j+1] \u2190 temp\n            end if\n        end for\n    end for\n\n# Example:\n# Input: A = [5, 2, 4, 6, 1, 3]\n# Pass 1: [2, 4, 5, 1, 3, 6]  # 6 bubbles to end\n# Pass 2: [2, 4, 1, 3, 5, 6]  # 5 bubbles to end\n# Pass 3: [2, 1, 3, 4, 5, 6]  # 4 bubbles to end\n# Pass 4: [1, 2, 3, 4, 5, 6]  # 3 bubbles to end\n# Pass 5: [1, 2, 3, 4, 5, 6]  # 2 bubbles to end\n# Output: [1, 2, 3, 4, 5, 6]",
    "keySteps": []
  },
  "bitwise-dp": {
    "name": "Bitwise Dynamic Programming",
    "type": "n2\u207f",
    "description": "Bitwise Dynamic Programming is an algorithm with time complexity O(n2\u207f). It is primarily used for subset problems and state       compression",
    "timeComplexity": "O(n2\u207f) &nbsp;|&nbsp; Space: O(2\u207f) &nbsp;|&nbsp; Use: Subset problems and state\n      compression\n    ",
    "spaceComplexity": "O(2\u207f) &nbsp;|&nbsp; Use: Subset problems and state\n      compression\n    ",
    "useCase": "Subset problems and state\n      compression\n    ",
    "pseudocode": "BITWISE-DP(n, cost):\n    // n is number of elements\n    // cost[i][j] is cost of including element j in subset i\n    // Returns minimum cost of covering all elements\n    \n    // Initialize dp array\n    dp[0..2\u207f-1] \u2190 \u221e\n    dp[0] \u2190 0\n    \n    // Iterate through all possible subsets\n    for mask \u2190 0 to 2\u207f-1:\n        // Try adding each element to current subset\n        for j \u2190 0 to n-1:\n            if not (mask & (1 << j)):\n                new_mask \u2190 mask | (1 << j)\n                dp[new_mask] \u2190 min(dp[new_mask], dp[mask] + cost[mask][j])\n    \n    return dp[2\u207f-1]\n\n// Example: Traveling Salesman Problem\n// n = 3 cities\n// cost matrix:\n// 0 10 15\n// 10 0 20\n// 15 20 0\n//\n// Binary representation of states:\n// 000: empty set\n// 001: {0}\n// 010: {1}\n// 011: {0,1}\n// 100: {2}\n// 101: {0,2}\n// 110: {1,2}\n// 111: {0,1,2}\n//\n// Final answer: minimum cost of visiting all cities",
    "keySteps": [
      "Uses bit manipulation for state representation",
      "Efficient for subset and permutation problems",
      "Common in competitive programming",
      "Practical for n \u2264 20 due to exponential complexity"
    ]
  },
  "bit-manipulation": {
    "name": "Bit Manipulation",
    "type": "1",
    "description": "Bit Manipulation is an algorithm with time complexity O(1). It is primarily used for efficient bit-level operations",
    "timeComplexity": "O(1) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Efficient bit-level operations\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Efficient bit-level operations\n    ",
    "useCase": "Efficient bit-level operations\n    ",
    "pseudocode": "// Basic Operations\nAND(x, y):     return x & y\nOR(x, y):      return x | y\nXOR(x, y):     return x ^ y\nNOT(x):        return ~x\nLEFT-SHIFT(x, n):  return x << n\nRIGHT-SHIFT(x, n): return x >> n\n\n// Count Set Bits\nCOUNT-BITS(x):\n  count = 0\n  while x > 0:\n    count += x & 1\n    x = x >> 1\n  return count\n\n// Check Power of Two\nIS-POWER-OF-TWO(x):\n  return x > 0 and (x & (x - 1)) == 0\n\n// Find Single Number\nSINGLE-NUMBER(A):\n  result = 0\n  for num in A:\n    result ^= num\n  return result\n\n// Swap Without Temp\nSWAP(x, y):\n  x = x ^ y\n  y = x ^ y\n  x = x ^ y\n  return (x, y)\n\n// Add Without Plus\nADD(x, y):\n  while y != 0:\n    carry = x & y\n    x = x ^ y\n    y = carry << 1\n  return x",
    "keySteps": []
  },
  "binary-search": {
    "name": "Binary Search",
    "type": "log n",
    "description": "Binary Search is an algorithm with time complexity O(log n). It is primarily used for searching in sorted arrays",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Searching in sorted arrays\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Searching in sorted arrays\n    ",
    "useCase": "Searching in sorted arrays\n    ",
    "pseudocode": "// Standard Binary Search\nBINARY-SEARCH(A, x):\n  left = 0\n  right = n - 1\n  while left \u2264 right:\n    mid = floor((left + right) / 2)\n    if A[mid] == x:\n      return mid\n    if A[mid] < x:\n      left = mid + 1\n    else:\n      right = mid - 1\n  return -1\n\n// First Occurrence\nFIRST-OCCURRENCE(A, x):\n  left = 0\n  right = n - 1\n  result = -1\n  while left \u2264 right:\n    mid = floor((left + right) / 2)\n    if A[mid] == x:\n      result = mid\n      right = mid - 1\n    elif A[mid] < x:\n      left = mid + 1\n    else:\n      right = mid - 1\n  return result\n\n// Last Occurrence\nLAST-OCCURRENCE(A, x):\n  left = 0\n  right = n - 1\n  result = -1\n  while left \u2264 right:\n    mid = floor((left + right) / 2)\n    if A[mid] == x:\n      result = mid\n      left = mid + 1\n    elif A[mid] < x:\n      left = mid + 1\n    else:\n      right = mid - 1\n  return result\n\n// Rotated Array Search\nROTATED-SEARCH(A, x):\n  left = 0\n  right = n - 1\n  while left \u2264 right:\n    mid = floor((left + right) / 2)\n    if A[mid] == x:\n      return mid\n    if A[left] \u2264 A[mid]:\n      if A[left] \u2264 x < A[mid]:\n        right = mid - 1\n      else:\n        left = mid + 1\n    else:\n      if A[mid] < x \u2264 A[right]:\n        left = mid + 1\n      else:\n        right = mid - 1\n  return -1",
    "keySteps": []
  },
  "binary-search-tree": {
    "name": "Binary Search Tree",
    "type": "Algorithm",
    "description": "Binary Search Tree is an algorithm with time complexity O(h). It is primarily used for efficient search and insertion",
    "timeComplexity": "O(h) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Efficient search and insertion\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Efficient search and insertion\n    ",
    "useCase": "Efficient search and insertion\n    ",
    "pseudocode": "// Binary search tree node structure\nBST-NODE:\n    key\n    left\n    right\n    parent\n\n// Tree operations\nTREE-INSERT(T, z):\n    y \u2190 NIL\n    x \u2190 T.root\n    while x \u2260 NIL:\n        y \u2190 x\n        if z.key < x.key:\n            x \u2190 x.left\n        else:\n            x \u2190 x.right\n    z.parent \u2190 y\n    if y = NIL:\n        T.root \u2190 z\n    else if z.key < y.key:\n        y.left \u2190 z\n    else:\n        y.right \u2190 z\n\nTREE-SEARCH(x, k):\n    if x = NIL or k = x.key:\n        return x\n    if k < x.key:\n        return TREE-SEARCH(x.left, k)\n    else:\n        return TREE-SEARCH(x.right, k)\n\nTREE-DELETE(T, z):\n    if z.left = NIL:\n        TRANSPLANT(T, z, z.right)\n    else if z.right = NIL:\n        TRANSPLANT(T, z, z.left)\n    else:\n        y \u2190 TREE-MINIMUM(z.right)\n        if y.parent \u2260 z:\n            TRANSPLANT(T, y, y.right)\n            y.right \u2190 z.right\n            y.right.parent \u2190 y\n        TRANSPLANT(T, z, y)\n        y.left \u2190 z.left\n        y.left.parent \u2190 y\n\nTRANSPLANT(T, u, v):\n    if u.parent = NIL:\n        T.root \u2190 v\n    else if u = u.parent.left:\n        u.parent.left \u2190 v\n    else:\n        u.parent.right \u2190 v\n    if v \u2260 NIL:\n        v.parent \u2190 u.parent\n\n// Example:\n// Input: T = empty tree\n// Operations:\n// 1. Insert 5\n// 2. Insert 3\n// 3. Insert 7\n// 4. Insert 2\n// 5. Insert 4\n// 6. Insert 6\n// 7. Insert 8\n//\n// Resulting tree:\n//        5\n//      /   \\\\\n//     3     7\n//    / \\\\   / \\\\\n//   2   4 6   8",
    "keySteps": [
      "Insert: Maintain BST property",
      "Search: Binary search in tree",
      "Delete: Handle three cases"
    ]
  },
  "binary-search-on-answer": {
    "name": "Binary Search on Answer",
    "type": "Algorithm",
    "description": "Binary Search on Answer is an algorithm with time complexity O(n log m). It is primarily used for find optimal value in search       space",
    "timeComplexity": "O(n log m) &nbsp;|&nbsp; Space: O(1) &nbsp;|&nbsp; Use: Find optimal value in search\n      space\n    ",
    "spaceComplexity": "O(1) &nbsp;|&nbsp; Use: Find optimal value in search\n      space\n    ",
    "useCase": "Find optimal value in search\n      space\n    ",
    "pseudocode": "// Binary search on answer with predicate function\nBINARY-SEARCH-ANSWER(low, high, predicate):\n    while low < high:\n        mid \u2190 \u230a(low + high) / 2\u230b\n        if predicate(mid):\n            high \u2190 mid\n        else:\n            low \u2190 mid + 1\n    return low\n\n// Example: Find minimum capacity to ship packages within D days\nSHIP-PACKAGES(weights, D):\n    n \u2190 length[weights]\n    low \u2190 max(weights)\n    high \u2190 sum(weights)\n    predicate \u2190 \u03bb(capacity):\n        days \u2190 1\n        current \u2190 0\n        for i \u2190 1 to n:\n            if current + weights[i] > capacity:\n                days \u2190 days + 1\n                current \u2190 weights[i]\n            else:\n                current \u2190 current + weights[i]\n        return days \u2264 D\n    return BINARY-SEARCH-ANSWER(low, high, predicate)\n\n// Example:\n// Input: weights = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], D = 5\n//\n// Execution:\n// 1. low = 10, high = 55\n// 2. mid = 32: days = 3 \u2264 5\n// 3. mid = 21: days = 4 \u2264 5\n// 4. mid = 15: days = 5 \u2264 5\n// 5. mid = 12: days = 6 > 5\n// 6. mid = 13: days = 6 > 5\n// 7. mid = 14: days = 5 \u2264 5\n//\n// Output: 15",
    "keySteps": [
      "Initialize: Set search space boundaries",
      "Search: Binary search with predicate function",
      "Verify: Check if solution meets requirements"
    ]
  },
  "binary-indexed-tree": {
    "name": "Binary Indexed Tree",
    "type": "Algorithm",
    "description": "Binary Indexed Tree is an algorithm with time complexity O(log n). It is primarily used for efficient range queries and point       updates",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Efficient range queries and point\n      updates\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Efficient range queries and point\n      updates\n    ",
    "useCase": "Efficient range queries and point\n      updates\n    ",
    "pseudocode": "BINARY-INDEXED-TREE(A)\n    let n be the length of A\n    let tree[1\u2025n] be a new array\n\n    for i \u2190 1 to n\n        do tree[i] \u2190 0\n\n    for i \u2190 1 to n\n        do UPDATE(tree, i, A[i])\n\n    return tree\n\nUPDATE(tree, idx, delta)\n    while idx \u2264 n\n        do tree[idx] \u2190 tree[idx] + delta\n            idx \u2190 idx + (idx & -idx)\n\nQUERY(tree, idx)\n    let sum \u2190 0\n    while idx > 0\n        do sum \u2190 sum + tree[idx]\n            idx \u2190 idx - (idx & -idx)\n    return sum\n\nRANGE-QUERY(tree, l, r)\n    return QUERY(tree, r) - QUERY(tree, l-1)\n\n// Example:\n// Input: A = [1, 3, 5, 7, 9, 11]\n//\n// Initial tree:\n//   tree = [0, 0, 0, 0, 0, 0]\n//\n// After updates:\n//   tree = [1, 4, 5, 16, 9, 20]\n//\n// Query(4):\n//   idx = 4: sum = 16\n//   idx = 0: return 16\n//\n// Range Query(2,5):\n//   QUERY(5) = 25\n//   QUERY(1) = 1\n//   return 24\n//\n// Output: Range sum from index 2 to 5 is 24",
    "keySteps": [
      "Initialize: Create tree array and set all values to 0",
      "Update: Add value to all affected nodes using LSB",
      "Query: Compute prefix sums and range queries efficiently"
    ]
  },
  "bfs": {
    "name": "BFS",
    "type": "V + E",
    "description": "BFS is an algorithm with time complexity O(V + E). It is primarily used for level-order traversal and shortest       path in unweighted graphs",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Level-order traversal and shortest\n      path in unweighted graphs\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Level-order traversal and shortest\n      path in unweighted graphs\n    ",
    "useCase": "Level-order traversal and shortest\n      path in unweighted graphs\n    ",
    "pseudocode": "// Standard BFS\nBFS(G, s):\n  for each vertex u in G.V - {s}:\n    u.color = WHITE\n    u.d = \u221e\n    u.\u03c0 = NIL\n  s.color = GRAY\n  s.d = 0\n  s.\u03c0 = NIL\n  Q = \u2205\n  ENQUEUE(Q, s)\n  while Q \u2260 \u2205:\n    u = DEQUEUE(Q)\n    for each v in G.adj[u]:\n      if v.color == WHITE:\n        v.color = GRAY\n        v.d = u.d + 1\n        v.\u03c0 = u\n        ENQUEUE(Q, v)\n    u.color = BLACK\n\n// Shortest Path\nSHORTEST-PATH(G, s, t):\n  BFS(G, s)\n  if t.d == \u221e:\n    return NIL\n  path = []\n  u = t\n  while u \u2260 NIL:\n    path.append(u)\n    u = u.\u03c0\n  return reverse(path)\n\n// Connected Components\nCONNECTED-COMPONENTS(G):\n  for each vertex u in G.V:\n    u.color = WHITE\n    u.\u03c0 = NIL\n  cc = 0\n  for each vertex u in G.V:\n    if u.color == WHITE:\n      cc += 1\n      BFS-VISIT(G, u, cc)\n  return cc\n\n// Level Order Traversal\nLEVEL-ORDER(T):\n  if T.root == NIL:\n    return []\n  Q = \u2205\n  ENQUEUE(Q, T.root)\n  result = []\n  while Q \u2260 \u2205:\n    level_size = Q.size\n    level = []\n    for i from 1 to level_size:\n      u = DEQUEUE(Q)\n      level.append(u.key)\n      if u.left \u2260 NIL:\n        ENQUEUE(Q, u.left)\n      if u.right \u2260 NIL:\n        ENQUEUE(Q, u.right)\n    result.append(level)\n  return result",
    "keySteps": []
  },
  "bfs-linked-list": {
    "name": "BFS Linked List",
    "type": "Algorithm",
    "description": "BFS Linked List is an algorithm with time complexity O(n). It is primarily used for traverse linked list level by level",
    "timeComplexity": "O(n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Traverse linked list level by level\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Traverse linked list level by level\n    ",
    "useCase": "Traverse linked list level by level\n    ",
    "pseudocode": "// Node structure for linked list\nNODE:\n    key\n    next\n    visited\n\n// BFS on linked list\nBFS-LINKED-LIST(head):\n    if head = NIL:\n        return\n\n    // Initialize queue and mark head as visited\n    Q \u2190 \u2205\n    ENQUEUE(Q, head)\n    head.visited \u2190 true\n\n    while Q \u2260 \u2205:\n        u \u2190 DEQUEUE(Q)\n        process u.key\n\n        // Process next node if not visited\n        if u.next \u2260 NIL and not u.next.visited:\n            u.next.visited \u2190 true\n            ENQUEUE(Q, u.next)\n\n// Example:\n// Input: 1 \u2192 2 \u2192 3 \u2192 4 \u2192 5\n//\n// Execution:\n// 1. Q = [1], visited = {1}\n// 2. Q = [2], visited = {1,2}\n// 3. Q = [3], visited = {1,2,3}\n// 4. Q = [4], visited = {1,2,3,4}\n// 5. Q = [5], visited = {1,2,3,4,5}\n//\n// Output: 1, 2, 3, 4, 5",
    "keySteps": [
      "Initialize: Queue and visited set",
      "Process: Nodes level by level",
      "Mark: Visited nodes to prevent cycles"
    ]
  },
  "bellman-ford": {
    "name": "Bellman Ford",
    "type": "VE",
    "description": "Bellman Ford is an algorithm with time complexity O(VE). It is primarily used for find shortest paths with negative       weights",
    "timeComplexity": "O(VE) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find shortest paths with negative\n      weights\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find shortest paths with negative\n      weights\n    ",
    "useCase": "Find shortest paths with negative\n      weights\n    ",
    "pseudocode": "# Bellman-Ford: Find shortest paths with negative weights\n# Input: Weighted directed graph G = (V, E) with weight function w, source vertex s\n# Output: Shortest paths from s to all vertices, or indication of negative cycle\n\nAlgorithm BELLMAN-FORD(G, w, s)\n    # Initialize distances\n    for each vertex v in V do\n        d[v] \u2190 \u221e\n        \u03c0[v] \u2190 NIL\n    end for\n    d[s] \u2190 0\n\n    # Relax edges |V| - 1 times\n    for i \u2190 1 to |V| - 1 do\n        for each edge (u, v) in E do\n            if d[v] > d[u] + w(u, v) then\n                d[v] \u2190 d[u] + w(u, v)\n                \u03c0[v] \u2190 u\n            end if\n        end for\n    end for\n\n    # Check for negative cycles\n    for each edge (u, v) in E do\n        if d[v] > d[u] + w(u, v) then\n            return \"Graph contains negative cycle\"\n        end if\n    end for\n\n    return d, \u03c0\n\n# Example:\n# Input: G with V = {s,a,b,c} and edges:\n# (s,a,4), (s,b,5), (a,b,-1), (a,c,2), (b,c,1)\n#\n# Step 1: Initial distances\n#         d = [0, \u221e, \u221e, \u221e]\n# Step 2: After first relaxation\n#         d = [0, 4, 5, \u221e]\n# Step 3: After second relaxation\n#         d = [0, 4, 3, 4]\n# Step 4: After third relaxation\n#         d = [0, 4, 3, 4]\n# Step 5: No negative cycle found\n#\n# Output: d = [0, 4, 3, 4]",
    "keySteps": [
      "Initialize distances and predecessors",
      "Relax edges |V| - 1 times",
      "Check for negative cycles",
      "Return distances and predecessors"
    ]
  },
  "backtracking": {
    "name": "Backtracking",
    "type": "n!",
    "description": "Backtracking is an algorithm with time complexity O(n!). It is primarily used for exhaustive search with pruning",
    "timeComplexity": "O(n!) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Exhaustive search with pruning\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Exhaustive search with pruning\n    ",
    "useCase": "Exhaustive search with pruning\n    ",
    "pseudocode": "// N-Queens\nN-QUEENS(n):\n  board = [0] * n\n  return SOLVE-N-QUEENS(board, 0)\n\nSOLVE-N-QUEENS(board, row):\n  if row == n:\n    return true\n  for col from 0 to n-1:\n    if IS-SAFE(board, row, col):\n      board[row] = col\n      if SOLVE-N-QUEENS(board, row+1):\n        return true\n      board[row] = 0\n  return false\n\n// Sudoku\nSUDOKU(board):\n  return SOLVE-SUDOKU(board)\n\nSOLVE-SUDOKU(board):\n  find empty cell (i, j)\n  if no empty cell:\n    return true\n  for num from 1 to 9:\n    if IS-VALID(board, i, j, num):\n      board[i][j] = num\n      if SOLVE-SUDOKU(board):\n        return true\n      board[i][j] = 0\n  return false\n\n// Subset Sum\nSUBSET-SUM(S, target):\n  return SOLVE-SUBSET-SUM(S, 0, target)\n\nSOLVE-SUBSET-SUM(S, i, target):\n  if target == 0:\n    return true\n  if i == length(S) or target < 0:\n    return false\n  if SOLVE-SUBSET-SUM(S, i+1, target-S[i]):\n    return true\n  return SOLVE-SUBSET-SUM(S, i+1, target)",
    "keySteps": []
  },
  "b-tree": {
    "name": "B-Tree",
    "type": "log n",
    "description": "B-Tree is an algorithm with time complexity O(log n). It is primarily used for disk-based balanced search tree",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Disk-based balanced search tree\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Disk-based balanced search tree\n    ",
    "useCase": "Disk-based balanced search tree\n    ",
    "pseudocode": "B-TREE-INSERT(T, k)\n    let r \u2190 T.root\n    if r.n = 2t - 1\n        then s \u2190 ALLOCATE-NODE()\n             T.root \u2190 s\n             s.leaf \u2190 false\n             s.n \u2190 0\n             s.c\u2081 \u2190 r\n             B-TREE-SPLIT-CHILD(s, 1)\n             B-TREE-INSERT-NONFULL(s, k)\n        else B-TREE-INSERT-NONFULL(r, k)\n\nB-TREE-INSERT-NONFULL(x, k)\n    let i \u2190 x.n\n    if x.leaf\n        then while i \u2265 1 and k < x.key\u1d62\n                do x.key\u1d62\u208a\u2081 \u2190 x.key\u1d62\n                   i \u2190 i - 1\n             x.key\u1d62\u208a\u2081 \u2190 k\n             x.n \u2190 x.n + 1\n        else while i \u2265 1 and k < x.key\u1d62\n                do i \u2190 i - 1\n             i \u2190 i + 1\n             if x.c\u1d62.n = 2t - 1\n                then B-TREE-SPLIT-CHILD(x, i)\n                     if k > x.key\u1d62\n                        then i \u2190 i + 1\n             B-TREE-INSERT-NONFULL(x.c\u1d62, k)\n\nB-TREE-SPLIT-CHILD(x, i)\n    let z \u2190 ALLOCATE-NODE()\n    let y \u2190 x.c\u1d62\n    z.leaf \u2190 y.leaf\n    z.n \u2190 t - 1\n    for j \u2190 1 to t - 1\n        do z.key\u2c7c \u2190 y.key\u2c7c\u208a\u209c\n    if not y.leaf\n        then for j \u2190 1 to t\n                do z.c\u2c7c \u2190 y.c\u2c7c\u208a\u209c\n    y.n \u2190 t - 1\n    for j \u2190 x.n + 1 downto i + 1\n        do x.c\u2c7c\u208a\u2081 \u2190 x.c\u2c7c\n    x.c\u1d62\u208a\u2081 \u2190 z\n    for j \u2190 x.n downto i\n        do x.key\u2c7c\u208a\u2081 \u2190 x.key\u2c7c\n    x.key\u1d62 \u2190 y.key\u209c\n    x.n \u2190 x.n + 1\n\n// Example:\n// Input: Insert keys [10, 20, 30, 40, 50, 60, 70, 80, 90] with t = 2\n//\n// Insert 10, 20:\n//   [10, 20]\n//\n// Insert 30:\n//   [20]\n//  /    \\\n// [10]  [30]\n//\n// Insert 40, 50:\n//   [20, 40]\n//  /   |   \\\n// [10] [30] [50]\n//\n// Insert 60:\n//      [40]\n//    /     \\\n// [20]     [60]\n// /  \\     /  \\\n// [10][30][50][70]\n//\n// Insert 70, 80, 90:\n//      [40, 70]\n//    /    |    \\\n// [20]  [60]  [80,90]\n// /  \\  /  \\\n// [10][30][50]",
    "keySteps": [
      "Insert: Find appropriate leaf node for insertion",
      "Split: Handle node overflow by splitting nodes",
      "Maintain: Keep tree balanced through proper splitting"
    ]
  },
  "avl-tree": {
    "name": "AVL Tree",
    "type": "Algorithm",
    "description": "AVL Tree is an algorithm with time complexity O(log n). It is primarily used for self-balancing binary search tree",
    "timeComplexity": "O(log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Self-balancing binary search tree\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Self-balancing binary search tree\n    ",
    "useCase": "Self-balancing binary search tree\n    ",
    "pseudocode": "AVL-INSERT(T, z)\n    let y \u2190 null\n    let x \u2190 T.root\n\n    while x \u2260 null\n        do y \u2190 x\n           if z.key < x.key\n               then x \u2190 x.left\n               else x \u2190 x.right\n\n    z.p \u2190 y\n    if y = null\n        then T.root \u2190 z\n        else if z.key < y.key\n            then y.left \u2190 z\n            else y.right \u2190 z\n\n    z.left \u2190 null\n    z.right \u2190 null\n    z.height \u2190 1\n\n    AVL-BALANCE(T, z)\n\nAVL-BALANCE(T, z)\n    while z \u2260 null\n        do z.height \u2190 1 + max(HEIGHT(z.left), HEIGHT(z.right))\n           if HEIGHT(z.left) - HEIGHT(z.right) > 1\n               then if HEIGHT(z.left.left) \u2265 HEIGHT(z.left.right)\n                       then RIGHT-ROTATE(T, z)\n                       else LEFT-ROTATE(T, z.left)\n                           RIGHT-ROTATE(T, z)\n           else if HEIGHT(z.right) - HEIGHT(z.left) > 1\n               then if HEIGHT(z.right.right) \u2265 HEIGHT(z.right.left)\n                       then LEFT-ROTATE(T, z)\n                       else RIGHT-ROTATE(T, z.right)\n                           LEFT-ROTATE(T, z)\n           z \u2190 z.p\n\nRIGHT-ROTATE(T, y)\n    let x \u2190 y.left\n    y.left \u2190 x.right\n    if x.right \u2260 null\n        then x.right.p \u2190 y\n    x.p \u2190 y.p\n    if y.p = null\n        then T.root \u2190 x\n        else if y = y.p.right\n            then y.p.right \u2190 x\n            else y.p.left \u2190 x\n    x.right \u2190 y\n    y.p \u2190 x\n    y.height \u2190 1 + max(HEIGHT(y.left), HEIGHT(y.right))\n    x.height \u2190 1 + max(HEIGHT(x.left), HEIGHT(x.right))\n\nLEFT-ROTATE(T, x)\n    let y \u2190 x.right\n    x.right \u2190 y.left\n    if y.left \u2260 null\n        then y.left.p \u2190 x\n    y.p \u2190 x.p\n    if x.p = null\n        then T.root \u2190 y\n        else if x = x.p.left\n            then x.p.left \u2190 y\n            else x.p.right \u2190 y\n    y.left \u2190 x\n    x.p \u2190 y\n    x.height \u2190 1 + max(HEIGHT(x.left), HEIGHT(x.right))\n    y.height \u2190 1 + max(HEIGHT(y.left), HEIGHT(y.right))\n\n// Example:\n// Input: Insert keys [10, 20, 30, 40, 50, 25]\n//\n// Insert 10:\n//   Tree: 10\n//\n// Insert 20:\n//   Tree: 10\n//         \\\n//         20\n//\n// Insert 30:\n//   Tree: 20\n//        /  \\\n//      10    30\n//\n// Insert 40:\n//   Tree: 20\n//        /  \\\n//      10    30\n//             \\\n//             40\n//\n// Insert 50:\n//   Tree: 20\n//        /  \\\n//      10    40\n//           /  \\\n//         30    50\n//\n// Insert 25:\n//   Tree: 30\n//        /  \\\n//      20    40\n//     /  \\    \\\n//   10   25   50",
    "keySteps": [
      "Insert: Standard BST insertion with height tracking",
      "Balance: Check and fix height imbalances using rotations",
      "Rotate: Perform left/right rotations to maintain balance"
    ]
  },
  "articulation-points": {
    "name": "Articulation Points",
    "type": "Algorithm",
    "description": "Articulation Points is an algorithm with time complexity O(V + E). It is primarily used for find vertices whose removal       increases connected components",
    "timeComplexity": "O(V + E) &nbsp;|&nbsp; Space: O(V) &nbsp;|&nbsp; Use: Find vertices whose removal\n      increases connected components\n    ",
    "spaceComplexity": "O(V) &nbsp;|&nbsp; Use: Find vertices whose removal\n      increases connected components\n    ",
    "useCase": "Find vertices whose removal\n      increases connected components\n    ",
    "pseudocode": "# Articulation Points: Find vertices whose removal increases connected components\n# Input: Undirected graph G = (V, E)\n# Output: Set of articulation points\n\nAlgorithm ARTICULATION-POINTS(G)\n    time \u2190 0\n    for each vertex v in V do\n        visited[v] \u2190 false\n        disc[v] \u2190 \u221e\n        low[v] \u2190 \u221e\n        parent[v] \u2190 NIL\n    end for\n\n    for each vertex v in V do\n        if not visited[v] then\n            DFS-AP(v)\n        end if\n    end for\n\n    return articulation_points\n\nAlgorithm DFS-AP(u)\n    visited[u] \u2190 true\n    disc[u] \u2190 low[u] \u2190 time + 1\n    time \u2190 time + 1\n    children \u2190 0\n\n    for each vertex v in Adj[u] do\n        if not visited[v] then\n            children \u2190 children + 1\n            parent[v] \u2190 u\n            DFS-AP(v)\n\n            # Check if subtree rooted with v has connection to ancestors of u\n            low[u] \u2190 min(low[u], low[v])\n\n            # u is articulation point if:\n            # 1. u is root and has two or more children\n            # 2. u is not root and low[v] \u2265 disc[u]\n            if parent[u] = NIL and children > 1 then\n                articulation_points \u2190 articulation_points \u222a {u}\n            else if parent[u] \u2260 NIL and low[v] \u2265 disc[u] then\n                articulation_points \u2190 articulation_points \u222a {u}\n            end if\n        else if v \u2260 parent[u] then\n            low[u] \u2190 min(low[u], disc[v])\n        end if\n    end for\n\n# Example:\n# Input: G with V = {0,1,2,3,4} and edges:\n# (0,1), (1,2), (2,0), (1,3), (1,4), (3,4)\n#\n# Step 1: Start DFS from 0\n# Step 2: Visit 0, 1, 2\n# Step 3: Backtrack to 1, visit 3, 4\n# Step 4: Check articulation points\n#         - 1 is root with 2 children\n#         - No other vertices satisfy conditions\n#\n# Output: {1}",
    "keySteps": [
      "Initialize visited, discovery, and low values",
      "Perform DFS from each unvisited vertex",
      "Update low values and check articulation conditions",
      "Return set of articulation points"
    ]
  },
  "activity-selection": {
    "name": "Activity Selection",
    "type": "Algorithm",
    "description": "Activity Selection is an algorithm with time complexity O(n log n). It is primarily used for selecting maximum number of       non-overlapping activities",
    "timeComplexity": "O(n log n) &nbsp;|&nbsp; Space: O(n) &nbsp;|&nbsp; Use: Selecting maximum number of\n      non-overlapping activities\n    ",
    "spaceComplexity": "O(n) &nbsp;|&nbsp; Use: Selecting maximum number of\n      non-overlapping activities\n    ",
    "useCase": "Selecting maximum number of\n      non-overlapping activities\n    ",
    "pseudocode": "// Standard Activity Selection\ndef activity_selection(activities):\n    # Sort activities by finish time\n    activities.sort(key=lambda x: x[1])\n\n    selected = []\n    last_finish = 0\n\n    for activity in activities:\n        start, finish = activity\n        if start >= last_finish:\n            selected.append(activity)\n            last_finish = finish\n\n    return selected\n\n// Activity Selection with Weights\ndef activity_selection_weights(activities):\n    # Sort activities by finish time\n    activities.sort(key=lambda x: x[1])\n\n    n = len(activities)\n    dp = [0] * n\n    dp[0] = activities[0][2]  # weight\n\n    for i in range(1, n):\n        # Find last non-conflicting activity\n        last_non_conflict = -1\n        for j in range(i-1, -1, -1):\n            if activities[j][1] <= activities[i][0]:\n                last_non_conflict = j\n                break\n\n        # Include current activity\n        include = activities[i][2]\n        if last_non_conflict != -1:\n            include += dp[last_non_conflict]\n\n        # Store maximum of including or excluding\n        dp[i] = max(include, dp[i-1])\n\n    return dp[n-1]\n\n// Activity Selection with Resource Constraints\ndef activity_selection_resources(activities, resources):\n    # Sort activities by finish time\n    activities.sort(key=lambda x: x[1])\n\n    selected = []\n    resource_available = [0] * resources\n\n    for activity in activities:\n        start, finish, resource = activity\n        if start >= resource_available[resource]:\n            selected.append(activity)\n            resource_available[resource] = finish\n\n    return selected\n\n# Examples:\n\n# Standard Activity Selection\n# Input:\n# activities = [\n#     (1, 4),  # (start, finish)\n#     (3, 5),\n#     (0, 6),\n#     (5, 7),\n#     (3, 8),\n#     (5, 9),\n#     (6, 10),\n#     (8, 11),\n#     (8, 12),\n#     (2, 13),\n#     (12, 14)\n# ]\n# Output:\n# selected = [(1, 4), (5, 7), (8, 11), (12, 14)]\n# Total activities: 4\n\n# Activity Selection with Weights\n# Input:\n# activities = [\n#     (1, 4, 2),  # (start, finish, weight)\n#     (3, 5, 4),\n#     (0, 6, 4),\n#     (5, 7, 7),\n#     (3, 8, 2),\n#     (5, 9, 1)\n# ]\n# Output:\n# max_weight = 8  # (1,4,2) + (5,7,7)\n\n# Activity Selection with Resource Constraints\n# Input:\n# activities = [\n#     (1, 4, 0),  # (start, finish, resource)\n#     (3, 5, 1),\n#     (0, 6, 0),\n#     (5, 7, 1),\n#     (3, 8, 0),\n#     (5, 9, 1)\n# ]\n# Output:\n# selected = [(1, 4, 0), (3, 5, 1), (5, 7, 1)]\n# Total activities: 3",
    "keySteps": [
      "Sort: Activities by finish time",
      "Select: First activity and subsequent non-overlapping activities",
      "Update: Track last finish time or resource availability"
    ]
  },
  "a-star-search": {
    "name": "A* Search",
    "type": "b^d",
    "description": "A* Search is an algorithm with time complexity O(b^d). It is primarily used for optimal path finding with       heuristics",
    "timeComplexity": "O(b^d) &nbsp;|&nbsp; Space: O(b^d) &nbsp;|&nbsp; Use: Optimal path finding with\n      heuristics\n    ",
    "spaceComplexity": "O(b^d) &nbsp;|&nbsp; Use: Optimal path finding with\n      heuristics\n    ",
    "useCase": "Optimal path finding with\n      heuristics\n    ",
    "pseudocode": "A-STAR-SEARCH(G, start, goal)\n    let openSet be a new priority queue\n    let gScore[1\u2025n] be a new array\n    let fScore[1\u2025n] be a new array\n    let cameFrom[1\u2025n] be a new array\n\n    for each vertex v in G.V\n        do gScore[v] \u2190 \u221e\n           fScore[v] \u2190 \u221e\n           cameFrom[v] \u2190 null\n\n    gScore[start] \u2190 0\n    fScore[start] \u2190 h(start, goal)\n    openSet.insert(start, fScore[start])\n\n    while openSet is not empty\n        do current \u2190 openSet.extract_min()\n           if current = goal\n               then return RECONSTRUCT-PATH(cameFrom, current)\n\n           for each neighbor in G.adj[current]\n               do tentative_gScore \u2190 gScore[current] + d(current, neighbor)\n                  if tentative_gScore < gScore[neighbor]\n                      then cameFrom[neighbor] \u2190 current\n                           gScore[neighbor] \u2190 tentative_gScore\n                           fScore[neighbor] \u2190 gScore[neighbor] + h(neighbor, goal)\n                           if neighbor not in openSet\n                               then openSet.insert(neighbor, fScore[neighbor])\n\n    return null\n\nRECONSTRUCT-PATH(cameFrom, current)\n    let path be a new array\n    while current \u2260 null\n        do path.append(current)\n           current \u2190 cameFrom[current]\n    return reverse(path)\n\n// Example:\n// Input: G = {\n//   V = {A, B, C, D, E},\n//   E = {(A,B,4), (A,C,2), (B,D,5), (C,D,1), (C,E,3), (D,E,1)}\n// }\n// start = A, goal = E\n//\n// Initial state:\n//   openSet = {(A,6)}\n//   gScore = {A:0, B:\u221e, C:\u221e, D:\u221e, E:\u221e}\n//   fScore = {A:6, B:\u221e, C:\u221e, D:\u221e, E:\u221e}\n//\n// First iteration:\n//   current = A\n//   openSet = {(B,9), (C,5)}\n//   gScore = {A:0, B:4, C:2, D:\u221e, E:\u221e}\n//   fScore = {A:6, B:9, C:5, D:\u221e, E:\u221e}\n//\n// Second iteration:\n//   current = C\n//   openSet = {(B,9), (D,4), (E,5)}\n//   gScore = {A:0, B:4, C:2, D:3, E:5}\n//   fScore = {A:6, B:9, C:5, D:4, E:5}\n//\n// Final path: A \u2192 C \u2192 D \u2192 E",
    "keySteps": [
      "Initialize: Set up priority queue and score arrays",
      "Process: Expand nodes with lowest f-score",
      "Update: Maintain g-scores and reconstruct path"
    ]
  }
}